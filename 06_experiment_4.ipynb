{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from joblib import load, dump\n",
    "from enum import Enum\n",
    "\n",
    "from fire_modules import severity_matrix as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevacion</th>\n",
       "      <th>erodi</th>\n",
       "      <th>slope</th>\n",
       "      <th>orientacion_sen</th>\n",
       "      <th>orientacion_cos</th>\n",
       "      <th>altura</th>\n",
       "      <th>lfcc</th>\n",
       "      <th>inflam</th>\n",
       "      <th>mcroth</th>\n",
       "      <th>anomalia</th>\n",
       "      <th>dpv</th>\n",
       "      <th>vel_media_viento</th>\n",
       "      <th>severidad_real</th>\n",
       "      <th>severidad_discreta</th>\n",
       "      <th>coord_x_etrs89</th>\n",
       "      <th>coord_y_etrs89</th>\n",
       "      <th>incendio</th>\n",
       "      <th>provincia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119340</th>\n",
       "      <td>1024.904053</td>\n",
       "      <td>4</td>\n",
       "      <td>15.177</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.103298</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.956501</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>73.561211</td>\n",
       "      <td>2.246882</td>\n",
       "      <td>2.916394</td>\n",
       "      <td>0.845614</td>\n",
       "      <td>3</td>\n",
       "      <td>490110.0</td>\n",
       "      <td>4538190.0</td>\n",
       "      <td>Cogolludo</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58023</th>\n",
       "      <td>505.352997</td>\n",
       "      <td>1</td>\n",
       "      <td>25.718</td>\n",
       "      <td>0.206331</td>\n",
       "      <td>0.978482</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.892401</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>86.961823</td>\n",
       "      <td>2.385298</td>\n",
       "      <td>4.876472</td>\n",
       "      <td>0.270908</td>\n",
       "      <td>1</td>\n",
       "      <td>604950.0</td>\n",
       "      <td>4257480.0</td>\n",
       "      <td>Talave</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46997</th>\n",
       "      <td>388.710999</td>\n",
       "      <td>2</td>\n",
       "      <td>31.593</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>0.178167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956900</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>79.168137</td>\n",
       "      <td>2.319516</td>\n",
       "      <td>5.026659</td>\n",
       "      <td>0.412787</td>\n",
       "      <td>1</td>\n",
       "      <td>617730.0</td>\n",
       "      <td>4243860.0</td>\n",
       "      <td>Donceles</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67214</th>\n",
       "      <td>1063.177002</td>\n",
       "      <td>1</td>\n",
       "      <td>22.364</td>\n",
       "      <td>0.901304</td>\n",
       "      <td>-0.433188</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.424201</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50.321835</td>\n",
       "      <td>0.349119</td>\n",
       "      <td>2.470344</td>\n",
       "      <td>0.576249</td>\n",
       "      <td>2</td>\n",
       "      <td>561090.0</td>\n",
       "      <td>4256790.0</td>\n",
       "      <td>Yeste</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153590</th>\n",
       "      <td>507.516998</td>\n",
       "      <td>3</td>\n",
       "      <td>13.911</td>\n",
       "      <td>0.872081</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.275799</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>72.893860</td>\n",
       "      <td>1.469779</td>\n",
       "      <td>3.393716</td>\n",
       "      <td>0.310006</td>\n",
       "      <td>1</td>\n",
       "      <td>407340.0</td>\n",
       "      <td>4412550.0</td>\n",
       "      <td>Montesion</td>\n",
       "      <td>Toledo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          elevacion  erodi   slope  orientacion_sen  orientacion_cos  altura  \\\n",
       "119340  1024.904053      4  15.177         0.994650         0.103298     9.0   \n",
       "58023    505.352997      1  25.718         0.206331         0.978482     3.0   \n",
       "46997    388.710999      2  31.593        -0.984000         0.178167     1.0   \n",
       "67214   1063.177002      1  22.364         0.901304        -0.433188     2.0   \n",
       "153590   507.516998      3  13.911         0.872081         0.489362     3.0   \n",
       "\n",
       "             lfcc  inflam  mcroth   anomalia       dpv  vel_media_viento  \\\n",
       "119340  46.956501       3       2  73.561211  2.246882          2.916394   \n",
       "58023   19.892401       4       3  86.961823  2.385298          4.876472   \n",
       "46997    0.956900       4       3  79.168137  2.319516          5.026659   \n",
       "67214    7.424201       4       1  50.321835  0.349119          2.470344   \n",
       "153590  32.275799       4       3  72.893860  1.469779          3.393716   \n",
       "\n",
       "        severidad_real  severidad_discreta  coord_x_etrs89  coord_y_etrs89  \\\n",
       "119340        0.845614                   3        490110.0       4538190.0   \n",
       "58023         0.270908                   1        604950.0       4257480.0   \n",
       "46997         0.412787                   1        617730.0       4243860.0   \n",
       "67214         0.576249                   2        561090.0       4256790.0   \n",
       "153590        0.310006                   1        407340.0       4412550.0   \n",
       "\n",
       "         incendio    provincia  \n",
       "119340  Cogolludo  Guadalajara  \n",
       "58023      Talave     Albacete  \n",
       "46997    Donceles     Albacete  \n",
       "67214       Yeste     Albacete  \n",
       "153590  Montesion       Toledo  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = os.path.join('data', 'fires_transformed.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "df.sample(5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables = ['elevacion', 'slope', 'orientacion_sen', 'orientacion_cos', 'altura', 'lfcc', 'anomalia', 'dpv', 'vel_media_viento']\n",
    "categorical_variables = ['erodi', 'inflam', 'mcroth']\n",
    "variables = numerical_variables + categorical_variables\n",
    "target_real = 'severidad_real'\n",
    "target_discrete = 'severidad_discreta'\n",
    "\n",
    "coords_columns = ['coord_x_etrs89', 'coord_y_etrs89']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params(estimator, X, y, cv, scoring=None, refit=True, **param_grid):\n",
    "    t = time()\n",
    "\n",
    "    # GridSearch over specified parameter values for an estimator\n",
    "    grid_search_cv = GridSearchCV(estimator,\n",
    "                                  param_grid,\n",
    "                                  scoring=scoring,\n",
    "                                  refit=False,  # Disable automatic refit to manually select best estimator\n",
    "                                  cv=cv,\n",
    "                                  verbose=1,\n",
    "                                  n_jobs=10,\n",
    "                                  return_train_score=True).fit(X, y)\n",
    "\n",
    "    cv_results = pd.DataFrame(grid_search_cv.cv_results_)   \n",
    "\n",
    "    # Calculate weighted sizes of each fold\n",
    "    sizes_train = []\n",
    "    sizes_test = []\n",
    "    for train_indexes, test_indexes in cv:\n",
    "        sizes_train.append(len(train_indexes))\n",
    "        sizes_test.append(len(test_indexes))\n",
    "    total_sizes_train = sum(sizes_train)\n",
    "    total_sizes_test = sum(sizes_test)\n",
    "    weighted_sizes_train = [x / total_sizes_train for x in sizes_train]\n",
    "    weighted_sizes_test = [x / total_sizes_test for x in sizes_test]\n",
    "\n",
    "    # Calculate weighted mean score for train and test\n",
    "    weighted_mean_train_score = sum(cv_results[f'split{i}_train_score'] * weighted_sizes_train[i] for i in range(len(weighted_sizes_train)))\n",
    "    cv_results.insert(cv_results.columns.get_loc('mean_train_score'), 'weighted_mean_train_score', weighted_mean_train_score)\n",
    "    weighted_mean_test_score = sum(cv_results[f'split{i}_test_score'] * weighted_sizes_test[i] for i in range(len(weighted_sizes_test)))\n",
    "    cv_results.insert(cv_results.columns.get_loc('mean_test_score'), 'weighted_mean_test_score', weighted_mean_test_score)\n",
    "\n",
    "    # Order params by the weighted mean test score\n",
    "    cv_results = cv_results.sort_values(by='weighted_mean_test_score', ascending=False)\n",
    "    cv_results['rank_test_score'] = range(1, len(cv_results) + 1)\n",
    "\n",
    "    # Drop the results for each validation split\n",
    "    labels = cv_results.filter(regex=\"split\")\n",
    "    cv_results = cv_results.drop(labels, axis=1)\n",
    "\n",
    "    print(f'Time: {round(time()-t, 2)} seg.')\n",
    "    display(cv_results)\n",
    "\n",
    "    \n",
    "    grid_search_cv.best_index_ = cv_results.index[0]\n",
    "    grid_search_cv.best_params_ = cv_results.loc[grid_search_cv.best_index_, 'params']\n",
    "    grid_search_cv.best_score_ = cv_results.loc[grid_search_cv.best_index_, 'weighted_mean_test_score']\n",
    "    # Refit with best params\n",
    "    if refit:\n",
    "        grid_search_cv.best_estimator_ = grid_search_cv.estimator.set_params(**grid_search_cv.best_params_).fit(X, y)\n",
    "    \n",
    "\n",
    "    return grid_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = make_column_transformer(\n",
    "        (StandardScaler(), numerical_variables),\n",
    "        (OneHotEncoder(handle_unknown='ignore'), categorical_variables),\n",
    "        remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclass(new_classification, df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy[df_copy[target_discrete].isin(list(new_classification.keys()))].reset_index(drop=True)\n",
    "    df_copy[target_discrete] = df_copy[target_discrete].map(new_classification, na_action='ignore')\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zona(Enum):\n",
    "    AB_CU = ['Albacete', 'Cuenca']\n",
    "    TO_CR_GU = ['Toledo', 'Ciudad Real', 'Guadalajara']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zona AB_CU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['Donceles', 'Lietor', 'Talave', 'Yeste', 'Ca√±ada_del_Hoyo']\n",
      "Test:  ['Agramon', 'Almansa']\n"
     ]
    }
   ],
   "source": [
    "fire_names = list(df[df['provincia'].isin(Zona.AB_CU.value)]['incendio'].unique())\n",
    "test_fire_names = ['Agramon', 'Almansa']\n",
    "train_fire_names = [x for x in fire_names if x not in test_fire_names]\n",
    "\n",
    "print(f'Train: {train_fire_names}')\n",
    "print(f'Test:  {test_fire_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevacion</th>\n",
       "      <th>erodi</th>\n",
       "      <th>slope</th>\n",
       "      <th>orientacion_sen</th>\n",
       "      <th>orientacion_cos</th>\n",
       "      <th>altura</th>\n",
       "      <th>lfcc</th>\n",
       "      <th>inflam</th>\n",
       "      <th>mcroth</th>\n",
       "      <th>anomalia</th>\n",
       "      <th>dpv</th>\n",
       "      <th>vel_media_viento</th>\n",
       "      <th>severidad_real</th>\n",
       "      <th>severidad_discreta</th>\n",
       "      <th>coord_x_etrs89</th>\n",
       "      <th>coord_y_etrs89</th>\n",
       "      <th>incendio</th>\n",
       "      <th>provincia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>474.993988</td>\n",
       "      <td>1</td>\n",
       "      <td>2.988</td>\n",
       "      <td>0.591536</td>\n",
       "      <td>0.806278</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.578500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78.942978</td>\n",
       "      <td>2.530710</td>\n",
       "      <td>5.199876</td>\n",
       "      <td>0.153908</td>\n",
       "      <td>0</td>\n",
       "      <td>607110.0</td>\n",
       "      <td>4256310.0</td>\n",
       "      <td>Donceles</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472.980011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.177</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>0.074776</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.838201</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78.941406</td>\n",
       "      <td>2.531341</td>\n",
       "      <td>5.200114</td>\n",
       "      <td>0.174595</td>\n",
       "      <td>0</td>\n",
       "      <td>607140.0</td>\n",
       "      <td>4256310.0</td>\n",
       "      <td>Donceles</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466.144989</td>\n",
       "      <td>1</td>\n",
       "      <td>7.510</td>\n",
       "      <td>0.977572</td>\n",
       "      <td>-0.210601</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.604599</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78.936714</td>\n",
       "      <td>2.533220</td>\n",
       "      <td>5.200821</td>\n",
       "      <td>0.176796</td>\n",
       "      <td>0</td>\n",
       "      <td>607230.0</td>\n",
       "      <td>4256310.0</td>\n",
       "      <td>Donceles</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>475.859985</td>\n",
       "      <td>1</td>\n",
       "      <td>3.765</td>\n",
       "      <td>0.762302</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.039700</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78.944611</td>\n",
       "      <td>2.529883</td>\n",
       "      <td>5.199497</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0</td>\n",
       "      <td>607110.0</td>\n",
       "      <td>4256280.0</td>\n",
       "      <td>Donceles</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>473.007996</td>\n",
       "      <td>1</td>\n",
       "      <td>3.792</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.166089</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.137899</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78.943054</td>\n",
       "      <td>2.530514</td>\n",
       "      <td>5.199735</td>\n",
       "      <td>0.202057</td>\n",
       "      <td>0</td>\n",
       "      <td>607140.0</td>\n",
       "      <td>4256280.0</td>\n",
       "      <td>Donceles</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elevacion  erodi  slope  orientacion_sen  orientacion_cos  altura  \\\n",
       "0  474.993988      1  2.988         0.591536         0.806278     4.0   \n",
       "1  472.980011      1  2.177         0.997200         0.074776     8.0   \n",
       "2  466.144989      1  7.510         0.977572        -0.210601     9.0   \n",
       "3  475.859985      1  3.765         0.762302         0.647222     4.0   \n",
       "4  473.007996      1  3.792         0.986111         0.166089     4.0   \n",
       "\n",
       "        lfcc  inflam  mcroth   anomalia       dpv  vel_media_viento  \\\n",
       "0  13.578500       4       3  78.942978  2.530710          5.199876   \n",
       "1  10.838201       4       3  78.941406  2.531341          5.200114   \n",
       "2  17.604599       4       3  78.936714  2.533220          5.200821   \n",
       "3  14.039700       4       3  78.944611  2.529883          5.199497   \n",
       "4  16.137899       4       3  78.943054  2.530514          5.199735   \n",
       "\n",
       "   severidad_real  severidad_discreta  coord_x_etrs89  coord_y_etrs89  \\\n",
       "0        0.153908                   0        607110.0       4256310.0   \n",
       "1        0.174595                   0        607140.0       4256310.0   \n",
       "2        0.176796                   0        607230.0       4256310.0   \n",
       "3        0.168421                   0        607110.0       4256280.0   \n",
       "4        0.202057                   0        607140.0       4256280.0   \n",
       "\n",
       "   incendio provincia  \n",
       "0  Donceles  Albacete  \n",
       "1  Donceles  Albacete  \n",
       "2  Donceles  Albacete  \n",
       "3  Donceles  Albacete  \n",
       "4  Donceles  Albacete  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['incendio'].isin(train_fire_names)].reset_index(drop=True)\n",
    "print(len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4518\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevacion</th>\n",
       "      <th>erodi</th>\n",
       "      <th>slope</th>\n",
       "      <th>orientacion_sen</th>\n",
       "      <th>orientacion_cos</th>\n",
       "      <th>altura</th>\n",
       "      <th>lfcc</th>\n",
       "      <th>inflam</th>\n",
       "      <th>mcroth</th>\n",
       "      <th>anomalia</th>\n",
       "      <th>dpv</th>\n",
       "      <th>vel_media_viento</th>\n",
       "      <th>severidad_real</th>\n",
       "      <th>severidad_discreta</th>\n",
       "      <th>coord_x_etrs89</th>\n",
       "      <th>coord_y_etrs89</th>\n",
       "      <th>incendio</th>\n",
       "      <th>provincia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>482.423004</td>\n",
       "      <td>1</td>\n",
       "      <td>15.401000</td>\n",
       "      <td>0.091827</td>\n",
       "      <td>0.995775</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80.210800</td>\n",
       "      <td>1.464469</td>\n",
       "      <td>2.855457</td>\n",
       "      <td>0.155662</td>\n",
       "      <td>0</td>\n",
       "      <td>615180.0</td>\n",
       "      <td>4257300.0</td>\n",
       "      <td>Agramon</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487.563995</td>\n",
       "      <td>1</td>\n",
       "      <td>20.632999</td>\n",
       "      <td>0.087687</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80.228157</td>\n",
       "      <td>1.463829</td>\n",
       "      <td>2.855017</td>\n",
       "      <td>0.224380</td>\n",
       "      <td>0</td>\n",
       "      <td>614850.0</td>\n",
       "      <td>4257270.0</td>\n",
       "      <td>Agramon</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>486.273987</td>\n",
       "      <td>1</td>\n",
       "      <td>12.380000</td>\n",
       "      <td>-0.129868</td>\n",
       "      <td>0.991531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.1383</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80.207359</td>\n",
       "      <td>1.464057</td>\n",
       "      <td>2.855563</td>\n",
       "      <td>0.308407</td>\n",
       "      <td>1</td>\n",
       "      <td>615120.0</td>\n",
       "      <td>4257270.0</td>\n",
       "      <td>Agramon</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>495.325989</td>\n",
       "      <td>1</td>\n",
       "      <td>21.625000</td>\n",
       "      <td>0.222399</td>\n",
       "      <td>0.974956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4184</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80.210716</td>\n",
       "      <td>1.463563</td>\n",
       "      <td>2.855489</td>\n",
       "      <td>0.207618</td>\n",
       "      <td>0</td>\n",
       "      <td>614970.0</td>\n",
       "      <td>4257240.0</td>\n",
       "      <td>Agramon</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490.188995</td>\n",
       "      <td>1</td>\n",
       "      <td>19.408001</td>\n",
       "      <td>-0.010958</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.4510</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80.206093</td>\n",
       "      <td>1.463614</td>\n",
       "      <td>2.855611</td>\n",
       "      <td>0.292563</td>\n",
       "      <td>1</td>\n",
       "      <td>615030.0</td>\n",
       "      <td>4257240.0</td>\n",
       "      <td>Agramon</td>\n",
       "      <td>Albacete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elevacion  erodi      slope  orientacion_sen  orientacion_cos  altura  \\\n",
       "0  482.423004      1  15.401000         0.091827         0.995775    10.0   \n",
       "1  487.563995      1  20.632999         0.087687         0.996148     1.0   \n",
       "2  486.273987      1  12.380000        -0.129868         0.991531     1.0   \n",
       "3  495.325989      1  21.625000         0.222399         0.974956     1.0   \n",
       "4  490.188995      1  19.408001        -0.010958         0.999940     4.0   \n",
       "\n",
       "      lfcc  inflam  mcroth   anomalia       dpv  vel_media_viento  \\\n",
       "0  13.2000       3       3  80.210800  1.464469          2.855457   \n",
       "1   0.7326       3       3  80.228157  1.463829          2.855017   \n",
       "2   5.1383       3       3  80.207359  1.464057          2.855563   \n",
       "3   1.4184       3       3  80.210716  1.463563          2.855489   \n",
       "4   7.4510       3       3  80.206093  1.463614          2.855611   \n",
       "\n",
       "   severidad_real  severidad_discreta  coord_x_etrs89  coord_y_etrs89  \\\n",
       "0        0.155662                   0        615180.0       4257300.0   \n",
       "1        0.224380                   0        614850.0       4257270.0   \n",
       "2        0.308407                   1        615120.0       4257270.0   \n",
       "3        0.207618                   0        614970.0       4257240.0   \n",
       "4        0.292563                   1        615030.0       4257240.0   \n",
       "\n",
       "  incendio provincia  \n",
       "0  Agramon  Albacete  \n",
       "1  Agramon  Albacete  \n",
       "2  Agramon  Albacete  \n",
       "3  Agramon  Albacete  \n",
       "4  Agramon  Albacete  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[df['incendio'].isin(test_fire_names)].reset_index(drop=True)\n",
    "print(len(df_test))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baja - Alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classification = {0:0, 1:0, 2:1, 3:1}\n",
    "\n",
    "df_train_reclass = reclass(new_classification, df_train)\n",
    "df_test_reclass = reclass(new_classification, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_reclass[variables]\n",
    "y_train = df_train_reclass[target_discrete]\n",
    "\n",
    "X_test = df_test_reclass[variables]\n",
    "y_test = df_test_reclass[target_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Train: 44837\tTest:43211\n",
      "Fold 1: Train: 81916\tTest:6132\n",
      "Fold 2: Train: 79397\tTest:8651\n",
      "Fold 3: Train: 60978\tTest:27070\n",
      "Fold 4: Train: 85064\tTest:2984\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "\n",
    "for name in train_fire_names:\n",
    "    fold_train_names = [x for x in train_fire_names if x != name]\n",
    "    fold_test_name = [x for x in train_fire_names if x == name]\n",
    "\n",
    "    fold_train_indices = df_train_reclass[(df_train_reclass['incendio'].isin(fold_train_names))].index\n",
    "    fold_test_indices = df_train_reclass[df_train_reclass['incendio'].isin(fold_test_name)].index\n",
    "    folds.append((fold_train_indices, fold_test_indices))\n",
    "\n",
    "[print(f'Fold {i}: Train: {x.size}\\tTest:{y.size}') for i, (x, y) in enumerate(folds)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Time: 72.2 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.581760</td>\n",
       "      <td>3.446838</td>\n",
       "      <td>0.102133</td>\n",
       "      <td>0.072840</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.279116</td>\n",
       "      <td>0.234977</td>\n",
       "      <td>0.212433</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613411</td>\n",
       "      <td>0.616904</td>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.645056</td>\n",
       "      <td>1.540839</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>0.086880</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.276766</td>\n",
       "      <td>0.236804</td>\n",
       "      <td>0.211521</td>\n",
       "      <td>2</td>\n",
       "      <td>0.613490</td>\n",
       "      <td>0.616999</td>\n",
       "      <td>0.032064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.607081</td>\n",
       "      <td>1.625180</td>\n",
       "      <td>0.106829</td>\n",
       "      <td>0.077009</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.261599</td>\n",
       "      <td>0.262618</td>\n",
       "      <td>0.293753</td>\n",
       "      <td>3</td>\n",
       "      <td>0.617506</td>\n",
       "      <td>0.621151</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.846117</td>\n",
       "      <td>3.071219</td>\n",
       "      <td>0.114709</td>\n",
       "      <td>0.084010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.260285</td>\n",
       "      <td>0.256382</td>\n",
       "      <td>0.286865</td>\n",
       "      <td>4</td>\n",
       "      <td>0.617538</td>\n",
       "      <td>0.621086</td>\n",
       "      <td>0.030564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.008638</td>\n",
       "      <td>3.151030</td>\n",
       "      <td>0.112022</td>\n",
       "      <td>0.084062</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.256604</td>\n",
       "      <td>0.286938</td>\n",
       "      <td>5</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>0.623991</td>\n",
       "      <td>0.028636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.558689</td>\n",
       "      <td>2.920727</td>\n",
       "      <td>0.108164</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.251835</td>\n",
       "      <td>0.254709</td>\n",
       "      <td>0.283090</td>\n",
       "      <td>6</td>\n",
       "      <td>0.620402</td>\n",
       "      <td>0.623958</td>\n",
       "      <td>0.028364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.713383</td>\n",
       "      <td>0.883931</td>\n",
       "      <td>0.054541</td>\n",
       "      <td>0.046965</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.251536</td>\n",
       "      <td>0.255034</td>\n",
       "      <td>0.286305</td>\n",
       "      <td>7</td>\n",
       "      <td>0.620343</td>\n",
       "      <td>0.623852</td>\n",
       "      <td>0.027707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.614572</td>\n",
       "      <td>1.598248</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.251325</td>\n",
       "      <td>0.260935</td>\n",
       "      <td>0.295594</td>\n",
       "      <td>8</td>\n",
       "      <td>0.618037</td>\n",
       "      <td>0.621760</td>\n",
       "      <td>0.030729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.704830</td>\n",
       "      <td>2.933852</td>\n",
       "      <td>0.125710</td>\n",
       "      <td>0.101437</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.251293</td>\n",
       "      <td>0.256540</td>\n",
       "      <td>0.294301</td>\n",
       "      <td>9</td>\n",
       "      <td>0.620207</td>\n",
       "      <td>0.623776</td>\n",
       "      <td>0.028822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.731250</td>\n",
       "      <td>1.648340</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.105495</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.251028</td>\n",
       "      <td>0.257521</td>\n",
       "      <td>0.292268</td>\n",
       "      <td>10</td>\n",
       "      <td>0.617709</td>\n",
       "      <td>0.621407</td>\n",
       "      <td>0.030965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.468807</td>\n",
       "      <td>1.553552</td>\n",
       "      <td>0.125559</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.250677</td>\n",
       "      <td>0.260993</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>11</td>\n",
       "      <td>0.618417</td>\n",
       "      <td>0.622220</td>\n",
       "      <td>0.031048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.639430</td>\n",
       "      <td>1.599583</td>\n",
       "      <td>0.130157</td>\n",
       "      <td>0.109565</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.249915</td>\n",
       "      <td>0.258881</td>\n",
       "      <td>0.295248</td>\n",
       "      <td>12</td>\n",
       "      <td>0.618656</td>\n",
       "      <td>0.622279</td>\n",
       "      <td>0.030270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.928704</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.237645</td>\n",
       "      <td>0.127898</td>\n",
       "      <td>0.179567</td>\n",
       "      <td>13</td>\n",
       "      <td>0.499733</td>\n",
       "      <td>0.509428</td>\n",
       "      <td>0.047591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.015995</td>\n",
       "      <td>0.331441</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.030409</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.237645</td>\n",
       "      <td>0.127898</td>\n",
       "      <td>0.179567</td>\n",
       "      <td>14</td>\n",
       "      <td>0.499733</td>\n",
       "      <td>0.509428</td>\n",
       "      <td>0.047591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.867247</td>\n",
       "      <td>0.264449</td>\n",
       "      <td>0.049983</td>\n",
       "      <td>0.024252</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.237597</td>\n",
       "      <td>0.127423</td>\n",
       "      <td>0.179516</td>\n",
       "      <td>15</td>\n",
       "      <td>0.499803</td>\n",
       "      <td>0.509513</td>\n",
       "      <td>0.047678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.975379</td>\n",
       "      <td>0.346812</td>\n",
       "      <td>0.049539</td>\n",
       "      <td>0.035464</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.237597</td>\n",
       "      <td>0.127423</td>\n",
       "      <td>0.179516</td>\n",
       "      <td>16</td>\n",
       "      <td>0.499803</td>\n",
       "      <td>0.509513</td>\n",
       "      <td>0.047678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.885365</td>\n",
       "      <td>0.275952</td>\n",
       "      <td>0.048089</td>\n",
       "      <td>0.029996</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.237548</td>\n",
       "      <td>0.127403</td>\n",
       "      <td>0.179479</td>\n",
       "      <td>17</td>\n",
       "      <td>0.499766</td>\n",
       "      <td>0.509468</td>\n",
       "      <td>0.047617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.900967</td>\n",
       "      <td>0.257475</td>\n",
       "      <td>0.045157</td>\n",
       "      <td>0.036943</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.237548</td>\n",
       "      <td>0.127403</td>\n",
       "      <td>0.179479</td>\n",
       "      <td>18</td>\n",
       "      <td>0.499766</td>\n",
       "      <td>0.509468</td>\n",
       "      <td>0.047617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.967803</td>\n",
       "      <td>0.301868</td>\n",
       "      <td>0.045267</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.127313</td>\n",
       "      <td>0.179313</td>\n",
       "      <td>19</td>\n",
       "      <td>0.499788</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>0.047609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.938395</td>\n",
       "      <td>0.301494</td>\n",
       "      <td>0.052694</td>\n",
       "      <td>0.029784</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.127313</td>\n",
       "      <td>0.179313</td>\n",
       "      <td>20</td>\n",
       "      <td>0.499788</td>\n",
       "      <td>0.509488</td>\n",
       "      <td>0.047609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.057338</td>\n",
       "      <td>0.388721</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.026216</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.229294</td>\n",
       "      <td>0.127401</td>\n",
       "      <td>0.173688</td>\n",
       "      <td>21</td>\n",
       "      <td>0.499221</td>\n",
       "      <td>0.508802</td>\n",
       "      <td>0.046904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989443</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>0.028208</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.229294</td>\n",
       "      <td>0.127401</td>\n",
       "      <td>0.173688</td>\n",
       "      <td>22</td>\n",
       "      <td>0.499211</td>\n",
       "      <td>0.508794</td>\n",
       "      <td>0.046920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.258368</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.151873</td>\n",
       "      <td>0.098705</td>\n",
       "      <td>0.122120</td>\n",
       "      <td>23</td>\n",
       "      <td>0.494866</td>\n",
       "      <td>0.504051</td>\n",
       "      <td>0.044532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.762999</td>\n",
       "      <td>0.196162</td>\n",
       "      <td>0.040828</td>\n",
       "      <td>0.023324</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.151873</td>\n",
       "      <td>0.098705</td>\n",
       "      <td>0.122120</td>\n",
       "      <td>24</td>\n",
       "      <td>0.494866</td>\n",
       "      <td>0.504051</td>\n",
       "      <td>0.044532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       12.581760      3.446838         0.102133        0.072840   \n",
       "1        6.645056      1.540839         0.109761        0.086880   \n",
       "5        6.607081      1.625180         0.106829        0.077009   \n",
       "7       12.846117      3.071219         0.114709        0.084010   \n",
       "11      13.008638      3.151030         0.112022        0.084062   \n",
       "19      12.558689      2.920727         0.108164        0.095070   \n",
       "23       7.713383      0.883931         0.054541        0.046965   \n",
       "9        6.614572      1.598248         0.117667        0.089300   \n",
       "15      12.704830      2.933852         0.125710        0.101437   \n",
       "13       6.731250      1.648340         0.128906        0.105495   \n",
       "17       6.468807      1.553552         0.125559        0.092809   \n",
       "21       6.639430      1.599583         0.130157        0.109565   \n",
       "8        0.928704      0.281545         0.043216        0.028846   \n",
       "10       1.015995      0.331441         0.045593        0.030409   \n",
       "20       0.867247      0.264449         0.049983        0.024252   \n",
       "22       0.975379      0.346812         0.049539        0.035464   \n",
       "18       0.885365      0.275952         0.048089        0.029996   \n",
       "16       0.900967      0.257475         0.045157        0.036943   \n",
       "12       0.967803      0.301868         0.045267        0.027162   \n",
       "14       0.938395      0.301494         0.052694        0.029784   \n",
       "6        1.057338      0.388721         0.035680        0.026216   \n",
       "4        0.989443      0.297019         0.038523        0.028208   \n",
       "2        0.794250      0.258368         0.041886        0.024803   \n",
       "0        0.762999      0.196162         0.040828        0.023324   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__max_iter  \\\n",
       "3                         0.01                                200   \n",
       "1                         0.01                                100   \n",
       "5                          0.1                                100   \n",
       "7                          0.1                                200   \n",
       "11                           1                                200   \n",
       "19                           5                                200   \n",
       "23                          10                                200   \n",
       "9                            1                                100   \n",
       "15                           2                                200   \n",
       "13                           2                                100   \n",
       "17                           5                                100   \n",
       "21                          10                                100   \n",
       "8                            1                                100   \n",
       "10                           1                                200   \n",
       "20                          10                                100   \n",
       "22                          10                                200   \n",
       "18                           5                                200   \n",
       "16                           5                                100   \n",
       "12                           2                                100   \n",
       "14                           2                                200   \n",
       "6                          0.1                                200   \n",
       "4                          0.1                                100   \n",
       "2                         0.01                                200   \n",
       "0                         0.01                                100   \n",
       "\n",
       "   param_polynomialfeatures__degree  \\\n",
       "3                                 2   \n",
       "1                                 2   \n",
       "5                                 2   \n",
       "7                                 2   \n",
       "11                                2   \n",
       "19                                2   \n",
       "23                                2   \n",
       "9                                 2   \n",
       "15                                2   \n",
       "13                                2   \n",
       "17                                2   \n",
       "21                                2   \n",
       "8                                 1   \n",
       "10                                1   \n",
       "20                                1   \n",
       "22                                1   \n",
       "18                                1   \n",
       "16                                1   \n",
       "12                                1   \n",
       "14                                1   \n",
       "6                                 1   \n",
       "4                                 1   \n",
       "2                                 1   \n",
       "0                                 1   \n",
       "\n",
       "                                               params  \\\n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "1   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "7   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "11  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "19  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "23  {'logisticregression__C': 10, 'logisticregress...   \n",
       "9   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "13  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "17  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "21  {'logisticregression__C': 10, 'logisticregress...   \n",
       "8   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "10  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "20  {'logisticregression__C': 10, 'logisticregress...   \n",
       "22  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "12  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "14  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "2   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "0   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "3                   0.279116         0.234977        0.212433   \n",
       "1                   0.276766         0.236804        0.211521   \n",
       "5                   0.261599         0.262618        0.293753   \n",
       "7                   0.260285         0.256382        0.286865   \n",
       "11                  0.252900         0.256604        0.286938   \n",
       "19                  0.251835         0.254709        0.283090   \n",
       "23                  0.251536         0.255034        0.286305   \n",
       "9                   0.251325         0.260935        0.295594   \n",
       "15                  0.251293         0.256540        0.294301   \n",
       "13                  0.251028         0.257521        0.292268   \n",
       "17                  0.250677         0.260993        0.299065   \n",
       "21                  0.249915         0.258881        0.295248   \n",
       "8                   0.237645         0.127898        0.179567   \n",
       "10                  0.237645         0.127898        0.179567   \n",
       "20                  0.237597         0.127423        0.179516   \n",
       "22                  0.237597         0.127423        0.179516   \n",
       "18                  0.237548         0.127403        0.179479   \n",
       "16                  0.237548         0.127403        0.179479   \n",
       "12                  0.237327         0.127313        0.179313   \n",
       "14                  0.237327         0.127313        0.179313   \n",
       "6                   0.229294         0.127401        0.173688   \n",
       "4                   0.229294         0.127401        0.173688   \n",
       "2                   0.151873         0.098705        0.122120   \n",
       "0                   0.151873         0.098705        0.122120   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "3                 1                   0.613411          0.616904   \n",
       "1                 2                   0.613490          0.616999   \n",
       "5                 3                   0.617506          0.621151   \n",
       "7                 4                   0.617538          0.621086   \n",
       "11                5                   0.620448          0.623991   \n",
       "19                6                   0.620402          0.623958   \n",
       "23                7                   0.620343          0.623852   \n",
       "9                 8                   0.618037          0.621760   \n",
       "15                9                   0.620207          0.623776   \n",
       "13               10                   0.617709          0.621407   \n",
       "17               11                   0.618417          0.622220   \n",
       "21               12                   0.618656          0.622279   \n",
       "8                13                   0.499733          0.509428   \n",
       "10               14                   0.499733          0.509428   \n",
       "20               15                   0.499803          0.509513   \n",
       "22               16                   0.499803          0.509513   \n",
       "18               17                   0.499766          0.509468   \n",
       "16               18                   0.499766          0.509468   \n",
       "12               19                   0.499788          0.509488   \n",
       "14               20                   0.499788          0.509488   \n",
       "6                21                   0.499221          0.508802   \n",
       "4                22                   0.499211          0.508794   \n",
       "2                23                   0.494866          0.504051   \n",
       "0                24                   0.494866          0.504051   \n",
       "\n",
       "    std_train_score  \n",
       "3          0.032299  \n",
       "1          0.032064  \n",
       "5          0.030918  \n",
       "7          0.030564  \n",
       "11         0.028636  \n",
       "19         0.028364  \n",
       "23         0.027707  \n",
       "9          0.030729  \n",
       "15         0.028822  \n",
       "13         0.030965  \n",
       "17         0.031048  \n",
       "21         0.030270  \n",
       "8          0.047591  \n",
       "10         0.047591  \n",
       "20         0.047678  \n",
       "22         0.047678  \n",
       "18         0.047617  \n",
       "16         0.047617  \n",
       "12         0.047609  \n",
       "14         0.047609  \n",
       "6          0.046904  \n",
       "4          0.046920  \n",
       "2          0.044532  \n",
       "0          0.044532  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "logistic_reg = LogisticRegression(random_state=seed)\n",
    "logistic_reg_pipeline = make_pipeline(preprocessing, poly, logistic_reg)\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "    'logisticregression__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "logistic_reg_gs = optimize_params(logistic_reg_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Time: 363.48 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>param_kneighborsclassifier__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094468</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>11.019151</td>\n",
       "      <td>7.306364</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.262815</td>\n",
       "      <td>0.234943</td>\n",
       "      <td>0.081457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.752396</td>\n",
       "      <td>0.754858</td>\n",
       "      <td>0.023863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102550</td>\n",
       "      <td>0.017376</td>\n",
       "      <td>11.190759</td>\n",
       "      <td>7.207277</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.262774</td>\n",
       "      <td>0.234926</td>\n",
       "      <td>0.081459</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070286</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>10.967528</td>\n",
       "      <td>7.283043</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.246041</td>\n",
       "      <td>0.217094</td>\n",
       "      <td>0.083649</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067112</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>11.089795</td>\n",
       "      <td>7.197760</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.223212</td>\n",
       "      <td>0.194226</td>\n",
       "      <td>0.102266</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.070043</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>11.861816</td>\n",
       "      <td>8.174742</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.218032</td>\n",
       "      <td>0.191113</td>\n",
       "      <td>0.115743</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063813</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>12.493296</td>\n",
       "      <td>8.545294</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.217664</td>\n",
       "      <td>0.195929</td>\n",
       "      <td>0.120592</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059519</td>\n",
       "      <td>0.011422</td>\n",
       "      <td>12.525888</td>\n",
       "      <td>8.544546</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.214578</td>\n",
       "      <td>0.193215</td>\n",
       "      <td>0.121494</td>\n",
       "      <td>7</td>\n",
       "      <td>0.643268</td>\n",
       "      <td>0.646244</td>\n",
       "      <td>0.036226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.063474</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>11.646032</td>\n",
       "      <td>7.701969</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.211552</td>\n",
       "      <td>0.184784</td>\n",
       "      <td>0.116566</td>\n",
       "      <td>8</td>\n",
       "      <td>0.657522</td>\n",
       "      <td>0.660426</td>\n",
       "      <td>0.034543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073844</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>12.083043</td>\n",
       "      <td>7.994644</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.210342</td>\n",
       "      <td>0.182504</td>\n",
       "      <td>0.088072</td>\n",
       "      <td>9</td>\n",
       "      <td>0.693123</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>0.031608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057894</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>10.942424</td>\n",
       "      <td>6.961068</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.206304</td>\n",
       "      <td>0.177098</td>\n",
       "      <td>0.104915</td>\n",
       "      <td>10</td>\n",
       "      <td>0.675907</td>\n",
       "      <td>0.679097</td>\n",
       "      <td>0.032709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.094468      0.017014        11.019151        7.306364   \n",
       "1       0.102550      0.017376        11.190759        7.207277   \n",
       "3       0.070286      0.011529        10.967528        7.283043   \n",
       "5       0.067112      0.015274        11.089795        7.197760   \n",
       "7       0.070043      0.008606        11.861816        8.174742   \n",
       "9       0.063813      0.014213        12.493296        8.545294   \n",
       "8       0.059519      0.011422        12.525888        8.544546   \n",
       "6       0.063474      0.014777        11.646032        7.701969   \n",
       "2       0.073844      0.017060        12.083043        7.994644   \n",
       "4       0.057894      0.014691        10.942424        6.961068   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors param_kneighborsclassifier__weights  \\\n",
       "0                                       5                             uniform   \n",
       "1                                       5                            distance   \n",
       "3                                      10                            distance   \n",
       "5                                      20                            distance   \n",
       "7                                      50                            distance   \n",
       "9                                     100                            distance   \n",
       "8                                     100                             uniform   \n",
       "6                                      50                             uniform   \n",
       "2                                      10                             uniform   \n",
       "4                                      20                             uniform   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "1  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "3  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "5  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "7  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "9  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "8  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "6  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "2  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "4  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "\n",
       "   weighted_mean_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0                  0.262815         0.234943        0.081457                1   \n",
       "1                  0.262774         0.234926        0.081459                2   \n",
       "3                  0.246041         0.217094        0.083649                3   \n",
       "5                  0.223212         0.194226        0.102266                4   \n",
       "7                  0.218032         0.191113        0.115743                5   \n",
       "9                  0.217664         0.195929        0.120592                6   \n",
       "8                  0.214578         0.193215        0.121494                7   \n",
       "6                  0.211552         0.184784        0.116566                8   \n",
       "2                  0.210342         0.182504        0.088072                9   \n",
       "4                  0.206304         0.177098        0.104915               10   \n",
       "\n",
       "   weighted_mean_train_score  mean_train_score  std_train_score  \n",
       "0                   0.752396          0.754858         0.023863  \n",
       "1                   1.000000          1.000000         0.000000  \n",
       "3                   1.000000          1.000000         0.000000  \n",
       "5                   1.000000          1.000000         0.000000  \n",
       "7                   1.000000          1.000000         0.000000  \n",
       "9                   1.000000          1.000000         0.000000  \n",
       "8                   0.643268          0.646244         0.036226  \n",
       "6                   0.657522          0.660426         0.034543  \n",
       "2                   0.693123          0.696349         0.031608  \n",
       "4                   0.675907          0.679097         0.032709  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_neighbors_class = KNeighborsClassifier()\n",
    "k_neighbours_class_pipeline = make_pipeline(preprocessing, k_neighbors_class)\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_neighbors_class_gs = optimize_params(k_neighbours_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "Time: 163.53 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_decisiontreeclassifier__ccp_alpha</th>\n",
       "      <th>param_decisiontreeclassifier__criterion</th>\n",
       "      <th>param_decisiontreeclassifier__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.605676</td>\n",
       "      <td>0.853545</td>\n",
       "      <td>0.023026</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.347322</td>\n",
       "      <td>0.278272</td>\n",
       "      <td>0.132708</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.328887</td>\n",
       "      <td>0.795890</td>\n",
       "      <td>0.021455</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.320509</td>\n",
       "      <td>0.269573</td>\n",
       "      <td>0.162627</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829910</td>\n",
       "      <td>0.831715</td>\n",
       "      <td>0.028756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.140234</td>\n",
       "      <td>1.018650</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.284627</td>\n",
       "      <td>0.231587</td>\n",
       "      <td>0.103254</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3.344098</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.257428</td>\n",
       "      <td>0.197025</td>\n",
       "      <td>0.152004</td>\n",
       "      <td>4</td>\n",
       "      <td>0.772064</td>\n",
       "      <td>0.776737</td>\n",
       "      <td>0.047755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.804013</td>\n",
       "      <td>0.631619</td>\n",
       "      <td>0.023850</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>0</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.248087</td>\n",
       "      <td>0.215611</td>\n",
       "      <td>0.085293</td>\n",
       "      <td>5</td>\n",
       "      <td>0.705555</td>\n",
       "      <td>0.708959</td>\n",
       "      <td>0.033367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.715225</td>\n",
       "      <td>0.349645</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.01, 'd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146</td>\n",
       "      <td>0.378726</td>\n",
       "      <td>0.399790</td>\n",
       "      <td>0.261869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.713411</td>\n",
       "      <td>0.361648</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.01, 'd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>0.378726</td>\n",
       "      <td>0.399790</td>\n",
       "      <td>0.261869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.708162</td>\n",
       "      <td>0.374792</td>\n",
       "      <td>0.023550</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.01, 'd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148</td>\n",
       "      <td>0.378726</td>\n",
       "      <td>0.399790</td>\n",
       "      <td>0.261869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2.330711</td>\n",
       "      <td>0.554216</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.01, 'd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149</td>\n",
       "      <td>0.378726</td>\n",
       "      <td>0.399790</td>\n",
       "      <td>0.261869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2.440192</td>\n",
       "      <td>0.460026</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "27        3.605676      0.853545         0.023026        0.014423   \n",
       "28        3.328887      0.795890         0.021455        0.016237   \n",
       "12        4.140234      1.018650         0.021164        0.007880   \n",
       "58        3.344098      0.805360         0.019968        0.010257   \n",
       "10        2.804013      0.631619         0.023850        0.016215   \n",
       "..             ...           ...              ...             ...   \n",
       "111       1.715225      0.349645         0.021541        0.012108   \n",
       "112       1.713411      0.361648         0.019590        0.010236   \n",
       "113       1.708162      0.374792         0.023550        0.015811   \n",
       "114       2.330711      0.554216         0.023965        0.016109   \n",
       "149       2.440192      0.460026         0.016281        0.017911   \n",
       "\n",
       "    param_decisiontreeclassifier__ccp_alpha  \\\n",
       "27                                        0   \n",
       "28                                        0   \n",
       "12                                        0   \n",
       "58                                   0.0001   \n",
       "10                                        0   \n",
       "..                                      ...   \n",
       "111                                    0.01   \n",
       "112                                    0.01   \n",
       "113                                    0.01   \n",
       "114                                    0.01   \n",
       "149                                     0.1   \n",
       "\n",
       "    param_decisiontreeclassifier__criterion  \\\n",
       "27                                     gini   \n",
       "28                                     gini   \n",
       "12                                  entropy   \n",
       "58                                     gini   \n",
       "10                                  entropy   \n",
       "..                                      ...   \n",
       "111                                    gini   \n",
       "112                                    gini   \n",
       "113                                    gini   \n",
       "114                                    gini   \n",
       "149                                    gini   \n",
       "\n",
       "    param_decisiontreeclassifier__max_depth  \\\n",
       "27                                     None   \n",
       "28                                     None   \n",
       "12                                     None   \n",
       "58                                     None   \n",
       "10                                       10   \n",
       "..                                      ...   \n",
       "111                                       7   \n",
       "112                                       7   \n",
       "113                                       7   \n",
       "114                                      10   \n",
       "149                                    None   \n",
       "\n",
       "                                                params  \\\n",
       "27   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "28   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "12   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "58   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "10   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "..                                                 ...   \n",
       "111  {'decisiontreeclassifier__ccp_alpha': 0.01, 'd...   \n",
       "112  {'decisiontreeclassifier__ccp_alpha': 0.01, 'd...   \n",
       "113  {'decisiontreeclassifier__ccp_alpha': 0.01, 'd...   \n",
       "114  {'decisiontreeclassifier__ccp_alpha': 0.01, 'd...   \n",
       "149  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "27                   0.347322         0.278272        0.132708   \n",
       "28                   0.320509         0.269573        0.162627   \n",
       "12                   0.284627         0.231587        0.103254   \n",
       "58                   0.257428         0.197025        0.152004   \n",
       "10                   0.248087         0.215611        0.085293   \n",
       "..                        ...              ...             ...   \n",
       "111                  0.000000         0.000000        0.000000   \n",
       "112                  0.000000         0.000000        0.000000   \n",
       "113                  0.000000         0.000000        0.000000   \n",
       "114                  0.000000         0.000000        0.000000   \n",
       "149                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "27                 1                   1.000000          1.000000   \n",
       "28                 2                   0.829910          0.831715   \n",
       "12                 3                   1.000000          1.000000   \n",
       "58                 4                   0.772064          0.776737   \n",
       "10                 5                   0.705555          0.708959   \n",
       "..               ...                        ...               ...   \n",
       "111              146                   0.378726          0.399790   \n",
       "112              147                   0.378726          0.399790   \n",
       "113              148                   0.378726          0.399790   \n",
       "114              149                   0.378726          0.399790   \n",
       "149              150                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "27          0.000000  \n",
       "28          0.028756  \n",
       "12          0.000000  \n",
       "58          0.047755  \n",
       "10          0.033367  \n",
       "..               ...  \n",
       "111         0.261869  \n",
       "112         0.261869  \n",
       "113         0.261869  \n",
       "114         0.261869  \n",
       "149         0.000000  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_class = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree_class_pipeline = make_pipeline(preprocessing, decision_tree_class)\n",
    "\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 50, 200],\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "decision_tree_class_gs = optimize_params(decision_tree_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Time: 132.67 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.518290</td>\n",
       "      <td>1.683799</td>\n",
       "      <td>0.048313</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>0.094095</td>\n",
       "      <td>0.108967</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986199</td>\n",
       "      <td>0.986304</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.558946</td>\n",
       "      <td>4.162733</td>\n",
       "      <td>0.080495</td>\n",
       "      <td>0.052878</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.041496</td>\n",
       "      <td>0.043364</td>\n",
       "      <td>0.042190</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>0.998243</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.443904</td>\n",
       "      <td>3.300899</td>\n",
       "      <td>0.068504</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.037158</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998331</td>\n",
       "      <td>0.998357</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.629050</td>\n",
       "      <td>1.489086</td>\n",
       "      <td>0.045765</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.056514</td>\n",
       "      <td>0.060139</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985886</td>\n",
       "      <td>0.985989</td>\n",
       "      <td>0.003061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.236640</td>\n",
       "      <td>0.441232</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>0.023574</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>5</td>\n",
       "      <td>0.566415</td>\n",
       "      <td>0.572303</td>\n",
       "      <td>0.087398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.394127</td>\n",
       "      <td>0.682383</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>6</td>\n",
       "      <td>0.638086</td>\n",
       "      <td>0.642972</td>\n",
       "      <td>0.066353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.442231</td>\n",
       "      <td>8.484132</td>\n",
       "      <td>0.116748</td>\n",
       "      <td>0.096845</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.030133</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25.288487</td>\n",
       "      <td>4.141622</td>\n",
       "      <td>0.084779</td>\n",
       "      <td>0.090989</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.687460</td>\n",
       "      <td>0.529857</td>\n",
       "      <td>0.034121</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>9</td>\n",
       "      <td>0.565881</td>\n",
       "      <td>0.572853</td>\n",
       "      <td>0.076679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.077826</td>\n",
       "      <td>2.256019</td>\n",
       "      <td>0.094580</td>\n",
       "      <td>0.076371</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>10</td>\n",
       "      <td>0.566515</td>\n",
       "      <td>0.571515</td>\n",
       "      <td>0.090489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.374728</td>\n",
       "      <td>1.004538</td>\n",
       "      <td>0.056628</td>\n",
       "      <td>0.039876</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>11</td>\n",
       "      <td>0.570309</td>\n",
       "      <td>0.573988</td>\n",
       "      <td>0.092995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.424496</td>\n",
       "      <td>1.705427</td>\n",
       "      <td>0.092977</td>\n",
       "      <td>0.073350</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>12</td>\n",
       "      <td>0.463172</td>\n",
       "      <td>0.469792</td>\n",
       "      <td>0.153582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.065312</td>\n",
       "      <td>1.413443</td>\n",
       "      <td>0.080921</td>\n",
       "      <td>0.059018</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>13</td>\n",
       "      <td>0.466829</td>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.152507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.501802</td>\n",
       "      <td>1.610985</td>\n",
       "      <td>0.066542</td>\n",
       "      <td>0.048071</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>14</td>\n",
       "      <td>0.645170</td>\n",
       "      <td>0.649946</td>\n",
       "      <td>0.065702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.582714</td>\n",
       "      <td>2.959717</td>\n",
       "      <td>0.096756</td>\n",
       "      <td>0.077118</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>15</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>0.655233</td>\n",
       "      <td>0.066139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.507709</td>\n",
       "      <td>1.124141</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>16</td>\n",
       "      <td>0.568581</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.076109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.942234</td>\n",
       "      <td>0.586541</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>17</td>\n",
       "      <td>0.648929</td>\n",
       "      <td>0.651832</td>\n",
       "      <td>0.058873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.279419</td>\n",
       "      <td>1.506769</td>\n",
       "      <td>0.059276</td>\n",
       "      <td>0.046546</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.654330</td>\n",
       "      <td>0.657074</td>\n",
       "      <td>0.065947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.690994</td>\n",
       "      <td>0.329260</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.440124</td>\n",
       "      <td>0.448864</td>\n",
       "      <td>0.153237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.320586</td>\n",
       "      <td>0.607047</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.454819</td>\n",
       "      <td>0.462987</td>\n",
       "      <td>0.148709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.054814</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>0.065489</td>\n",
       "      <td>0.045384</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.435903</td>\n",
       "      <td>0.445772</td>\n",
       "      <td>0.150376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.948987</td>\n",
       "      <td>3.304147</td>\n",
       "      <td>0.101709</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.646162</td>\n",
       "      <td>0.650978</td>\n",
       "      <td>0.065799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.014386</td>\n",
       "      <td>2.529310</td>\n",
       "      <td>0.101251</td>\n",
       "      <td>0.072235</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.556344</td>\n",
       "      <td>0.562496</td>\n",
       "      <td>0.088151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.347973</td>\n",
       "      <td>0.268411</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.464480</td>\n",
       "      <td>0.470868</td>\n",
       "      <td>0.149899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        7.518290      1.683799         0.048313        0.034707   \n",
       "10      18.558946      4.162733         0.080495        0.052878   \n",
       "22      15.443904      3.300899         0.068504        0.044059   \n",
       "21       6.629050      1.489086         0.045765        0.034063   \n",
       "15       2.236640      0.441232         0.037074        0.023574   \n",
       "6        3.394127      0.682383         0.039877        0.020112   \n",
       "11      37.442231      8.484132         0.116748        0.096845   \n",
       "23      25.288487      4.141622         0.084779        0.090989   \n",
       "3        2.687460      0.529857         0.034121        0.019676   \n",
       "17      11.077826      2.256019         0.094580        0.076371   \n",
       "16       5.374728      1.004538         0.056628        0.039876   \n",
       "2        8.424496      1.705427         0.092977        0.073350   \n",
       "14       7.065312      1.413443         0.080921        0.059018   \n",
       "7        8.501802      1.610985         0.066542        0.048071   \n",
       "20      14.582714      2.959717         0.096756        0.077118   \n",
       "4        6.507709      1.124141         0.054396        0.038750   \n",
       "18       2.942234      0.586541         0.038504        0.024962   \n",
       "19       7.279419      1.506769         0.059276        0.046546   \n",
       "0        1.690994      0.329260         0.038204        0.024865   \n",
       "13       3.320586      0.607047         0.050910        0.032945   \n",
       "1        4.054814      0.618020         0.065489        0.045384   \n",
       "8       16.948987      3.304147         0.101709        0.072163   \n",
       "5       13.014386      2.529310         0.101251        0.072235   \n",
       "12       1.347973      0.268411         0.035655        0.022673   \n",
       "\n",
       "   param_randomforestclassifier__criterion  \\\n",
       "9                                  entropy   \n",
       "10                                 entropy   \n",
       "22                                    gini   \n",
       "21                                    gini   \n",
       "15                                    gini   \n",
       "6                                  entropy   \n",
       "11                                 entropy   \n",
       "23                                    gini   \n",
       "3                                  entropy   \n",
       "17                                    gini   \n",
       "16                                    gini   \n",
       "2                                  entropy   \n",
       "14                                    gini   \n",
       "7                                  entropy   \n",
       "20                                    gini   \n",
       "4                                  entropy   \n",
       "18                                    gini   \n",
       "19                                    gini   \n",
       "0                                  entropy   \n",
       "13                                    gini   \n",
       "1                                  entropy   \n",
       "8                                  entropy   \n",
       "5                                  entropy   \n",
       "12                                    gini   \n",
       "\n",
       "   param_randomforestclassifier__max_depth  \\\n",
       "9                                     None   \n",
       "10                                    None   \n",
       "22                                    None   \n",
       "21                                    None   \n",
       "15                                       5   \n",
       "6                                        7   \n",
       "11                                    None   \n",
       "23                                    None   \n",
       "3                                        5   \n",
       "17                                       5   \n",
       "16                                       5   \n",
       "2                                        3   \n",
       "14                                       3   \n",
       "7                                        7   \n",
       "20                                       7   \n",
       "4                                        5   \n",
       "18                                       7   \n",
       "19                                       7   \n",
       "0                                        3   \n",
       "13                                       3   \n",
       "1                                        3   \n",
       "8                                        7   \n",
       "5                                        5   \n",
       "12                                       3   \n",
       "\n",
       "   param_randomforestclassifier__n_estimators  \\\n",
       "9                                          10   \n",
       "10                                         25   \n",
       "22                                         25   \n",
       "21                                         10   \n",
       "15                                         10   \n",
       "6                                          10   \n",
       "11                                         50   \n",
       "23                                         50   \n",
       "3                                          10   \n",
       "17                                         50   \n",
       "16                                         25   \n",
       "2                                          50   \n",
       "14                                         50   \n",
       "7                                          25   \n",
       "20                                         50   \n",
       "4                                          25   \n",
       "18                                         10   \n",
       "19                                         25   \n",
       "0                                          10   \n",
       "13                                         25   \n",
       "1                                          25   \n",
       "8                                          50   \n",
       "5                                          50   \n",
       "12                                         10   \n",
       "\n",
       "                                               params  \\\n",
       "9   {'randomforestclassifier__criterion': 'entropy...   \n",
       "10  {'randomforestclassifier__criterion': 'entropy...   \n",
       "22  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "21  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "15  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "6   {'randomforestclassifier__criterion': 'entropy...   \n",
       "11  {'randomforestclassifier__criterion': 'entropy...   \n",
       "23  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "3   {'randomforestclassifier__criterion': 'entropy...   \n",
       "17  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "16  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "2   {'randomforestclassifier__criterion': 'entropy...   \n",
       "14  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "7   {'randomforestclassifier__criterion': 'entropy...   \n",
       "20  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "4   {'randomforestclassifier__criterion': 'entropy...   \n",
       "18  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "19  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "0   {'randomforestclassifier__criterion': 'entropy...   \n",
       "13  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "1   {'randomforestclassifier__criterion': 'entropy...   \n",
       "8   {'randomforestclassifier__criterion': 'entropy...   \n",
       "5   {'randomforestclassifier__criterion': 'entropy...   \n",
       "12  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "9                   0.058530         0.094095        0.108967   \n",
       "10                  0.041496         0.043364        0.042190   \n",
       "22                  0.023410         0.033371        0.037158   \n",
       "21                  0.023188         0.056514        0.060139   \n",
       "15                  0.022472         0.014304        0.027306   \n",
       "6                   0.011773         0.007461        0.014111   \n",
       "11                  0.009574         0.024097        0.030133   \n",
       "23                  0.008043         0.029255        0.039097   \n",
       "3                   0.000895         0.000444        0.000545   \n",
       "17                  0.000698         0.000454        0.000908   \n",
       "16                  0.000605         0.000393        0.000787   \n",
       "2                   0.000187         0.000122        0.000243   \n",
       "14                  0.000140         0.000091        0.000182   \n",
       "7                   0.000047         0.000030        0.000061   \n",
       "20                  0.000047         0.000030        0.000061   \n",
       "4                   0.000047         0.000030        0.000061   \n",
       "18                  0.000031         0.000185        0.000370   \n",
       "19                  0.000000         0.000000        0.000000   \n",
       "0                   0.000000         0.000000        0.000000   \n",
       "13                  0.000000         0.000000        0.000000   \n",
       "1                   0.000000         0.000000        0.000000   \n",
       "8                   0.000000         0.000000        0.000000   \n",
       "5                   0.000000         0.000000        0.000000   \n",
       "12                  0.000000         0.000000        0.000000   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "9                 1                   0.986199          0.986304   \n",
       "10                2                   0.998248          0.998243   \n",
       "22                3                   0.998331          0.998357   \n",
       "21                4                   0.985886          0.985989   \n",
       "15                5                   0.566415          0.572303   \n",
       "6                 6                   0.638086          0.642972   \n",
       "11                7                   0.999657          0.999647   \n",
       "23                8                   0.999652          0.999652   \n",
       "3                 9                   0.565881          0.572853   \n",
       "17               10                   0.566515          0.571515   \n",
       "16               11                   0.570309          0.573988   \n",
       "2                12                   0.463172          0.469792   \n",
       "14               13                   0.466829          0.473418   \n",
       "7                14                   0.645170          0.649946   \n",
       "20               15                   0.652103          0.655233   \n",
       "4                16                   0.568581          0.575221   \n",
       "18               17                   0.648929          0.651832   \n",
       "19               18                   0.654330          0.657074   \n",
       "0                19                   0.440124          0.448864   \n",
       "13               20                   0.454819          0.462987   \n",
       "1                21                   0.435903          0.445772   \n",
       "8                22                   0.646162          0.650978   \n",
       "5                23                   0.556344          0.562496   \n",
       "12               24                   0.464480          0.470868   \n",
       "\n",
       "    std_train_score  \n",
       "9          0.003024  \n",
       "10         0.000230  \n",
       "22         0.000184  \n",
       "21         0.003061  \n",
       "15         0.087398  \n",
       "6          0.066353  \n",
       "11         0.000095  \n",
       "23         0.000098  \n",
       "3          0.076679  \n",
       "17         0.090489  \n",
       "16         0.092995  \n",
       "2          0.153582  \n",
       "14         0.152507  \n",
       "7          0.065702  \n",
       "20         0.066139  \n",
       "4          0.076109  \n",
       "18         0.058873  \n",
       "19         0.065947  \n",
       "0          0.153237  \n",
       "13         0.148709  \n",
       "1          0.150376  \n",
       "8          0.065799  \n",
       "5          0.088151  \n",
       "12         0.149899  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_class = RandomForestClassifier(random_state=seed)\n",
    "random_forest_class_pipeline = make_pipeline(preprocessing, random_forest_class)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [10, 25, 50],\n",
    "    'randomforestclassifier__max_depth': [3, 5, 7, None],\n",
    "    'randomforestclassifier__criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "random_forest_class_gs = optimize_params(random_forest_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Time: 95.72 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbclassifier__learning_rate</th>\n",
       "      <th>param_xgbclassifier__max_depth</th>\n",
       "      <th>param_xgbclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.895029</td>\n",
       "      <td>0.177206</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>0.043090</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.110274</td>\n",
       "      <td>0.080450</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738138</td>\n",
       "      <td>0.742209</td>\n",
       "      <td>0.038365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.314329</td>\n",
       "      <td>0.241747</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>0.046688</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.094676</td>\n",
       "      <td>0.077135</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>2</td>\n",
       "      <td>0.772524</td>\n",
       "      <td>0.776784</td>\n",
       "      <td>0.036582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.589372</td>\n",
       "      <td>0.238446</td>\n",
       "      <td>0.071314</td>\n",
       "      <td>0.045429</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.1, 'xgbclas...</td>\n",
       "      <td>0.093737</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>3</td>\n",
       "      <td>0.803433</td>\n",
       "      <td>0.806272</td>\n",
       "      <td>0.035052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.143729</td>\n",
       "      <td>0.196447</td>\n",
       "      <td>0.066023</td>\n",
       "      <td>0.045598</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.096248</td>\n",
       "      <td>0.095393</td>\n",
       "      <td>4</td>\n",
       "      <td>0.797270</td>\n",
       "      <td>0.801185</td>\n",
       "      <td>0.035542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.243086</td>\n",
       "      <td>0.219305</td>\n",
       "      <td>0.073504</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.1, 'xgbclas...</td>\n",
       "      <td>0.087196</td>\n",
       "      <td>0.174896</td>\n",
       "      <td>0.195624</td>\n",
       "      <td>5</td>\n",
       "      <td>0.758700</td>\n",
       "      <td>0.762474</td>\n",
       "      <td>0.040908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.774758</td>\n",
       "      <td>0.304895</td>\n",
       "      <td>0.069832</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.963724</td>\n",
       "      <td>0.184550</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>0.027790</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.430891</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.109878</td>\n",
       "      <td>0.083578</td>\n",
       "      <td>0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118</td>\n",
       "      <td>0.328811</td>\n",
       "      <td>0.340323</td>\n",
       "      <td>0.135759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.346899</td>\n",
       "      <td>0.252008</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>0.029934</td>\n",
       "      <td>0.047026</td>\n",
       "      <td>0.094053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.459803</td>\n",
       "      <td>0.097612</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.05, 'xgbcla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.060187</td>\n",
       "      <td>0.066321</td>\n",
       "      <td>0.059358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "106       0.895029      0.177206         0.059833        0.043090   \n",
       "107       1.314329      0.241747         0.069117        0.046688   \n",
       "93        1.589372      0.238446         0.071314        0.045429   \n",
       "110       1.143729      0.196447         0.066023        0.045598   \n",
       "90        1.243086      0.219305         0.073504        0.051525   \n",
       "..             ...           ...              ...             ...   \n",
       "33        1.774758      0.304895         0.069832        0.049211   \n",
       "32        0.963724      0.184550         0.044998        0.027790   \n",
       "31        2.430891      0.466200         0.109878        0.083578   \n",
       "30        1.346899      0.252008         0.071270        0.045604   \n",
       "60        0.459803      0.097612         0.036827        0.021561   \n",
       "\n",
       "    param_xgbclassifier__learning_rate param_xgbclassifier__max_depth  \\\n",
       "106                                0.2                              5   \n",
       "107                                0.2                              5   \n",
       "93                                 0.1                             10   \n",
       "110                                0.2                              7   \n",
       "90                                 0.1                              7   \n",
       "..                                 ...                            ...   \n",
       "33                               0.005                             10   \n",
       "32                               0.005                             10   \n",
       "31                               0.005                              7   \n",
       "30                               0.005                              7   \n",
       "60                                0.05                              3   \n",
       "\n",
       "    param_xgbclassifier__n_estimators  \\\n",
       "106                                50   \n",
       "107                               100   \n",
       "93                                 25   \n",
       "110                                50   \n",
       "90                                 50   \n",
       "..                                ...   \n",
       "33                                 25   \n",
       "32                                 10   \n",
       "31                                100   \n",
       "30                                 50   \n",
       "60                                 10   \n",
       "\n",
       "                                                params  \\\n",
       "106  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "107  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "93   {'xgbclassifier__learning_rate': 0.1, 'xgbclas...   \n",
       "110  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "90   {'xgbclassifier__learning_rate': 0.1, 'xgbclas...   \n",
       "..                                                 ...   \n",
       "33   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "32   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "31   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "30   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "60   {'xgbclassifier__learning_rate': 0.05, 'xgbcla...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "106                  0.110274         0.080450        0.053633   \n",
       "107                  0.094676         0.077135        0.054217   \n",
       "93                   0.093737         0.044648        0.058746   \n",
       "110                  0.091280         0.096248        0.095393   \n",
       "90                   0.087196         0.174896        0.195624   \n",
       "..                        ...              ...             ...   \n",
       "33                   0.000000         0.000000        0.000000   \n",
       "32                   0.000000         0.000000        0.000000   \n",
       "31                   0.000000         0.000000        0.000000   \n",
       "30                   0.000000         0.000000        0.000000   \n",
       "60                   0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "106                1                   0.738138          0.742209   \n",
       "107                2                   0.772524          0.776784   \n",
       "93                 3                   0.803433          0.806272   \n",
       "110                4                   0.797270          0.801185   \n",
       "90                 5                   0.758700          0.762474   \n",
       "..               ...                        ...               ...   \n",
       "33               116                   0.000000          0.000000   \n",
       "32               117                   0.000000          0.000000   \n",
       "31               118                   0.328811          0.340323   \n",
       "30               119                   0.029934          0.047026   \n",
       "60               120                   0.060187          0.066321   \n",
       "\n",
       "     std_train_score  \n",
       "106         0.038365  \n",
       "107         0.036582  \n",
       "93          0.035052  \n",
       "110         0.035542  \n",
       "90          0.040908  \n",
       "..               ...  \n",
       "33          0.000000  \n",
       "32          0.000000  \n",
       "31          0.135759  \n",
       "30          0.094053  \n",
       "60          0.059358  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state=seed)\n",
    "xgb_class_pipeline = make_pipeline(preprocessing, xgb_class)\n",
    "\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [10, 25, 50, 100],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_class_gs = optimize_params(xgb_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n",
      "Time: 63.76 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_sgdclassifier__alpha</th>\n",
       "      <th>param_sgdclassifier__class_weight</th>\n",
       "      <th>param_sgdclassifier__loss</th>\n",
       "      <th>param_sgdclassifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.060205</td>\n",
       "      <td>0.255091</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.019396</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.0001, 'sgdclassifie...</td>\n",
       "      <td>0.289915</td>\n",
       "      <td>0.179727</td>\n",
       "      <td>0.191640</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.480640</td>\n",
       "      <td>0.048302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.356977</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>0.030040</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.254988</td>\n",
       "      <td>0.149902</td>\n",
       "      <td>0.179152</td>\n",
       "      <td>2</td>\n",
       "      <td>0.616717</td>\n",
       "      <td>0.619885</td>\n",
       "      <td>0.022617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.355087</td>\n",
       "      <td>0.102311</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.254988</td>\n",
       "      <td>0.149902</td>\n",
       "      <td>0.179152</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616717</td>\n",
       "      <td>0.619885</td>\n",
       "      <td>0.022617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.356720</td>\n",
       "      <td>0.097649</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.254988</td>\n",
       "      <td>0.149902</td>\n",
       "      <td>0.179152</td>\n",
       "      <td>4</td>\n",
       "      <td>0.616717</td>\n",
       "      <td>0.619885</td>\n",
       "      <td>0.022617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.357635</td>\n",
       "      <td>0.100754</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.254988</td>\n",
       "      <td>0.149902</td>\n",
       "      <td>0.179152</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616717</td>\n",
       "      <td>0.619885</td>\n",
       "      <td>0.022617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.222549</td>\n",
       "      <td>0.049676</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.5, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.007684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.216198</td>\n",
       "      <td>0.045813</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.5, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.007684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.215888</td>\n",
       "      <td>0.051535</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.226984</td>\n",
       "      <td>0.049641</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.230893</td>\n",
       "      <td>0.051943</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "20        1.060205      0.255091         0.032895        0.019396   \n",
       "80        0.356977      0.099631         0.030040        0.018284   \n",
       "81        0.355087      0.102311         0.030576        0.018479   \n",
       "82        0.356720      0.097649         0.030327        0.015261   \n",
       "83        0.357635      0.100754         0.032402        0.019032   \n",
       "..             ...           ...              ...             ...   \n",
       "197       0.222549      0.049676         0.028226        0.018308   \n",
       "196       0.216198      0.045813         0.027064        0.016597   \n",
       "232       0.215888      0.051535         0.026720        0.017066   \n",
       "235       0.226984      0.049641         0.030008        0.015928   \n",
       "233       0.230893      0.051943         0.028323        0.019168   \n",
       "\n",
       "    param_sgdclassifier__alpha param_sgdclassifier__class_weight  \\\n",
       "20                      0.0001                              None   \n",
       "80                        0.01                          balanced   \n",
       "81                        0.01                          balanced   \n",
       "82                        0.01                          balanced   \n",
       "83                        0.01                          balanced   \n",
       "..                         ...                               ...   \n",
       "197                        0.5                              None   \n",
       "196                        0.5                              None   \n",
       "232                        0.8                              None   \n",
       "235                        0.8                              None   \n",
       "233                        0.8                              None   \n",
       "\n",
       "    param_sgdclassifier__loss param_sgdclassifier__max_iter  \\\n",
       "20             modified_huber                            50   \n",
       "80             modified_huber                            50   \n",
       "81             modified_huber                           100   \n",
       "82             modified_huber                           500   \n",
       "83             modified_huber                          1000   \n",
       "..                        ...                           ...   \n",
       "197                     hinge                           100   \n",
       "196                     hinge                            50   \n",
       "232                     hinge                            50   \n",
       "235                     hinge                          1000   \n",
       "233                     hinge                           100   \n",
       "\n",
       "                                                params  \\\n",
       "20   {'sgdclassifier__alpha': 0.0001, 'sgdclassifie...   \n",
       "80   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "81   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "82   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "83   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "..                                                 ...   \n",
       "197  {'sgdclassifier__alpha': 0.5, 'sgdclassifier__...   \n",
       "196  {'sgdclassifier__alpha': 0.5, 'sgdclassifier__...   \n",
       "232  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "235  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "233  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "20                   0.289915         0.179727        0.191640   \n",
       "80                   0.254988         0.149902        0.179152   \n",
       "81                   0.254988         0.149902        0.179152   \n",
       "82                   0.254988         0.149902        0.179152   \n",
       "83                   0.254988         0.149902        0.179152   \n",
       "..                        ...              ...             ...   \n",
       "197                  0.000000         0.000000        0.000000   \n",
       "196                  0.000000         0.000000        0.000000   \n",
       "232                  0.000000         0.000000        0.000000   \n",
       "235                  0.000000         0.000000        0.000000   \n",
       "233                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "20                 1                   0.478476          0.480640   \n",
       "80                 2                   0.616717          0.619885   \n",
       "81                 3                   0.616717          0.619885   \n",
       "82                 4                   0.616717          0.619885   \n",
       "83                 5                   0.616717          0.619885   \n",
       "..               ...                        ...               ...   \n",
       "197              248                   0.003326          0.003842   \n",
       "196              249                   0.003326          0.003842   \n",
       "232              250                   0.000000          0.000000   \n",
       "235              251                   0.000000          0.000000   \n",
       "233              252                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "20          0.048302  \n",
       "80          0.022617  \n",
       "81          0.022617  \n",
       "82          0.022617  \n",
       "83          0.022617  \n",
       "..               ...  \n",
       "197         0.007684  \n",
       "196         0.007684  \n",
       "232         0.000000  \n",
       "235         0.000000  \n",
       "233         0.000000  \n",
       "\n",
       "[252 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgd_class = SGDClassifier(random_state=seed)\n",
    "sgd_class_pipeline = make_pipeline(preprocessing, sgd_class)\n",
    "\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "    'sgdclassifier__max_iter': [50, 100, 500, 1000],\n",
    "    'sgdclassifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'sgdclassifier__class_weight': ['balanced', None, {0:1, 1:2}]\n",
    "}\n",
    "\n",
    "sgd_class_gs = optimize_params(sgd_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbol de decision</td>\n",
       "      <td>0.347322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.289915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresion logistica</td>\n",
       "      <td>0.279116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.262815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.110274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.058530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Mejor puntuacion\n",
       "2    Arbol de decision          0.347322\n",
       "5                  SGD          0.289915\n",
       "0  Regresion logistica          0.279116\n",
       "1           KNeighbors          0.262815\n",
       "4              XGBoost          0.110274\n",
       "3        Random Forest          0.058530"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = {\n",
    "    'Regresion logistica': logistic_reg_gs,\n",
    "    'KNeighbors' : k_neighbors_class_gs,\n",
    "    'Arbol de decision': decision_tree_class_gs,\n",
    "    'Random Forest': random_forest_class_gs,\n",
    "    'XGBoost': xgb_class_gs,\n",
    "    'SGD': sgd_class_gs\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Modelo': models_dict.keys(),\n",
    "    'Mejor puntuacion': [gs.best_score_ for gs in models_dict.values()]\n",
    "})\n",
    "df_results = df_results.sort_values(by='Mejor puntuacion', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model_4\\\\ab_cu\\\\model_baja_alta.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[df_results.loc[df_results.index[0], 'Modelo']].best_estimator_\n",
    "model_path = os.path.join('models', 'experiment_4', 'AB_CU', 'model_baja_alta.joblib')\n",
    "dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas predicci√≥n del test\n",
      "F1:        0.19017857142857145\n",
      "Recall:    0.1343001261034048\n",
      "Precision: 0.3256880733944954\n",
      "Accuracy:  0.5984949092518813\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('models', 'experiment_4', 'AB_CU', 'model_baja_alta.joblib')\n",
    "model = load(model_path)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\"\"M√©tricas predicci√≥n del test\n",
    "F1:        {f1_score(y_test, pred)}\n",
    "Recall:    {recall_score(y_test, pred)}\n",
    "Precision: {precision_score(y_test, pred)}\n",
    "Accuracy:  {accuracy_score(y_test, pred)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baja - Media baja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classification = {0:0, 1:1}\n",
    "\n",
    "df_train_reclass = reclass(new_classification, df_train)\n",
    "df_test_reclass = reclass(new_classification, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_reclass[variables]\n",
    "y_train = df_train_reclass[target_discrete]\n",
    "\n",
    "X_test = df_test_reclass[variables]\n",
    "y_test = df_test_reclass[target_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Train: 27796\tTest:31128\n",
      "Fold 1: Train: 53052\tTest:5872\n",
      "Fold 2: Train: 51762\tTest:7162\n",
      "Fold 3: Train: 45009\tTest:13915\n",
      "Fold 4: Train: 58077\tTest:847\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "\n",
    "for name in train_fire_names:\n",
    "    fold_train_names = [x for x in train_fire_names if x != name]\n",
    "    fold_test_name = [x for x in train_fire_names if x == name]\n",
    "\n",
    "    fold_train_indices = df_train_reclass[(df_train_reclass['incendio'].isin(fold_train_names))].index\n",
    "    fold_test_indices = df_train_reclass[df_train_reclass['incendio'].isin(fold_test_name)].index\n",
    "    folds.append((fold_train_indices, fold_test_indices))\n",
    "\n",
    "[print(f'Fold {i}: Train: {x.size}\\tTest:{y.size}') for i, (x, y) in enumerate(folds)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Time: 45.85 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491723</td>\n",
       "      <td>0.129618</td>\n",
       "      <td>0.032774</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.716042</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719249</td>\n",
       "      <td>0.716105</td>\n",
       "      <td>0.030132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.513019</td>\n",
       "      <td>0.148499</td>\n",
       "      <td>0.034944</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.716042</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>2</td>\n",
       "      <td>0.719249</td>\n",
       "      <td>0.716105</td>\n",
       "      <td>0.030132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.646769</td>\n",
       "      <td>0.159351</td>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.708985</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>0.059028</td>\n",
       "      <td>3</td>\n",
       "      <td>0.718410</td>\n",
       "      <td>0.715263</td>\n",
       "      <td>0.030053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.637571</td>\n",
       "      <td>0.162229</td>\n",
       "      <td>0.042548</td>\n",
       "      <td>0.022840</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.708985</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>0.059028</td>\n",
       "      <td>4</td>\n",
       "      <td>0.718410</td>\n",
       "      <td>0.715263</td>\n",
       "      <td>0.030053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.540347</td>\n",
       "      <td>2.006596</td>\n",
       "      <td>0.081167</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.698932</td>\n",
       "      <td>0.579189</td>\n",
       "      <td>0.190640</td>\n",
       "      <td>5</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.459566</td>\n",
       "      <td>2.033536</td>\n",
       "      <td>0.076135</td>\n",
       "      <td>0.050602</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.698574</td>\n",
       "      <td>0.572520</td>\n",
       "      <td>0.203258</td>\n",
       "      <td>6</td>\n",
       "      <td>0.743116</td>\n",
       "      <td>0.739895</td>\n",
       "      <td>0.025865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.350361</td>\n",
       "      <td>1.851715</td>\n",
       "      <td>0.075237</td>\n",
       "      <td>0.063034</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.698522</td>\n",
       "      <td>0.573115</td>\n",
       "      <td>0.203154</td>\n",
       "      <td>7</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.739991</td>\n",
       "      <td>0.025960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.486864</td>\n",
       "      <td>2.090393</td>\n",
       "      <td>0.083201</td>\n",
       "      <td>0.060214</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.698495</td>\n",
       "      <td>0.605430</td>\n",
       "      <td>0.168739</td>\n",
       "      <td>8</td>\n",
       "      <td>0.742460</td>\n",
       "      <td>0.739336</td>\n",
       "      <td>0.025587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.558413</td>\n",
       "      <td>1.031573</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.694617</td>\n",
       "      <td>0.623352</td>\n",
       "      <td>0.145475</td>\n",
       "      <td>9</td>\n",
       "      <td>0.742148</td>\n",
       "      <td>0.739094</td>\n",
       "      <td>0.025574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.293138</td>\n",
       "      <td>0.616237</td>\n",
       "      <td>0.039822</td>\n",
       "      <td>0.037703</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.693896</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.214822</td>\n",
       "      <td>10</td>\n",
       "      <td>0.743038</td>\n",
       "      <td>0.739893</td>\n",
       "      <td>0.025590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.325199</td>\n",
       "      <td>1.027353</td>\n",
       "      <td>0.077864</td>\n",
       "      <td>0.058654</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.693365</td>\n",
       "      <td>0.622319</td>\n",
       "      <td>0.146589</td>\n",
       "      <td>11</td>\n",
       "      <td>0.741692</td>\n",
       "      <td>0.738602</td>\n",
       "      <td>0.025894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.395464</td>\n",
       "      <td>1.007642</td>\n",
       "      <td>0.084168</td>\n",
       "      <td>0.064847</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.693311</td>\n",
       "      <td>0.622163</td>\n",
       "      <td>0.144716</td>\n",
       "      <td>12</td>\n",
       "      <td>0.742170</td>\n",
       "      <td>0.739025</td>\n",
       "      <td>0.025739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.441451</td>\n",
       "      <td>1.063305</td>\n",
       "      <td>0.084011</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.692428</td>\n",
       "      <td>0.623245</td>\n",
       "      <td>0.144215</td>\n",
       "      <td>13</td>\n",
       "      <td>0.741590</td>\n",
       "      <td>0.738448</td>\n",
       "      <td>0.026123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.361241</td>\n",
       "      <td>1.124833</td>\n",
       "      <td>0.075346</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.689596</td>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.127740</td>\n",
       "      <td>14</td>\n",
       "      <td>0.741930</td>\n",
       "      <td>0.738837</td>\n",
       "      <td>0.025648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.542936</td>\n",
       "      <td>0.138612</td>\n",
       "      <td>0.030217</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.678552</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.059656</td>\n",
       "      <td>15</td>\n",
       "      <td>0.718194</td>\n",
       "      <td>0.715025</td>\n",
       "      <td>0.030189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.493751</td>\n",
       "      <td>0.134681</td>\n",
       "      <td>0.030117</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.678552</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.059656</td>\n",
       "      <td>16</td>\n",
       "      <td>0.718194</td>\n",
       "      <td>0.715025</td>\n",
       "      <td>0.030189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.145541</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.677938</td>\n",
       "      <td>0.689795</td>\n",
       "      <td>0.059886</td>\n",
       "      <td>17</td>\n",
       "      <td>0.718184</td>\n",
       "      <td>0.715005</td>\n",
       "      <td>0.030232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.138040</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.677938</td>\n",
       "      <td>0.689795</td>\n",
       "      <td>0.059886</td>\n",
       "      <td>18</td>\n",
       "      <td>0.718184</td>\n",
       "      <td>0.715005</td>\n",
       "      <td>0.030232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.530449</td>\n",
       "      <td>0.156551</td>\n",
       "      <td>0.031176</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.677930</td>\n",
       "      <td>0.689688</td>\n",
       "      <td>0.059953</td>\n",
       "      <td>19</td>\n",
       "      <td>0.718193</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>0.030192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.582368</td>\n",
       "      <td>0.157775</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>0.025209</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.677930</td>\n",
       "      <td>0.689688</td>\n",
       "      <td>0.059953</td>\n",
       "      <td>20</td>\n",
       "      <td>0.718193</td>\n",
       "      <td>0.715024</td>\n",
       "      <td>0.030192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.507768</td>\n",
       "      <td>0.134627</td>\n",
       "      <td>0.035189</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.677721</td>\n",
       "      <td>0.689945</td>\n",
       "      <td>0.059779</td>\n",
       "      <td>21</td>\n",
       "      <td>0.718193</td>\n",
       "      <td>0.715027</td>\n",
       "      <td>0.030183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.518157</td>\n",
       "      <td>0.145101</td>\n",
       "      <td>0.035111</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.677721</td>\n",
       "      <td>0.689945</td>\n",
       "      <td>0.059779</td>\n",
       "      <td>22</td>\n",
       "      <td>0.718193</td>\n",
       "      <td>0.715027</td>\n",
       "      <td>0.030183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.536504</td>\n",
       "      <td>1.076712</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.056955</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.578442</td>\n",
       "      <td>0.564176</td>\n",
       "      <td>0.152463</td>\n",
       "      <td>23</td>\n",
       "      <td>0.740603</td>\n",
       "      <td>0.737558</td>\n",
       "      <td>0.025358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.435633</td>\n",
       "      <td>2.461617</td>\n",
       "      <td>0.083827</td>\n",
       "      <td>0.056381</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.560878</td>\n",
       "      <td>0.546043</td>\n",
       "      <td>0.194085</td>\n",
       "      <td>24</td>\n",
       "      <td>0.740675</td>\n",
       "      <td>0.737597</td>\n",
       "      <td>0.025490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.491723      0.129618         0.032774        0.016185   \n",
       "2        0.513019      0.148499         0.034944        0.016930   \n",
       "4        0.646769      0.159351         0.030034        0.016912   \n",
       "6        0.637571      0.162229         0.042548        0.022840   \n",
       "15       8.540347      2.006596         0.081167        0.061687   \n",
       "11       8.459566      2.033536         0.076135        0.050602   \n",
       "19       8.350361      1.851715         0.075237        0.063034   \n",
       "7        8.486864      2.090393         0.083201        0.060214   \n",
       "17       4.558413      1.031573         0.081846        0.053800   \n",
       "23       5.293138      0.616237         0.039822        0.037703   \n",
       "21       4.325199      1.027353         0.077864        0.058654   \n",
       "9        4.395464      1.007642         0.084168        0.064847   \n",
       "13       4.441451      1.063305         0.084011        0.058200   \n",
       "5        4.361241      1.124833         0.075346        0.056501   \n",
       "10       0.542936      0.138612         0.030217        0.018045   \n",
       "8        0.493751      0.134681         0.030117        0.018465   \n",
       "14       0.525846      0.145541         0.034597        0.019119   \n",
       "12       0.512900      0.138040         0.032481        0.018108   \n",
       "16       0.530449      0.156551         0.031176        0.021395   \n",
       "18       0.582368      0.157775         0.033248        0.025209   \n",
       "20       0.507768      0.134627         0.035189        0.023411   \n",
       "22       0.518157      0.145101         0.035111        0.018453   \n",
       "1        4.536504      1.076712         0.079723        0.056955   \n",
       "3        8.435633      2.461617         0.083827        0.056381   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__max_iter  \\\n",
       "0                         0.01                                100   \n",
       "2                         0.01                                200   \n",
       "4                          0.1                                100   \n",
       "6                          0.1                                200   \n",
       "15                           2                                200   \n",
       "11                           1                                200   \n",
       "19                           5                                200   \n",
       "7                          0.1                                200   \n",
       "17                           5                                100   \n",
       "23                          10                                200   \n",
       "21                          10                                100   \n",
       "9                            1                                100   \n",
       "13                           2                                100   \n",
       "5                          0.1                                100   \n",
       "10                           1                                200   \n",
       "8                            1                                100   \n",
       "14                           2                                200   \n",
       "12                           2                                100   \n",
       "16                           5                                100   \n",
       "18                           5                                200   \n",
       "20                          10                                100   \n",
       "22                          10                                200   \n",
       "1                         0.01                                100   \n",
       "3                         0.01                                200   \n",
       "\n",
       "   param_polynomialfeatures__degree  \\\n",
       "0                                 1   \n",
       "2                                 1   \n",
       "4                                 1   \n",
       "6                                 1   \n",
       "15                                2   \n",
       "11                                2   \n",
       "19                                2   \n",
       "7                                 2   \n",
       "17                                2   \n",
       "23                                2   \n",
       "21                                2   \n",
       "9                                 2   \n",
       "13                                2   \n",
       "5                                 2   \n",
       "10                                1   \n",
       "8                                 1   \n",
       "14                                1   \n",
       "12                                1   \n",
       "16                                1   \n",
       "18                                1   \n",
       "20                                1   \n",
       "22                                1   \n",
       "1                                 2   \n",
       "3                                 2   \n",
       "\n",
       "                                               params  \\\n",
       "0   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "2   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "15  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "11  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "19  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "7   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "17  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "23  {'logisticregression__C': 10, 'logisticregress...   \n",
       "21  {'logisticregression__C': 10, 'logisticregress...   \n",
       "9   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "13  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "8   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "14  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "12  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "18  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "20  {'logisticregression__C': 10, 'logisticregress...   \n",
       "22  {'logisticregression__C': 10, 'logisticregress...   \n",
       "1   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "0                   0.716042         0.709119        0.058278   \n",
       "2                   0.716042         0.709119        0.058278   \n",
       "4                   0.708985         0.703636        0.059028   \n",
       "6                   0.708985         0.703636        0.059028   \n",
       "15                  0.698932         0.579189        0.190640   \n",
       "11                  0.698574         0.572520        0.203258   \n",
       "19                  0.698522         0.573115        0.203154   \n",
       "7                   0.698495         0.605430        0.168739   \n",
       "17                  0.694617         0.623352        0.145475   \n",
       "23                  0.693896         0.557377        0.214822   \n",
       "21                  0.693365         0.622319        0.146589   \n",
       "9                   0.693311         0.622163        0.144716   \n",
       "13                  0.692428         0.623245        0.144215   \n",
       "5                   0.689596         0.627650        0.127740   \n",
       "10                  0.678552         0.690315        0.059656   \n",
       "8                   0.678552         0.690315        0.059656   \n",
       "14                  0.677938         0.689795        0.059886   \n",
       "12                  0.677938         0.689795        0.059886   \n",
       "16                  0.677930         0.689688        0.059953   \n",
       "18                  0.677930         0.689688        0.059953   \n",
       "20                  0.677721         0.689945        0.059779   \n",
       "22                  0.677721         0.689945        0.059779   \n",
       "1                   0.578442         0.564176        0.152463   \n",
       "3                   0.560878         0.546043        0.194085   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "0                 1                   0.719249          0.716105   \n",
       "2                 2                   0.719249          0.716105   \n",
       "4                 3                   0.718410          0.715263   \n",
       "6                 4                   0.718410          0.715263   \n",
       "15                5                   0.742960          0.739688   \n",
       "11                6                   0.743116          0.739895   \n",
       "19                7                   0.743208          0.739991   \n",
       "7                 8                   0.742460          0.739336   \n",
       "17                9                   0.742148          0.739094   \n",
       "23               10                   0.743038          0.739893   \n",
       "21               11                   0.741692          0.738602   \n",
       "9                12                   0.742170          0.739025   \n",
       "13               13                   0.741590          0.738448   \n",
       "5                14                   0.741930          0.738837   \n",
       "10               15                   0.718194          0.715025   \n",
       "8                16                   0.718194          0.715025   \n",
       "14               17                   0.718184          0.715005   \n",
       "12               18                   0.718184          0.715005   \n",
       "16               19                   0.718193          0.715024   \n",
       "18               20                   0.718193          0.715024   \n",
       "20               21                   0.718193          0.715027   \n",
       "22               22                   0.718193          0.715027   \n",
       "1                23                   0.740603          0.737558   \n",
       "3                24                   0.740675          0.737597   \n",
       "\n",
       "    std_train_score  \n",
       "0          0.030132  \n",
       "2          0.030132  \n",
       "4          0.030053  \n",
       "6          0.030053  \n",
       "15         0.025863  \n",
       "11         0.025865  \n",
       "19         0.025960  \n",
       "7          0.025587  \n",
       "17         0.025574  \n",
       "23         0.025590  \n",
       "21         0.025894  \n",
       "9          0.025739  \n",
       "13         0.026123  \n",
       "5          0.025648  \n",
       "10         0.030189  \n",
       "8          0.030189  \n",
       "14         0.030232  \n",
       "12         0.030232  \n",
       "16         0.030192  \n",
       "18         0.030192  \n",
       "20         0.030183  \n",
       "22         0.030183  \n",
       "1          0.025358  \n",
       "3          0.025490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "logistic_reg = LogisticRegression(random_state=seed)\n",
    "logistic_reg_pipeline = make_pipeline(preprocessing, poly, logistic_reg)\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "    'logisticregression__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "logistic_reg_gs = optimize_params(logistic_reg_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 158.41 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>param_kneighborsclassifier__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>5.642754</td>\n",
       "      <td>3.782154</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.656434</td>\n",
       "      <td>0.637073</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049974</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>5.867754</td>\n",
       "      <td>3.863868</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>0.633370</td>\n",
       "      <td>0.084352</td>\n",
       "      <td>2</td>\n",
       "      <td>0.751232</td>\n",
       "      <td>0.748139</td>\n",
       "      <td>0.024097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046757</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>5.190540</td>\n",
       "      <td>3.417705</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.640477</td>\n",
       "      <td>0.624609</td>\n",
       "      <td>0.088458</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.043663</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>5.094021</td>\n",
       "      <td>3.250778</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.632307</td>\n",
       "      <td>0.615714</td>\n",
       "      <td>0.088503</td>\n",
       "      <td>4</td>\n",
       "      <td>0.755686</td>\n",
       "      <td>0.752847</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.048580</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>4.768920</td>\n",
       "      <td>3.085321</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.629678</td>\n",
       "      <td>0.616317</td>\n",
       "      <td>0.078309</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049281</td>\n",
       "      <td>0.013589</td>\n",
       "      <td>4.682934</td>\n",
       "      <td>2.937828</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.622211</td>\n",
       "      <td>0.604690</td>\n",
       "      <td>0.076025</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059953</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>5.040992</td>\n",
       "      <td>3.145717</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.611365</td>\n",
       "      <td>0.598117</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>7</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.809930</td>\n",
       "      <td>0.013285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>4.899506</td>\n",
       "      <td>3.097423</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.611365</td>\n",
       "      <td>0.598117</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049128</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>4.756224</td>\n",
       "      <td>3.145404</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.608028</td>\n",
       "      <td>0.591339</td>\n",
       "      <td>0.081590</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764914</td>\n",
       "      <td>0.762503</td>\n",
       "      <td>0.021018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047149</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>4.618104</td>\n",
       "      <td>3.029573</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.586196</td>\n",
       "      <td>0.568690</td>\n",
       "      <td>0.073815</td>\n",
       "      <td>10</td>\n",
       "      <td>0.773274</td>\n",
       "      <td>0.771410</td>\n",
       "      <td>0.018194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9       0.051525      0.006408         5.642754        3.782154   \n",
       "8       0.049974      0.011926         5.867754        3.863868   \n",
       "7       0.046757      0.007137         5.190540        3.417705   \n",
       "6       0.043663      0.007780         5.094021        3.250778   \n",
       "5       0.048580      0.007882         4.768920        3.085321   \n",
       "3       0.049281      0.013589         4.682934        2.937828   \n",
       "0       0.059953      0.009710         5.040992        3.145717   \n",
       "1       0.058678      0.011325         4.899506        3.097423   \n",
       "4       0.049128      0.010517         4.756224        3.145404   \n",
       "2       0.047149      0.013072         4.618104        3.029573   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors param_kneighborsclassifier__weights  \\\n",
       "9                                     100                            distance   \n",
       "8                                     100                             uniform   \n",
       "7                                      50                            distance   \n",
       "6                                      50                             uniform   \n",
       "5                                      20                            distance   \n",
       "3                                      10                            distance   \n",
       "0                                       5                             uniform   \n",
       "1                                       5                            distance   \n",
       "4                                      20                             uniform   \n",
       "2                                      10                             uniform   \n",
       "\n",
       "                                              params  \\\n",
       "9  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "8  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "7  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "6  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "5  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "3  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "0  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "1  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "4  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "2  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "\n",
       "   weighted_mean_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "9                  0.656434         0.637073        0.085152                1   \n",
       "8                  0.652521         0.633370        0.084352                2   \n",
       "7                  0.640477         0.624609        0.088458                3   \n",
       "6                  0.632307         0.615714        0.088503                4   \n",
       "5                  0.629678         0.616317        0.078309                5   \n",
       "3                  0.622211         0.604690        0.076025                6   \n",
       "0                  0.611365         0.598117        0.069318                7   \n",
       "1                  0.611365         0.598117        0.069318                8   \n",
       "4                  0.608028         0.591339        0.081590                9   \n",
       "2                  0.586196         0.568690        0.073815               10   \n",
       "\n",
       "   weighted_mean_train_score  mean_train_score  std_train_score  \n",
       "9                   1.000000          1.000000         0.000000  \n",
       "8                   0.751232          0.748139         0.024097  \n",
       "7                   1.000000          1.000000         0.000000  \n",
       "6                   0.755686          0.752847         0.023077  \n",
       "5                   1.000000          1.000000         0.000000  \n",
       "3                   1.000000          1.000000         0.000000  \n",
       "0                   0.811331          0.809930         0.013285  \n",
       "1                   1.000000          1.000000         0.000000  \n",
       "4                   0.764914          0.762503         0.021018  \n",
       "2                   0.773274          0.771410         0.018194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_neighbors_class = KNeighborsClassifier()\n",
    "k_neighbours_class_pipeline = make_pipeline(preprocessing, k_neighbors_class)\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_neighbors_class_gs = optimize_params(k_neighbours_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "Time: 113.69 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_decisiontreeclassifier__ccp_alpha</th>\n",
       "      <th>param_decisiontreeclassifier__criterion</th>\n",
       "      <th>param_decisiontreeclassifier__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.659749</td>\n",
       "      <td>0.447277</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2.407511</td>\n",
       "      <td>0.659104</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.592530</td>\n",
       "      <td>0.137418</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.627492</td>\n",
       "      <td>0.145268</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.618930</td>\n",
       "      <td>0.138961</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>5</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.883727</td>\n",
       "      <td>0.756061</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.455660</td>\n",
       "      <td>0.299247</td>\n",
       "      <td>0.212370</td>\n",
       "      <td>146</td>\n",
       "      <td>0.845050</td>\n",
       "      <td>0.845810</td>\n",
       "      <td>0.006870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.215516</td>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.426697</td>\n",
       "      <td>0.280547</td>\n",
       "      <td>0.204779</td>\n",
       "      <td>147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.717774</td>\n",
       "      <td>0.692415</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.422277</td>\n",
       "      <td>0.422370</td>\n",
       "      <td>0.210567</td>\n",
       "      <td>148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.338575</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.419562</td>\n",
       "      <td>0.275963</td>\n",
       "      <td>0.201338</td>\n",
       "      <td>149</td>\n",
       "      <td>0.906830</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>0.037984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.412194</td>\n",
       "      <td>0.624203</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>0.009433</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.400059</td>\n",
       "      <td>0.374557</td>\n",
       "      <td>0.210495</td>\n",
       "      <td>150</td>\n",
       "      <td>0.850142</td>\n",
       "      <td>0.849902</td>\n",
       "      <td>0.004894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "149       1.659749      0.447277         0.010976        0.005885   \n",
       "134       2.407511      0.659104         0.015731        0.007551   \n",
       "120       0.592530      0.137418         0.013188        0.007995   \n",
       "121       0.627492      0.145268         0.015078        0.008892   \n",
       "122       0.618930      0.138961         0.017168        0.009047   \n",
       "..             ...           ...              ...             ...   \n",
       "43        2.883727      0.756061         0.020429        0.011312   \n",
       "12        3.215516      0.783321         0.016828        0.006793   \n",
       "27        2.717774      0.692415         0.015976        0.007957   \n",
       "42        3.338575      0.852090         0.020707        0.011457   \n",
       "28        2.412194      0.624203         0.018735        0.009433   \n",
       "\n",
       "    param_decisiontreeclassifier__ccp_alpha  \\\n",
       "149                                     0.1   \n",
       "134                                     0.1   \n",
       "120                                     0.1   \n",
       "121                                     0.1   \n",
       "122                                     0.1   \n",
       "..                                      ...   \n",
       "43                                   0.0001   \n",
       "12                                        0   \n",
       "27                                        0   \n",
       "42                                   0.0001   \n",
       "28                                        0   \n",
       "\n",
       "    param_decisiontreeclassifier__criterion  \\\n",
       "149                                    gini   \n",
       "134                                 entropy   \n",
       "120                                 entropy   \n",
       "121                                 entropy   \n",
       "122                                 entropy   \n",
       "..                                      ...   \n",
       "43                                  entropy   \n",
       "12                                  entropy   \n",
       "27                                     gini   \n",
       "42                                  entropy   \n",
       "28                                     gini   \n",
       "\n",
       "    param_decisiontreeclassifier__max_depth  \\\n",
       "149                                    None   \n",
       "134                                    None   \n",
       "120                                       3   \n",
       "121                                       3   \n",
       "122                                       3   \n",
       "..                                      ...   \n",
       "43                                     None   \n",
       "12                                     None   \n",
       "27                                     None   \n",
       "42                                     None   \n",
       "28                                     None   \n",
       "\n",
       "                                                params  \\\n",
       "149  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "134  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "120  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "121  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "122  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "..                                                 ...   \n",
       "43   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "12   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "27   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "42   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "28   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "149                  0.735138         0.727057        0.063567   \n",
       "134                  0.735138         0.727057        0.063567   \n",
       "120                  0.735138         0.727057        0.063567   \n",
       "121                  0.735138         0.727057        0.063567   \n",
       "122                  0.735138         0.727057        0.063567   \n",
       "..                        ...              ...             ...   \n",
       "43                   0.455660         0.299247        0.212370   \n",
       "12                   0.426697         0.280547        0.204779   \n",
       "27                   0.422277         0.422370        0.210567   \n",
       "42                   0.419562         0.275963        0.201338   \n",
       "28                   0.400059         0.374557        0.210495   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "149                1                   0.737326          0.735557   \n",
       "134                2                   0.737326          0.735557   \n",
       "120                3                   0.737326          0.735557   \n",
       "121                4                   0.737326          0.735557   \n",
       "122                5                   0.737326          0.735557   \n",
       "..               ...                        ...               ...   \n",
       "43               146                   0.845050          0.845810   \n",
       "12               147                   1.000000          1.000000   \n",
       "27               148                   1.000000          1.000000   \n",
       "42               149                   0.906830          0.915270   \n",
       "28               150                   0.850142          0.849902   \n",
       "\n",
       "     std_train_score  \n",
       "149         0.017202  \n",
       "134         0.017202  \n",
       "120         0.017202  \n",
       "121         0.017202  \n",
       "122         0.017202  \n",
       "..               ...  \n",
       "43          0.006870  \n",
       "12          0.000000  \n",
       "27          0.000000  \n",
       "42          0.037984  \n",
       "28          0.004894  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_class = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree_class_pipeline = make_pipeline(preprocessing, decision_tree_class)\n",
    "\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 50, 200],\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "decision_tree_class_gs = optimize_params(decision_tree_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Time: 95.71 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.895898</td>\n",
       "      <td>0.192844</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.687863</td>\n",
       "      <td>0.631510</td>\n",
       "      <td>0.162499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725536</td>\n",
       "      <td>0.723683</td>\n",
       "      <td>0.024755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.049869</td>\n",
       "      <td>0.246923</td>\n",
       "      <td>0.027376</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.684791</td>\n",
       "      <td>0.628956</td>\n",
       "      <td>0.165096</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>0.722309</td>\n",
       "      <td>0.024347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.704848</td>\n",
       "      <td>0.983443</td>\n",
       "      <td>0.057001</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.677676</td>\n",
       "      <td>0.558019</td>\n",
       "      <td>0.276736</td>\n",
       "      <td>3</td>\n",
       "      <td>0.729308</td>\n",
       "      <td>0.726671</td>\n",
       "      <td>0.027948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.610114</td>\n",
       "      <td>1.132924</td>\n",
       "      <td>0.068579</td>\n",
       "      <td>0.040783</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.677406</td>\n",
       "      <td>0.557664</td>\n",
       "      <td>0.276656</td>\n",
       "      <td>4</td>\n",
       "      <td>0.729113</td>\n",
       "      <td>0.726393</td>\n",
       "      <td>0.027773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.203068</td>\n",
       "      <td>0.400302</td>\n",
       "      <td>0.040087</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.675669</td>\n",
       "      <td>0.557898</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727657</td>\n",
       "      <td>0.725150</td>\n",
       "      <td>0.027454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.722333</td>\n",
       "      <td>0.518768</td>\n",
       "      <td>0.043671</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.672955</td>\n",
       "      <td>0.555619</td>\n",
       "      <td>0.280919</td>\n",
       "      <td>6</td>\n",
       "      <td>0.727315</td>\n",
       "      <td>0.724809</td>\n",
       "      <td>0.027223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.136685</td>\n",
       "      <td>1.467955</td>\n",
       "      <td>0.062461</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.668441</td>\n",
       "      <td>0.547744</td>\n",
       "      <td>0.277629</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741914</td>\n",
       "      <td>0.740201</td>\n",
       "      <td>0.023733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.774881</td>\n",
       "      <td>0.968587</td>\n",
       "      <td>0.050938</td>\n",
       "      <td>0.034347</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.665607</td>\n",
       "      <td>0.618245</td>\n",
       "      <td>0.172964</td>\n",
       "      <td>8</td>\n",
       "      <td>0.770855</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>0.015055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.454299</td>\n",
       "      <td>0.313413</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.019099</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.663745</td>\n",
       "      <td>0.546391</td>\n",
       "      <td>0.276910</td>\n",
       "      <td>9</td>\n",
       "      <td>0.742796</td>\n",
       "      <td>0.741261</td>\n",
       "      <td>0.022256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.558531</td>\n",
       "      <td>1.767891</td>\n",
       "      <td>0.064526</td>\n",
       "      <td>0.049190</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.662738</td>\n",
       "      <td>0.542351</td>\n",
       "      <td>0.279293</td>\n",
       "      <td>10</td>\n",
       "      <td>0.740140</td>\n",
       "      <td>0.738144</td>\n",
       "      <td>0.024916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.973465</td>\n",
       "      <td>0.436669</td>\n",
       "      <td>0.027525</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.657665</td>\n",
       "      <td>0.559409</td>\n",
       "      <td>0.246887</td>\n",
       "      <td>11</td>\n",
       "      <td>0.766986</td>\n",
       "      <td>0.766709</td>\n",
       "      <td>0.016178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.259809</td>\n",
       "      <td>2.368791</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.047547</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.653264</td>\n",
       "      <td>0.530855</td>\n",
       "      <td>0.282151</td>\n",
       "      <td>12</td>\n",
       "      <td>0.768501</td>\n",
       "      <td>0.767981</td>\n",
       "      <td>0.016440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.683641</td>\n",
       "      <td>1.965348</td>\n",
       "      <td>0.069921</td>\n",
       "      <td>0.051349</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.650345</td>\n",
       "      <td>0.537033</td>\n",
       "      <td>0.278439</td>\n",
       "      <td>13</td>\n",
       "      <td>0.771526</td>\n",
       "      <td>0.771136</td>\n",
       "      <td>0.015752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.640393</td>\n",
       "      <td>1.148639</td>\n",
       "      <td>0.050278</td>\n",
       "      <td>0.035065</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.645077</td>\n",
       "      <td>0.521946</td>\n",
       "      <td>0.280354</td>\n",
       "      <td>14</td>\n",
       "      <td>0.768178</td>\n",
       "      <td>0.767604</td>\n",
       "      <td>0.016642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.529272</td>\n",
       "      <td>0.749079</td>\n",
       "      <td>0.044277</td>\n",
       "      <td>0.031660</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.644055</td>\n",
       "      <td>0.525390</td>\n",
       "      <td>0.287223</td>\n",
       "      <td>15</td>\n",
       "      <td>0.742143</td>\n",
       "      <td>0.740359</td>\n",
       "      <td>0.024874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.249679</td>\n",
       "      <td>0.859830</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.639537</td>\n",
       "      <td>0.521481</td>\n",
       "      <td>0.289713</td>\n",
       "      <td>16</td>\n",
       "      <td>0.740452</td>\n",
       "      <td>0.738693</td>\n",
       "      <td>0.024552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.298720</td>\n",
       "      <td>0.538705</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.021044</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.636414</td>\n",
       "      <td>0.499380</td>\n",
       "      <td>0.249079</td>\n",
       "      <td>17</td>\n",
       "      <td>0.765768</td>\n",
       "      <td>0.765052</td>\n",
       "      <td>0.016956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.740900</td>\n",
       "      <td>0.376442</td>\n",
       "      <td>0.030944</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.607111</td>\n",
       "      <td>0.470289</td>\n",
       "      <td>0.283532</td>\n",
       "      <td>18</td>\n",
       "      <td>0.739989</td>\n",
       "      <td>0.738973</td>\n",
       "      <td>0.022419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.010675</td>\n",
       "      <td>3.327258</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>0.042044</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.446337</td>\n",
       "      <td>0.360083</td>\n",
       "      <td>0.131773</td>\n",
       "      <td>19</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.998851</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.748231</td>\n",
       "      <td>2.674944</td>\n",
       "      <td>0.055823</td>\n",
       "      <td>0.041233</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.420384</td>\n",
       "      <td>0.399606</td>\n",
       "      <td>0.141255</td>\n",
       "      <td>20</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.998847</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.852161</td>\n",
       "      <td>1.156176</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.411839</td>\n",
       "      <td>0.353305</td>\n",
       "      <td>0.080404</td>\n",
       "      <td>21</td>\n",
       "      <td>0.991294</td>\n",
       "      <td>0.991176</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.661061</td>\n",
       "      <td>1.369721</td>\n",
       "      <td>0.032280</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.378973</td>\n",
       "      <td>0.302411</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>22</td>\n",
       "      <td>0.991580</td>\n",
       "      <td>0.991482</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.651467</td>\n",
       "      <td>6.911464</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>0.071904</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.292062</td>\n",
       "      <td>0.241636</td>\n",
       "      <td>0.096987</td>\n",
       "      <td>23</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19.943462</td>\n",
       "      <td>3.701189</td>\n",
       "      <td>0.068703</td>\n",
       "      <td>0.072705</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.247067</td>\n",
       "      <td>0.222417</td>\n",
       "      <td>0.068248</td>\n",
       "      <td>24</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12       0.895898      0.192844         0.025609        0.016258   \n",
       "0        1.049869      0.246923         0.027376        0.013429   \n",
       "14       4.704848      0.983443         0.057001        0.033661   \n",
       "2        5.610114      1.132924         0.068579        0.040783   \n",
       "13       2.203068      0.400302         0.040087        0.027832   \n",
       "1        2.722333      0.518768         0.043671        0.033155   \n",
       "17       7.136685      1.467955         0.062461        0.046742   \n",
       "19       4.774881      0.968587         0.050938        0.034347   \n",
       "15       1.454299      0.313413         0.026596        0.019099   \n",
       "5        8.558531      1.767891         0.064526        0.049190   \n",
       "18       1.973465      0.436669         0.027525        0.019817   \n",
       "8       11.259809      2.368791         0.063598        0.047547   \n",
       "20       9.683641      1.965348         0.069921        0.051349   \n",
       "7        5.640393      1.148639         0.050278        0.035065   \n",
       "16       3.529272      0.749079         0.044277        0.031660   \n",
       "4        4.249679      0.859830         0.045788        0.035787   \n",
       "6        2.298720      0.538705         0.032642        0.021044   \n",
       "3        1.740900      0.376442         0.030944        0.017092   \n",
       "10      14.010675      3.327258         0.055038        0.042044   \n",
       "22      11.748231      2.674944         0.055823        0.041233   \n",
       "21       4.852161      1.156176         0.029401        0.014944   \n",
       "9        5.661061      1.369721         0.032280        0.019387   \n",
       "11      28.651467      6.911464         0.098919        0.071904   \n",
       "23      19.943462      3.701189         0.068703        0.072705   \n",
       "\n",
       "   param_randomforestclassifier__criterion  \\\n",
       "12                                    gini   \n",
       "0                                  entropy   \n",
       "14                                    gini   \n",
       "2                                  entropy   \n",
       "13                                    gini   \n",
       "1                                  entropy   \n",
       "17                                    gini   \n",
       "19                                    gini   \n",
       "15                                    gini   \n",
       "5                                  entropy   \n",
       "18                                    gini   \n",
       "8                                  entropy   \n",
       "20                                    gini   \n",
       "7                                  entropy   \n",
       "16                                    gini   \n",
       "4                                  entropy   \n",
       "6                                  entropy   \n",
       "3                                  entropy   \n",
       "10                                 entropy   \n",
       "22                                    gini   \n",
       "21                                    gini   \n",
       "9                                  entropy   \n",
       "11                                 entropy   \n",
       "23                                    gini   \n",
       "\n",
       "   param_randomforestclassifier__max_depth  \\\n",
       "12                                       3   \n",
       "0                                        3   \n",
       "14                                       3   \n",
       "2                                        3   \n",
       "13                                       3   \n",
       "1                                        3   \n",
       "17                                       5   \n",
       "19                                       7   \n",
       "15                                       5   \n",
       "5                                        5   \n",
       "18                                       7   \n",
       "8                                        7   \n",
       "20                                       7   \n",
       "7                                        7   \n",
       "16                                       5   \n",
       "4                                        5   \n",
       "6                                        7   \n",
       "3                                        5   \n",
       "10                                    None   \n",
       "22                                    None   \n",
       "21                                    None   \n",
       "9                                     None   \n",
       "11                                    None   \n",
       "23                                    None   \n",
       "\n",
       "   param_randomforestclassifier__n_estimators  \\\n",
       "12                                         10   \n",
       "0                                          10   \n",
       "14                                         50   \n",
       "2                                          50   \n",
       "13                                         25   \n",
       "1                                          25   \n",
       "17                                         50   \n",
       "19                                         25   \n",
       "15                                         10   \n",
       "5                                          50   \n",
       "18                                         10   \n",
       "8                                          50   \n",
       "20                                         50   \n",
       "7                                          25   \n",
       "16                                         25   \n",
       "4                                          25   \n",
       "6                                          10   \n",
       "3                                          10   \n",
       "10                                         25   \n",
       "22                                         25   \n",
       "21                                         10   \n",
       "9                                          10   \n",
       "11                                         50   \n",
       "23                                         50   \n",
       "\n",
       "                                               params  \\\n",
       "12  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "0   {'randomforestclassifier__criterion': 'entropy...   \n",
       "14  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "2   {'randomforestclassifier__criterion': 'entropy...   \n",
       "13  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "1   {'randomforestclassifier__criterion': 'entropy...   \n",
       "17  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "19  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "15  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "5   {'randomforestclassifier__criterion': 'entropy...   \n",
       "18  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "8   {'randomforestclassifier__criterion': 'entropy...   \n",
       "20  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "7   {'randomforestclassifier__criterion': 'entropy...   \n",
       "16  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "4   {'randomforestclassifier__criterion': 'entropy...   \n",
       "6   {'randomforestclassifier__criterion': 'entropy...   \n",
       "3   {'randomforestclassifier__criterion': 'entropy...   \n",
       "10  {'randomforestclassifier__criterion': 'entropy...   \n",
       "22  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "21  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "9   {'randomforestclassifier__criterion': 'entropy...   \n",
       "11  {'randomforestclassifier__criterion': 'entropy...   \n",
       "23  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "12                  0.687863         0.631510        0.162499   \n",
       "0                   0.684791         0.628956        0.165096   \n",
       "14                  0.677676         0.558019        0.276736   \n",
       "2                   0.677406         0.557664        0.276656   \n",
       "13                  0.675669         0.557898        0.279950   \n",
       "1                   0.672955         0.555619        0.280919   \n",
       "17                  0.668441         0.547744        0.277629   \n",
       "19                  0.665607         0.618245        0.172964   \n",
       "15                  0.663745         0.546391        0.276910   \n",
       "5                   0.662738         0.542351        0.279293   \n",
       "18                  0.657665         0.559409        0.246887   \n",
       "8                   0.653264         0.530855        0.282151   \n",
       "20                  0.650345         0.537033        0.278439   \n",
       "7                   0.645077         0.521946        0.280354   \n",
       "16                  0.644055         0.525390        0.287223   \n",
       "4                   0.639537         0.521481        0.289713   \n",
       "6                   0.636414         0.499380        0.249079   \n",
       "3                   0.607111         0.470289        0.283532   \n",
       "10                  0.446337         0.360083        0.131773   \n",
       "22                  0.420384         0.399606        0.141255   \n",
       "21                  0.411839         0.353305        0.080404   \n",
       "9                   0.378973         0.302411        0.121645   \n",
       "11                  0.292062         0.241636        0.096987   \n",
       "23                  0.247067         0.222417        0.068248   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "12                1                   0.725536          0.723683   \n",
       "0                 2                   0.724168          0.722309   \n",
       "14                3                   0.729308          0.726671   \n",
       "2                 4                   0.729113          0.726393   \n",
       "13                5                   0.727657          0.725150   \n",
       "1                 6                   0.727315          0.724809   \n",
       "17                7                   0.741914          0.740201   \n",
       "19                8                   0.770855          0.770669   \n",
       "15                9                   0.742796          0.741261   \n",
       "5                10                   0.740140          0.738144   \n",
       "18               11                   0.766986          0.766709   \n",
       "8                12                   0.768501          0.767981   \n",
       "20               13                   0.771526          0.771136   \n",
       "7                14                   0.768178          0.767604   \n",
       "16               15                   0.742143          0.740359   \n",
       "4                16                   0.740452          0.738693   \n",
       "6                17                   0.765768          0.765052   \n",
       "3                18                   0.739989          0.738973   \n",
       "10               19                   0.998875          0.998851   \n",
       "22               20                   0.998870          0.998847   \n",
       "21               21                   0.991294          0.991176   \n",
       "9                22                   0.991580          0.991482   \n",
       "11               23                   0.999898          0.999902   \n",
       "23               24                   0.999892          0.999895   \n",
       "\n",
       "    std_train_score  \n",
       "12         0.024755  \n",
       "0          0.024347  \n",
       "14         0.027948  \n",
       "2          0.027773  \n",
       "13         0.027454  \n",
       "1          0.027223  \n",
       "17         0.023733  \n",
       "19         0.015055  \n",
       "15         0.022256  \n",
       "5          0.024916  \n",
       "18         0.016178  \n",
       "8          0.016440  \n",
       "20         0.015752  \n",
       "7          0.016642  \n",
       "16         0.024874  \n",
       "4          0.024552  \n",
       "6          0.016956  \n",
       "3          0.022419  \n",
       "10         0.000163  \n",
       "22         0.000135  \n",
       "21         0.000942  \n",
       "9          0.000866  \n",
       "11         0.000040  \n",
       "23         0.000036  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_class = RandomForestClassifier(random_state=seed)\n",
    "random_forest_class_pipeline = make_pipeline(preprocessing, random_forest_class)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [10, 25, 50],\n",
    "    'randomforestclassifier__max_depth': [3, 5, 7, None],\n",
    "    'randomforestclassifier__criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "random_forest_class_gs = optimize_params(random_forest_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Time: 70.16 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbclassifier__learning_rate</th>\n",
       "      <th>param_xgbclassifier__max_depth</th>\n",
       "      <th>param_xgbclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229823</td>\n",
       "      <td>0.062408</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.001, 'xgbcl...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.387652</td>\n",
       "      <td>0.066190</td>\n",
       "      <td>0.027648</td>\n",
       "      <td>0.018861</td>\n",
       "      <td>0.005</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.342932</td>\n",
       "      <td>0.065226</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.735557</td>\n",
       "      <td>0.017202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.445939</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>4</td>\n",
       "      <td>0.738062</td>\n",
       "      <td>0.736807</td>\n",
       "      <td>0.015488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.651950</td>\n",
       "      <td>0.121397</td>\n",
       "      <td>0.042167</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.735138</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>5</td>\n",
       "      <td>0.748134</td>\n",
       "      <td>0.747103</td>\n",
       "      <td>0.010319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2.734241</td>\n",
       "      <td>0.339870</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.082528</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.332428</td>\n",
       "      <td>0.327763</td>\n",
       "      <td>0.168585</td>\n",
       "      <td>116</td>\n",
       "      <td>0.942119</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.012360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.392383</td>\n",
       "      <td>0.248965</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.048603</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.312864</td>\n",
       "      <td>0.327043</td>\n",
       "      <td>0.147638</td>\n",
       "      <td>117</td>\n",
       "      <td>0.867340</td>\n",
       "      <td>0.869708</td>\n",
       "      <td>0.011926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.766478</td>\n",
       "      <td>0.127044</td>\n",
       "      <td>0.052627</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.290537</td>\n",
       "      <td>0.338211</td>\n",
       "      <td>0.243549</td>\n",
       "      <td>118</td>\n",
       "      <td>0.818358</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>0.011712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.203086</td>\n",
       "      <td>0.063855</td>\n",
       "      <td>0.043007</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.249598</td>\n",
       "      <td>0.299935</td>\n",
       "      <td>0.204073</td>\n",
       "      <td>119</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.820798</td>\n",
       "      <td>0.010425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.890495</td>\n",
       "      <td>0.126841</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.040933</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.220804</td>\n",
       "      <td>0.274366</td>\n",
       "      <td>0.196277</td>\n",
       "      <td>120</td>\n",
       "      <td>0.843347</td>\n",
       "      <td>0.844970</td>\n",
       "      <td>0.010249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.229823      0.062408         0.018465        0.006855   \n",
       "36        0.387652      0.066190         0.027648        0.018861   \n",
       "24        0.342932      0.065226         0.028158        0.018912   \n",
       "25        0.445939      0.089694         0.025864        0.017913   \n",
       "26        0.651950      0.121397         0.042167        0.026946   \n",
       "..             ...           ...              ...             ...   \n",
       "115       2.734241      0.339870         0.110323        0.082528   \n",
       "111       1.392383      0.248965         0.067797        0.048603   \n",
       "118       0.766478      0.127044         0.052627        0.031153   \n",
       "107       0.938178      0.203086         0.063855        0.043007   \n",
       "119       0.890495      0.126841         0.042400        0.040933   \n",
       "\n",
       "    param_xgbclassifier__learning_rate param_xgbclassifier__max_depth  \\\n",
       "0                                0.001                              3   \n",
       "36                               0.005                           None   \n",
       "24                               0.005                              5   \n",
       "25                               0.005                              5   \n",
       "26                               0.005                              5   \n",
       "..                                 ...                            ...   \n",
       "115                                0.2                             10   \n",
       "111                                0.2                              7   \n",
       "118                                0.2                           None   \n",
       "107                                0.2                              5   \n",
       "119                                0.2                           None   \n",
       "\n",
       "    param_xgbclassifier__n_estimators  \\\n",
       "0                                  10   \n",
       "36                                 10   \n",
       "24                                 10   \n",
       "25                                 25   \n",
       "26                                 50   \n",
       "..                                ...   \n",
       "115                               100   \n",
       "111                               100   \n",
       "118                                50   \n",
       "107                               100   \n",
       "119                               100   \n",
       "\n",
       "                                                params  \\\n",
       "0    {'xgbclassifier__learning_rate': 0.001, 'xgbcl...   \n",
       "36   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "24   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "25   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "26   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "..                                                 ...   \n",
       "115  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "111  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "118  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "107  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "119  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "0                    0.735138         0.727057        0.063567   \n",
       "36                   0.735138         0.727057        0.063567   \n",
       "24                   0.735138         0.727057        0.063567   \n",
       "25                   0.735138         0.727057        0.063567   \n",
       "26                   0.735138         0.727057        0.063567   \n",
       "..                        ...              ...             ...   \n",
       "115                  0.332428         0.327763        0.168585   \n",
       "111                  0.312864         0.327043        0.147638   \n",
       "118                  0.290537         0.338211        0.243549   \n",
       "107                  0.249598         0.299935        0.204073   \n",
       "119                  0.220804         0.274366        0.196277   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "0                  1                   0.737326          0.735557   \n",
       "36                 2                   0.737326          0.735557   \n",
       "24                 3                   0.737326          0.735557   \n",
       "25                 4                   0.738062          0.736807   \n",
       "26                 5                   0.748134          0.747103   \n",
       "..               ...                        ...               ...   \n",
       "115              116                   0.942119          0.944763   \n",
       "111              117                   0.867340          0.869708   \n",
       "118              118                   0.818358          0.819279   \n",
       "107              119                   0.819923          0.820798   \n",
       "119              120                   0.843347          0.844970   \n",
       "\n",
       "     std_train_score  \n",
       "0           0.017202  \n",
       "36          0.017202  \n",
       "24          0.017202  \n",
       "25          0.015488  \n",
       "26          0.010319  \n",
       "..               ...  \n",
       "115         0.012360  \n",
       "111         0.011926  \n",
       "118         0.011712  \n",
       "107         0.010425  \n",
       "119         0.010249  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state=seed)\n",
    "xgb_class_pipeline = make_pipeline(preprocessing, xgb_class)\n",
    "\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [10, 25, 50, 100],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_class_gs = optimize_params(xgb_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n",
      "Time: 45.19 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_sgdclassifier__alpha</th>\n",
       "      <th>param_sgdclassifier__class_weight</th>\n",
       "      <th>param_sgdclassifier__loss</th>\n",
       "      <th>param_sgdclassifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.689908</td>\n",
       "      <td>0.160767</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.0001, 'sgdclassifie...</td>\n",
       "      <td>0.735213</td>\n",
       "      <td>0.726566</td>\n",
       "      <td>0.064017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731632</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.017137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.153341</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.023351</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.735171</td>\n",
       "      <td>0.727112</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737331</td>\n",
       "      <td>0.735608</td>\n",
       "      <td>0.017403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.161650</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.011514</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.735171</td>\n",
       "      <td>0.727112</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737331</td>\n",
       "      <td>0.735608</td>\n",
       "      <td>0.017403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.161754</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.735171</td>\n",
       "      <td>0.727112</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737331</td>\n",
       "      <td>0.735608</td>\n",
       "      <td>0.017403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.171523</td>\n",
       "      <td>0.036909</td>\n",
       "      <td>0.023596</td>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.735171</td>\n",
       "      <td>0.727112</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>5</td>\n",
       "      <td>0.737331</td>\n",
       "      <td>0.735608</td>\n",
       "      <td>0.017403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.230876</td>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.397047</td>\n",
       "      <td>0.568102</td>\n",
       "      <td>0.215099</td>\n",
       "      <td>248</td>\n",
       "      <td>0.666926</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.031026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.235466</td>\n",
       "      <td>0.037151</td>\n",
       "      <td>0.023713</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.397047</td>\n",
       "      <td>0.568102</td>\n",
       "      <td>0.215099</td>\n",
       "      <td>249</td>\n",
       "      <td>0.666926</td>\n",
       "      <td>0.662719</td>\n",
       "      <td>0.031026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.945682</td>\n",
       "      <td>0.150349</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.0001, 'sgdclassifie...</td>\n",
       "      <td>0.304599</td>\n",
       "      <td>0.523351</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>250</td>\n",
       "      <td>0.616059</td>\n",
       "      <td>0.607051</td>\n",
       "      <td>0.069349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.957474</td>\n",
       "      <td>0.144935</td>\n",
       "      <td>0.021789</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.0001, 'sgdclassifie...</td>\n",
       "      <td>0.304599</td>\n",
       "      <td>0.523351</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>251</td>\n",
       "      <td>0.616059</td>\n",
       "      <td>0.607051</td>\n",
       "      <td>0.069349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.949193</td>\n",
       "      <td>0.171388</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.0001, 'sgdclassifie...</td>\n",
       "      <td>0.304599</td>\n",
       "      <td>0.523351</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>252</td>\n",
       "      <td>0.616059</td>\n",
       "      <td>0.607051</td>\n",
       "      <td>0.069349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "32        0.689908      0.160767         0.022878        0.005434   \n",
       "231       0.153341      0.033766         0.023351        0.008915   \n",
       "228       0.161650      0.026127         0.024106        0.011514   \n",
       "229       0.161754      0.035317         0.021863        0.008652   \n",
       "230       0.171523      0.036909         0.023596        0.012616   \n",
       "..             ...           ...              ...             ...   \n",
       "38        0.230876      0.042774         0.019455        0.009962   \n",
       "39        0.235466      0.037151         0.023713        0.012566   \n",
       "10        0.945682      0.150349         0.020540        0.006190   \n",
       "11        0.957474      0.144935         0.021789        0.009948   \n",
       "9         0.949193      0.171388         0.023298        0.014250   \n",
       "\n",
       "    param_sgdclassifier__alpha param_sgdclassifier__class_weight  \\\n",
       "32                      0.0001                      {0: 1, 1: 2}   \n",
       "231                        0.8                              None   \n",
       "228                        0.8                              None   \n",
       "229                        0.8                              None   \n",
       "230                        0.8                              None   \n",
       "..                         ...                               ...   \n",
       "38                       0.001                          balanced   \n",
       "39                       0.001                          balanced   \n",
       "10                      0.0001                          balanced   \n",
       "11                      0.0001                          balanced   \n",
       "9                       0.0001                          balanced   \n",
       "\n",
       "    param_sgdclassifier__loss param_sgdclassifier__max_iter  \\\n",
       "32             modified_huber                            50   \n",
       "231                  log_loss                          1000   \n",
       "228                  log_loss                            50   \n",
       "229                  log_loss                           100   \n",
       "230                  log_loss                           500   \n",
       "..                        ...                           ...   \n",
       "38                   log_loss                           500   \n",
       "39                   log_loss                          1000   \n",
       "10             modified_huber                           500   \n",
       "11             modified_huber                          1000   \n",
       "9              modified_huber                           100   \n",
       "\n",
       "                                                params  \\\n",
       "32   {'sgdclassifier__alpha': 0.0001, 'sgdclassifie...   \n",
       "231  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "228  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "229  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "230  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "..                                                 ...   \n",
       "38   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "39   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "10   {'sgdclassifier__alpha': 0.0001, 'sgdclassifie...   \n",
       "11   {'sgdclassifier__alpha': 0.0001, 'sgdclassifie...   \n",
       "9    {'sgdclassifier__alpha': 0.0001, 'sgdclassifie...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "32                   0.735213         0.726566        0.064017   \n",
       "231                  0.735171         0.727112        0.063571   \n",
       "228                  0.735171         0.727112        0.063571   \n",
       "229                  0.735171         0.727112        0.063571   \n",
       "230                  0.735171         0.727112        0.063571   \n",
       "..                        ...              ...             ...   \n",
       "38                   0.397047         0.568102        0.215099   \n",
       "39                   0.397047         0.568102        0.215099   \n",
       "10                   0.304599         0.523351        0.273567   \n",
       "11                   0.304599         0.523351        0.273567   \n",
       "9                    0.304599         0.523351        0.273567   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "32                 1                   0.731632          0.730277   \n",
       "231                2                   0.737331          0.735608   \n",
       "228                3                   0.737331          0.735608   \n",
       "229                4                   0.737331          0.735608   \n",
       "230                5                   0.737331          0.735608   \n",
       "..               ...                        ...               ...   \n",
       "38               248                   0.666926          0.662719   \n",
       "39               249                   0.666926          0.662719   \n",
       "10               250                   0.616059          0.607051   \n",
       "11               251                   0.616059          0.607051   \n",
       "9                252                   0.616059          0.607051   \n",
       "\n",
       "     std_train_score  \n",
       "32          0.017137  \n",
       "231         0.017403  \n",
       "228         0.017403  \n",
       "229         0.017403  \n",
       "230         0.017403  \n",
       "..               ...  \n",
       "38          0.031026  \n",
       "39          0.031026  \n",
       "10          0.069349  \n",
       "11          0.069349  \n",
       "9           0.069349  \n",
       "\n",
       "[252 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgd_class = SGDClassifier(random_state=seed)\n",
    "sgd_class_pipeline = make_pipeline(preprocessing, sgd_class)\n",
    "\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "    'sgdclassifier__max_iter': [50, 100, 500, 1000],\n",
    "    'sgdclassifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'sgdclassifier__class_weight': ['balanced', None, {0:1, 1:2}]\n",
    "}\n",
    "\n",
    "sgd_class_gs = optimize_params(sgd_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.735213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbol de decision</td>\n",
       "      <td>0.735138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.735138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresion logistica</td>\n",
       "      <td>0.716042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.687863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.656434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Mejor puntuacion\n",
       "5                  SGD          0.735213\n",
       "2    Arbol de decision          0.735138\n",
       "4              XGBoost          0.735138\n",
       "0  Regresion logistica          0.716042\n",
       "3        Random Forest          0.687863\n",
       "1           KNeighbors          0.656434"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = {\n",
    "    'Regresion logistica': logistic_reg_gs,\n",
    "    'KNeighbors' : k_neighbors_class_gs,\n",
    "    'Arbol de decision': decision_tree_class_gs,\n",
    "    'Random Forest': random_forest_class_gs,\n",
    "    'XGBoost': xgb_class_gs,\n",
    "    'SGD': sgd_class_gs\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Modelo': models_dict.keys(),\n",
    "    'Mejor puntuacion': [gs.best_score_ for gs in models_dict.values()]\n",
    "})\n",
    "df_results = df_results.sort_values(by='Mejor puntuacion', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model_4\\\\ab_cu\\\\model_baja_mediabaja.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[df_results.loc[df_results.index[0], 'Modelo']].best_estimator_\n",
    "model_path = os.path.join('models', 'experiment_4', 'AB_CU', 'model_baja_mediabaja.joblib')\n",
    "dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas predicci√≥n del test\n",
      "F1:        0.7228501289735697\n",
      "Recall:    0.8426006623670909\n",
      "Precision: 0.632902001003775\n",
      "Accuracy:  0.62254768854796\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('models', 'experiment_4', 'AB_CU', 'model_baja_mediabaja.joblib')\n",
    "model = load(model_path)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\"\"M√©tricas predicci√≥n del test\n",
    "F1:        {f1_score(y_test, pred)}\n",
    "Recall:    {recall_score(y_test, pred)}\n",
    "Precision: {precision_score(y_test, pred)}\n",
    "Accuracy:  {accuracy_score(y_test, pred)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media alta - Alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classification = {2:0, 3:1}\n",
    "\n",
    "df_train_reclass = reclass(new_classification, df_train)\n",
    "df_test_reclass = reclass(new_classification, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_reclass[variables]\n",
    "y_train = df_train_reclass[target_discrete]\n",
    "\n",
    "X_test = df_test_reclass[variables]\n",
    "y_test = df_test_reclass[target_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Train: 17041\tTest:12083\n",
      "Fold 1: Train: 28864\tTest:260\n",
      "Fold 2: Train: 27635\tTest:1489\n",
      "Fold 3: Train: 15969\tTest:13155\n",
      "Fold 4: Train: 26987\tTest:2137\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "\n",
    "for name in train_fire_names:\n",
    "    fold_train_names = [x for x in train_fire_names if x != name]\n",
    "    fold_test_name = [x for x in train_fire_names if x == name]\n",
    "\n",
    "    fold_train_indices = df_train_reclass[(df_train_reclass['incendio'].isin(fold_train_names))].index\n",
    "    fold_test_indices = df_train_reclass[df_train_reclass['incendio'].isin(fold_test_name)].index\n",
    "    folds.append((fold_train_indices, fold_test_indices))\n",
    "\n",
    "[print(f'Fold {i}: Train: {x.size}\\tTest:{y.size}') for i, (x, y) in enumerate(folds)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Time: 21.73 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.100286</td>\n",
       "      <td>0.517364</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.161044</td>\n",
       "      <td>0.205970</td>\n",
       "      <td>0.302731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621187</td>\n",
       "      <td>0.621498</td>\n",
       "      <td>0.047338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.136242</td>\n",
       "      <td>0.497608</td>\n",
       "      <td>0.050257</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.160438</td>\n",
       "      <td>0.206073</td>\n",
       "      <td>0.303587</td>\n",
       "      <td>2</td>\n",
       "      <td>0.620970</td>\n",
       "      <td>0.620855</td>\n",
       "      <td>0.049751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.084258</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.045149</td>\n",
       "      <td>0.031315</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.160246</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.307370</td>\n",
       "      <td>3</td>\n",
       "      <td>0.623160</td>\n",
       "      <td>0.623288</td>\n",
       "      <td>0.047548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.088459</td>\n",
       "      <td>0.479874</td>\n",
       "      <td>0.041663</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>0.205697</td>\n",
       "      <td>0.302939</td>\n",
       "      <td>4</td>\n",
       "      <td>0.620768</td>\n",
       "      <td>0.621336</td>\n",
       "      <td>0.047341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.018924</td>\n",
       "      <td>0.995669</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.159868</td>\n",
       "      <td>0.207603</td>\n",
       "      <td>0.307667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.624157</td>\n",
       "      <td>0.624305</td>\n",
       "      <td>0.046358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.076151</td>\n",
       "      <td>0.499080</td>\n",
       "      <td>0.045443</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.159649</td>\n",
       "      <td>0.205261</td>\n",
       "      <td>0.302553</td>\n",
       "      <td>6</td>\n",
       "      <td>0.621447</td>\n",
       "      <td>0.621493</td>\n",
       "      <td>0.047604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.913202</td>\n",
       "      <td>0.900185</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.158561</td>\n",
       "      <td>0.207050</td>\n",
       "      <td>0.307769</td>\n",
       "      <td>7</td>\n",
       "      <td>0.624057</td>\n",
       "      <td>0.624366</td>\n",
       "      <td>0.046553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.506886</td>\n",
       "      <td>0.440047</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.022087</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.158386</td>\n",
       "      <td>0.206829</td>\n",
       "      <td>0.307447</td>\n",
       "      <td>8</td>\n",
       "      <td>0.624397</td>\n",
       "      <td>0.624705</td>\n",
       "      <td>0.045994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.020677</td>\n",
       "      <td>0.929793</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.136034</td>\n",
       "      <td>0.189841</td>\n",
       "      <td>0.292349</td>\n",
       "      <td>9</td>\n",
       "      <td>0.619269</td>\n",
       "      <td>0.618983</td>\n",
       "      <td>0.051278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.094856</td>\n",
       "      <td>0.481430</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.030243</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.130060</td>\n",
       "      <td>0.185139</td>\n",
       "      <td>0.288056</td>\n",
       "      <td>10</td>\n",
       "      <td>0.619027</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>0.051127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.408463</td>\n",
       "      <td>0.217962</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.056913</td>\n",
       "      <td>0.155126</td>\n",
       "      <td>0.310253</td>\n",
       "      <td>11</td>\n",
       "      <td>0.523621</td>\n",
       "      <td>0.528803</td>\n",
       "      <td>0.045155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.353061</td>\n",
       "      <td>0.137006</td>\n",
       "      <td>0.024598</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.056907</td>\n",
       "      <td>0.155112</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>12</td>\n",
       "      <td>0.523562</td>\n",
       "      <td>0.528751</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.326027</td>\n",
       "      <td>0.102568</td>\n",
       "      <td>0.021259</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.056868</td>\n",
       "      <td>0.155006</td>\n",
       "      <td>0.310012</td>\n",
       "      <td>13</td>\n",
       "      <td>0.523380</td>\n",
       "      <td>0.528576</td>\n",
       "      <td>0.045139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.311530</td>\n",
       "      <td>0.095637</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.056868</td>\n",
       "      <td>0.155006</td>\n",
       "      <td>0.310012</td>\n",
       "      <td>14</td>\n",
       "      <td>0.523396</td>\n",
       "      <td>0.528599</td>\n",
       "      <td>0.045132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.323008</td>\n",
       "      <td>0.107241</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.154650</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>15</td>\n",
       "      <td>0.523375</td>\n",
       "      <td>0.528549</td>\n",
       "      <td>0.045009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.325666</td>\n",
       "      <td>0.138558</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.154650</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>16</td>\n",
       "      <td>0.523375</td>\n",
       "      <td>0.528549</td>\n",
       "      <td>0.045009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.271749</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.028447</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.154650</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>17</td>\n",
       "      <td>0.523280</td>\n",
       "      <td>0.528460</td>\n",
       "      <td>0.045011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.285079</td>\n",
       "      <td>0.125240</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.154650</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>18</td>\n",
       "      <td>0.523280</td>\n",
       "      <td>0.528460</td>\n",
       "      <td>0.045011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.366471</td>\n",
       "      <td>0.103069</td>\n",
       "      <td>0.022053</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.043872</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.239163</td>\n",
       "      <td>19</td>\n",
       "      <td>0.524375</td>\n",
       "      <td>0.529713</td>\n",
       "      <td>0.045893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.363456</td>\n",
       "      <td>0.109928</td>\n",
       "      <td>0.021467</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.043872</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.239163</td>\n",
       "      <td>20</td>\n",
       "      <td>0.524375</td>\n",
       "      <td>0.529713</td>\n",
       "      <td>0.045893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217126</td>\n",
       "      <td>0.051939</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>0.102773</td>\n",
       "      <td>0.205547</td>\n",
       "      <td>21</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.531219</td>\n",
       "      <td>0.045474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182334</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.037705</td>\n",
       "      <td>0.102773</td>\n",
       "      <td>0.205547</td>\n",
       "      <td>22</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.531219</td>\n",
       "      <td>0.045474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.169690</td>\n",
       "      <td>0.572163</td>\n",
       "      <td>0.046591</td>\n",
       "      <td>0.032996</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.025586</td>\n",
       "      <td>0.061840</td>\n",
       "      <td>0.119483</td>\n",
       "      <td>23</td>\n",
       "      <td>0.611162</td>\n",
       "      <td>0.611317</td>\n",
       "      <td>0.051398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.669578</td>\n",
       "      <td>0.974604</td>\n",
       "      <td>0.047940</td>\n",
       "      <td>0.030243</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.025013</td>\n",
       "      <td>0.060280</td>\n",
       "      <td>0.116365</td>\n",
       "      <td>24</td>\n",
       "      <td>0.610994</td>\n",
       "      <td>0.611177</td>\n",
       "      <td>0.051390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "17       2.100286      0.517364         0.048676        0.030732   \n",
       "9        2.136242      0.497608         0.050257        0.038793   \n",
       "11       4.084258      0.970000         0.045149        0.031315   \n",
       "21       2.088459      0.479874         0.041663        0.028519   \n",
       "15       4.018924      0.995669         0.042160        0.027637   \n",
       "13       2.076151      0.499080         0.045443        0.033168   \n",
       "19       3.913202      0.900185         0.041635        0.034213   \n",
       "23       2.506886      0.440047         0.025009        0.022087   \n",
       "7        4.020677      0.929793         0.046610        0.031867   \n",
       "5        2.094856      0.481430         0.042203        0.030243   \n",
       "10       0.408463      0.217962         0.024504        0.011717   \n",
       "8        0.353061      0.137006         0.024598        0.005406   \n",
       "14       0.326027      0.102568         0.021259        0.008226   \n",
       "12       0.311530      0.095637         0.030410        0.012583   \n",
       "16       0.323008      0.107241         0.023934        0.011764   \n",
       "18       0.325666      0.138558         0.027010        0.012639   \n",
       "20       0.271749      0.106834         0.028447        0.018891   \n",
       "22       0.285079      0.125240         0.027624        0.009325   \n",
       "6        0.366471      0.103069         0.022053        0.007366   \n",
       "4        0.363456      0.109928         0.021467        0.013144   \n",
       "2        0.217126      0.051939         0.018371        0.010061   \n",
       "0        0.182334      0.041832         0.027777        0.011251   \n",
       "1        2.169690      0.572163         0.046591        0.032996   \n",
       "3        2.669578      0.974604         0.047940        0.030243   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__max_iter  \\\n",
       "17                           5                                100   \n",
       "9                            1                                100   \n",
       "11                           1                                200   \n",
       "21                          10                                100   \n",
       "15                           2                                200   \n",
       "13                           2                                100   \n",
       "19                           5                                200   \n",
       "23                          10                                200   \n",
       "7                          0.1                                200   \n",
       "5                          0.1                                100   \n",
       "10                           1                                200   \n",
       "8                            1                                100   \n",
       "14                           2                                200   \n",
       "12                           2                                100   \n",
       "16                           5                                100   \n",
       "18                           5                                200   \n",
       "20                          10                                100   \n",
       "22                          10                                200   \n",
       "6                          0.1                                200   \n",
       "4                          0.1                                100   \n",
       "2                         0.01                                200   \n",
       "0                         0.01                                100   \n",
       "1                         0.01                                100   \n",
       "3                         0.01                                200   \n",
       "\n",
       "   param_polynomialfeatures__degree  \\\n",
       "17                                2   \n",
       "9                                 2   \n",
       "11                                2   \n",
       "21                                2   \n",
       "15                                2   \n",
       "13                                2   \n",
       "19                                2   \n",
       "23                                2   \n",
       "7                                 2   \n",
       "5                                 2   \n",
       "10                                1   \n",
       "8                                 1   \n",
       "14                                1   \n",
       "12                                1   \n",
       "16                                1   \n",
       "18                                1   \n",
       "20                                1   \n",
       "22                                1   \n",
       "6                                 1   \n",
       "4                                 1   \n",
       "2                                 1   \n",
       "0                                 1   \n",
       "1                                 2   \n",
       "3                                 2   \n",
       "\n",
       "                                               params  \\\n",
       "17  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "9   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "11  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "21  {'logisticregression__C': 10, 'logisticregress...   \n",
       "15  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "13  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "19  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "23  {'logisticregression__C': 10, 'logisticregress...   \n",
       "7   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "10  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "8   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "14  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "12  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "18  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "20  {'logisticregression__C': 10, 'logisticregress...   \n",
       "22  {'logisticregression__C': 10, 'logisticregress...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "2   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "0   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "1   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "17                  0.161044         0.205970        0.302731   \n",
       "9                   0.160438         0.206073        0.303587   \n",
       "11                  0.160246         0.207645        0.307370   \n",
       "21                  0.160238         0.205697        0.302939   \n",
       "15                  0.159868         0.207603        0.307667   \n",
       "13                  0.159649         0.205261        0.302553   \n",
       "19                  0.158561         0.207050        0.307769   \n",
       "23                  0.158386         0.206829        0.307447   \n",
       "7                   0.136034         0.189841        0.292349   \n",
       "5                   0.130060         0.185139        0.288056   \n",
       "10                  0.056913         0.155126        0.310253   \n",
       "8                   0.056907         0.155112        0.310224   \n",
       "14                  0.056868         0.155006        0.310012   \n",
       "12                  0.056868         0.155006        0.310012   \n",
       "16                  0.056738         0.154650        0.309300   \n",
       "18                  0.056738         0.154650        0.309300   \n",
       "20                  0.056738         0.154650        0.309300   \n",
       "22                  0.056738         0.154650        0.309300   \n",
       "6                   0.043872         0.119582        0.239163   \n",
       "4                   0.043872         0.119582        0.239163   \n",
       "2                   0.037705         0.102773        0.205547   \n",
       "0                   0.037705         0.102773        0.205547   \n",
       "1                   0.025586         0.061840        0.119483   \n",
       "3                   0.025013         0.060280        0.116365   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "17                1                   0.621187          0.621498   \n",
       "9                 2                   0.620970          0.620855   \n",
       "11                3                   0.623160          0.623288   \n",
       "21                4                   0.620768          0.621336   \n",
       "15                5                   0.624157          0.624305   \n",
       "13                6                   0.621447          0.621493   \n",
       "19                7                   0.624057          0.624366   \n",
       "23                8                   0.624397          0.624705   \n",
       "7                 9                   0.619269          0.618983   \n",
       "5                10                   0.619027          0.618769   \n",
       "10               11                   0.523621          0.528803   \n",
       "8                12                   0.523562          0.528751   \n",
       "14               13                   0.523380          0.528576   \n",
       "12               14                   0.523396          0.528599   \n",
       "16               15                   0.523375          0.528549   \n",
       "18               16                   0.523375          0.528549   \n",
       "20               17                   0.523280          0.528460   \n",
       "22               18                   0.523280          0.528460   \n",
       "6                19                   0.524375          0.529713   \n",
       "4                20                   0.524375          0.529713   \n",
       "2                21                   0.525641          0.531219   \n",
       "0                22                   0.525641          0.531219   \n",
       "1                23                   0.611162          0.611317   \n",
       "3                24                   0.610994          0.611177   \n",
       "\n",
       "    std_train_score  \n",
       "17         0.047338  \n",
       "9          0.049751  \n",
       "11         0.047548  \n",
       "21         0.047341  \n",
       "15         0.046358  \n",
       "13         0.047604  \n",
       "19         0.046553  \n",
       "23         0.045994  \n",
       "7          0.051278  \n",
       "5          0.051127  \n",
       "10         0.045155  \n",
       "8          0.045228  \n",
       "14         0.045139  \n",
       "12         0.045132  \n",
       "16         0.045009  \n",
       "18         0.045009  \n",
       "20         0.045011  \n",
       "22         0.045011  \n",
       "6          0.045893  \n",
       "4          0.045893  \n",
       "2          0.045474  \n",
       "0          0.045474  \n",
       "1          0.051398  \n",
       "3          0.051390  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "logistic_reg = LogisticRegression(random_state=seed)\n",
    "logistic_reg_pipeline = make_pipeline(preprocessing, poly, logistic_reg)\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "    'logisticregression__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "logistic_reg_gs = optimize_params(logistic_reg_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Time: 41.87 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>param_kneighborsclassifier__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.026455</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>1.640095</td>\n",
       "      <td>1.492295</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.040365</td>\n",
       "      <td>0.110022</td>\n",
       "      <td>0.220044</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>1.635620</td>\n",
       "      <td>1.520593</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>0.109640</td>\n",
       "      <td>0.219280</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630155</td>\n",
       "      <td>0.629073</td>\n",
       "      <td>0.055153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.028906</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>1.427696</td>\n",
       "      <td>1.276270</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.086785</td>\n",
       "      <td>0.173570</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.027069</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>1.378901</td>\n",
       "      <td>1.237160</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.030899</td>\n",
       "      <td>0.084221</td>\n",
       "      <td>0.168442</td>\n",
       "      <td>4</td>\n",
       "      <td>0.643240</td>\n",
       "      <td>0.641966</td>\n",
       "      <td>0.052528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029070</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>1.124089</td>\n",
       "      <td>0.959780</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.024692</td>\n",
       "      <td>0.066058</td>\n",
       "      <td>0.131449</td>\n",
       "      <td>5</td>\n",
       "      <td>0.743292</td>\n",
       "      <td>0.743106</td>\n",
       "      <td>0.037556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031023</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>1.135979</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.024692</td>\n",
       "      <td>0.066058</td>\n",
       "      <td>0.131449</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025728</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>1.159000</td>\n",
       "      <td>0.971248</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.066172</td>\n",
       "      <td>0.132344</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>1.179046</td>\n",
       "      <td>0.949698</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.023655</td>\n",
       "      <td>0.064475</td>\n",
       "      <td>0.128950</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027914</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>1.235998</td>\n",
       "      <td>1.049195</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.117211</td>\n",
       "      <td>9</td>\n",
       "      <td>0.661437</td>\n",
       "      <td>0.660583</td>\n",
       "      <td>0.049998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026789</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>1.199945</td>\n",
       "      <td>1.020316</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.049517</td>\n",
       "      <td>0.099035</td>\n",
       "      <td>10</td>\n",
       "      <td>0.679681</td>\n",
       "      <td>0.680194</td>\n",
       "      <td>0.048757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9       0.026455      0.006714         1.640095        1.492295   \n",
       "8       0.026745      0.005203         1.635620        1.520593   \n",
       "7       0.028906      0.005878         1.427696        1.276270   \n",
       "6       0.027069      0.003261         1.378901        1.237160   \n",
       "0       0.029070      0.008406         1.124089        0.959780   \n",
       "1       0.031023      0.004940         1.135979        0.950474   \n",
       "3       0.025728      0.007466         1.159000        0.971248   \n",
       "5       0.025372      0.004030         1.179046        0.949698   \n",
       "4       0.027914      0.005682         1.235998        1.049195   \n",
       "2       0.026789      0.005012         1.199945        1.020316   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors param_kneighborsclassifier__weights  \\\n",
       "9                                     100                            distance   \n",
       "8                                     100                             uniform   \n",
       "7                                      50                            distance   \n",
       "6                                      50                             uniform   \n",
       "0                                       5                             uniform   \n",
       "1                                       5                            distance   \n",
       "3                                      10                            distance   \n",
       "5                                      20                            distance   \n",
       "4                                      20                             uniform   \n",
       "2                                      10                             uniform   \n",
       "\n",
       "                                              params  \\\n",
       "9  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "8  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "7  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "6  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "0  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "1  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "3  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "5  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "4  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "2  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "\n",
       "   weighted_mean_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "9                  0.040365         0.110022        0.220044                1   \n",
       "8                  0.040225         0.109640        0.219280                2   \n",
       "7                  0.031840         0.086785        0.173570                3   \n",
       "6                  0.030899         0.084221        0.168442                4   \n",
       "0                  0.024692         0.066058        0.131449                5   \n",
       "1                  0.024692         0.066058        0.131449                6   \n",
       "3                  0.024277         0.066172        0.132344                7   \n",
       "5                  0.023655         0.064475        0.128950                8   \n",
       "4                  0.021501         0.058606        0.117211                9   \n",
       "2                  0.018167         0.049517        0.099035               10   \n",
       "\n",
       "   weighted_mean_train_score  mean_train_score  std_train_score  \n",
       "9                   1.000000          1.000000         0.000000  \n",
       "8                   0.630155          0.629073         0.055153  \n",
       "7                   1.000000          1.000000         0.000000  \n",
       "6                   0.643240          0.641966         0.052528  \n",
       "0                   0.743292          0.743106         0.037556  \n",
       "1                   1.000000          1.000000         0.000000  \n",
       "3                   1.000000          1.000000         0.000000  \n",
       "5                   1.000000          1.000000         0.000000  \n",
       "4                   0.661437          0.660583         0.049998  \n",
       "2                   0.679681          0.680194         0.048757  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_neighbors_class = KNeighborsClassifier()\n",
    "k_neighbours_class_pipeline = make_pipeline(preprocessing, k_neighbors_class)\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_neighbors_class_gs = optimize_params(k_neighbours_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "Time: 50.94 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_decisiontreeclassifier__ccp_alpha</th>\n",
       "      <th>param_decisiontreeclassifier__criterion</th>\n",
       "      <th>param_decisiontreeclassifier__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.309902</td>\n",
       "      <td>0.079461</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.333756</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504938</td>\n",
       "      <td>0.468369</td>\n",
       "      <td>0.235813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.849385</td>\n",
       "      <td>0.214940</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.333756</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504938</td>\n",
       "      <td>0.468369</td>\n",
       "      <td>0.235813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.639343</td>\n",
       "      <td>0.143345</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.333756</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>3</td>\n",
       "      <td>0.504938</td>\n",
       "      <td>0.468369</td>\n",
       "      <td>0.235813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.678276</td>\n",
       "      <td>0.170326</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.333756</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504938</td>\n",
       "      <td>0.468369</td>\n",
       "      <td>0.235813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.644830</td>\n",
       "      <td>0.147540</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.333756</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>5</td>\n",
       "      <td>0.504938</td>\n",
       "      <td>0.468369</td>\n",
       "      <td>0.235813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.417907</td>\n",
       "      <td>0.085788</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.265903</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.247815</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.260546</td>\n",
       "      <td>0.064651</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.734721</td>\n",
       "      <td>0.177624</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "122       0.309902      0.079461         0.013481        0.006379   \n",
       "130       0.849385      0.214940         0.012153        0.002819   \n",
       "128       0.639343      0.143345         0.011718        0.003461   \n",
       "127       0.678276      0.170326         0.012007        0.004632   \n",
       "126       0.644830      0.147540         0.013656        0.004780   \n",
       "..             ...           ...              ...             ...   \n",
       "138       0.417907      0.085788         0.011821        0.006605   \n",
       "137       0.265903      0.060508         0.012322        0.006650   \n",
       "136       0.247815      0.064047         0.015575        0.005882   \n",
       "135       0.260546      0.064651         0.011284        0.006217   \n",
       "149       0.734721      0.177624         0.010710        0.004472   \n",
       "\n",
       "    param_decisiontreeclassifier__ccp_alpha  \\\n",
       "122                                     0.1   \n",
       "130                                     0.1   \n",
       "128                                     0.1   \n",
       "127                                     0.1   \n",
       "126                                     0.1   \n",
       "..                                      ...   \n",
       "138                                     0.1   \n",
       "137                                     0.1   \n",
       "136                                     0.1   \n",
       "135                                     0.1   \n",
       "149                                     0.1   \n",
       "\n",
       "    param_decisiontreeclassifier__criterion  \\\n",
       "122                                 entropy   \n",
       "130                                 entropy   \n",
       "128                                 entropy   \n",
       "127                                 entropy   \n",
       "126                                 entropy   \n",
       "..                                      ...   \n",
       "138                                    gini   \n",
       "137                                    gini   \n",
       "136                                    gini   \n",
       "135                                    gini   \n",
       "149                                    gini   \n",
       "\n",
       "    param_decisiontreeclassifier__max_depth  \\\n",
       "122                                       3   \n",
       "130                                      10   \n",
       "128                                       7   \n",
       "127                                       7   \n",
       "126                                       7   \n",
       "..                                      ...   \n",
       "138                                       5   \n",
       "137                                       3   \n",
       "136                                       3   \n",
       "135                                       3   \n",
       "149                                    None   \n",
       "\n",
       "                                                params  \\\n",
       "122  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "130  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "128  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "127  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "126  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "..                                                 ...   \n",
       "138  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "137  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "136  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "135  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "149  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "122                  0.333756         0.277308        0.343378   \n",
       "130                  0.333756         0.277308        0.343378   \n",
       "128                  0.333756         0.277308        0.343378   \n",
       "127                  0.333756         0.277308        0.343378   \n",
       "126                  0.333756         0.277308        0.343378   \n",
       "..                        ...              ...             ...   \n",
       "138                  0.000000         0.000000        0.000000   \n",
       "137                  0.000000         0.000000        0.000000   \n",
       "136                  0.000000         0.000000        0.000000   \n",
       "135                  0.000000         0.000000        0.000000   \n",
       "149                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "122                1                   0.504938          0.468369   \n",
       "130                2                   0.504938          0.468369   \n",
       "128                3                   0.504938          0.468369   \n",
       "127                4                   0.504938          0.468369   \n",
       "126                5                   0.504938          0.468369   \n",
       "..               ...                        ...               ...   \n",
       "138              146                   0.000000          0.000000   \n",
       "137              147                   0.000000          0.000000   \n",
       "136              148                   0.000000          0.000000   \n",
       "135              149                   0.000000          0.000000   \n",
       "149              150                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "122         0.235813  \n",
       "130         0.235813  \n",
       "128         0.235813  \n",
       "127         0.235813  \n",
       "126         0.235813  \n",
       "..               ...  \n",
       "138         0.000000  \n",
       "137         0.000000  \n",
       "136         0.000000  \n",
       "135         0.000000  \n",
       "149         0.000000  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_class = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree_class_pipeline = make_pipeline(preprocessing, decision_tree_class)\n",
    "\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 50, 200],\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "decision_tree_class_gs = optimize_params(decision_tree_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Time: 41.31 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.454980</td>\n",
       "      <td>0.100917</td>\n",
       "      <td>0.017756</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>0.030638</td>\n",
       "      <td>0.061276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534256</td>\n",
       "      <td>0.543317</td>\n",
       "      <td>0.067988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.724659</td>\n",
       "      <td>0.151215</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.059836</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>0.052989</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607431</td>\n",
       "      <td>0.609282</td>\n",
       "      <td>0.042804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491443</td>\n",
       "      <td>0.120775</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.033438</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.029611</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516689</td>\n",
       "      <td>0.525094</td>\n",
       "      <td>0.046485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.872681</td>\n",
       "      <td>0.150681</td>\n",
       "      <td>0.018928</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.032696</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>0.028955</td>\n",
       "      <td>4</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.044461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.862297</td>\n",
       "      <td>0.486996</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.048823</td>\n",
       "      <td>5</td>\n",
       "      <td>0.981347</td>\n",
       "      <td>0.980907</td>\n",
       "      <td>0.005396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.946797</td>\n",
       "      <td>0.189428</td>\n",
       "      <td>0.020531</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>6</td>\n",
       "      <td>0.651660</td>\n",
       "      <td>0.651633</td>\n",
       "      <td>0.051226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.157801</td>\n",
       "      <td>0.572639</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>7</td>\n",
       "      <td>0.981888</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>0.005219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.483911</td>\n",
       "      <td>1.067677</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.017894</td>\n",
       "      <td>0.028093</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997764</td>\n",
       "      <td>0.997752</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.715292</td>\n",
       "      <td>1.067143</td>\n",
       "      <td>0.039147</td>\n",
       "      <td>0.027331</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>9</td>\n",
       "      <td>0.656430</td>\n",
       "      <td>0.656150</td>\n",
       "      <td>0.049799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.300017</td>\n",
       "      <td>0.533710</td>\n",
       "      <td>0.039794</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>10</td>\n",
       "      <td>0.508335</td>\n",
       "      <td>0.516685</td>\n",
       "      <td>0.056589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.133840</td>\n",
       "      <td>0.277887</td>\n",
       "      <td>0.015901</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>11</td>\n",
       "      <td>0.646123</td>\n",
       "      <td>0.645816</td>\n",
       "      <td>0.049376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.335962</td>\n",
       "      <td>0.560944</td>\n",
       "      <td>0.026244</td>\n",
       "      <td>0.015559</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>12</td>\n",
       "      <td>0.656260</td>\n",
       "      <td>0.655933</td>\n",
       "      <td>0.049123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.144416</td>\n",
       "      <td>0.257820</td>\n",
       "      <td>0.024839</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>13</td>\n",
       "      <td>0.541543</td>\n",
       "      <td>0.546057</td>\n",
       "      <td>0.044084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.241564</td>\n",
       "      <td>1.664189</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.366679</td>\n",
       "      <td>1.414291</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>15</td>\n",
       "      <td>0.997758</td>\n",
       "      <td>0.997783</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.792680</td>\n",
       "      <td>0.368349</td>\n",
       "      <td>0.026829</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>16</td>\n",
       "      <td>0.610333</td>\n",
       "      <td>0.611536</td>\n",
       "      <td>0.042725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.795079</td>\n",
       "      <td>2.918825</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.368619</td>\n",
       "      <td>0.301149</td>\n",
       "      <td>0.026111</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>18</td>\n",
       "      <td>0.525805</td>\n",
       "      <td>0.532582</td>\n",
       "      <td>0.037788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.795287</td>\n",
       "      <td>0.593966</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>19</td>\n",
       "      <td>0.505870</td>\n",
       "      <td>0.514458</td>\n",
       "      <td>0.054650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.588016</td>\n",
       "      <td>0.826742</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>20</td>\n",
       "      <td>0.608555</td>\n",
       "      <td>0.609301</td>\n",
       "      <td>0.040199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.185674</td>\n",
       "      <td>0.909366</td>\n",
       "      <td>0.037340</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>21</td>\n",
       "      <td>0.598268</td>\n",
       "      <td>0.599894</td>\n",
       "      <td>0.042103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.136199</td>\n",
       "      <td>0.431323</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.607802</td>\n",
       "      <td>0.608721</td>\n",
       "      <td>0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.503337</td>\n",
       "      <td>1.348625</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.028840</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.650599</td>\n",
       "      <td>0.650195</td>\n",
       "      <td>0.051778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.781724</td>\n",
       "      <td>0.685812</td>\n",
       "      <td>0.026065</td>\n",
       "      <td>0.013335</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.652195</td>\n",
       "      <td>0.651932</td>\n",
       "      <td>0.052774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12       0.454980      0.100917         0.017756        0.010499   \n",
       "15       0.724659      0.151215         0.016527        0.007584   \n",
       "0        0.491443      0.120775         0.015457        0.006726   \n",
       "3        0.872681      0.150681         0.018928        0.009059   \n",
       "21       1.862297      0.486996         0.017843        0.009300   \n",
       "18       0.946797      0.189428         0.020531        0.010631   \n",
       "9        2.157801      0.572639         0.019836        0.009824   \n",
       "22       4.483911      1.067677         0.025307        0.012823   \n",
       "20       4.715292      1.067143         0.039147        0.027331   \n",
       "14       2.300017      0.533710         0.039794        0.022983   \n",
       "6        1.133840      0.277887         0.015901        0.008503   \n",
       "19       2.335962      0.560944         0.026244        0.015559   \n",
       "13       1.144416      0.257820         0.024839        0.014733   \n",
       "23       7.241564      1.664189         0.027116        0.022830   \n",
       "10       5.366679      1.414291         0.025900        0.013785   \n",
       "16       1.792680      0.368349         0.026829        0.013133   \n",
       "11      10.795079      2.918825         0.040039        0.031641   \n",
       "1        1.368619      0.301149         0.026111        0.015668   \n",
       "2        2.795287      0.593966         0.035302        0.020130   \n",
       "17       3.588016      0.826742         0.032169        0.018592   \n",
       "5        4.185674      0.909366         0.037340        0.023460   \n",
       "4        2.136199      0.431323         0.022767        0.012671   \n",
       "8        5.503337      1.348625         0.041768        0.028840   \n",
       "7        2.781724      0.685812         0.026065        0.013335   \n",
       "\n",
       "   param_randomforestclassifier__criterion  \\\n",
       "12                                    gini   \n",
       "15                                    gini   \n",
       "0                                  entropy   \n",
       "3                                  entropy   \n",
       "21                                    gini   \n",
       "18                                    gini   \n",
       "9                                  entropy   \n",
       "22                                    gini   \n",
       "20                                    gini   \n",
       "14                                    gini   \n",
       "6                                  entropy   \n",
       "19                                    gini   \n",
       "13                                    gini   \n",
       "23                                    gini   \n",
       "10                                 entropy   \n",
       "16                                    gini   \n",
       "11                                 entropy   \n",
       "1                                  entropy   \n",
       "2                                  entropy   \n",
       "17                                    gini   \n",
       "5                                  entropy   \n",
       "4                                  entropy   \n",
       "8                                  entropy   \n",
       "7                                  entropy   \n",
       "\n",
       "   param_randomforestclassifier__max_depth  \\\n",
       "12                                       3   \n",
       "15                                       5   \n",
       "0                                        3   \n",
       "3                                        5   \n",
       "21                                    None   \n",
       "18                                       7   \n",
       "9                                     None   \n",
       "22                                    None   \n",
       "20                                       7   \n",
       "14                                       3   \n",
       "6                                        7   \n",
       "19                                       7   \n",
       "13                                       3   \n",
       "23                                    None   \n",
       "10                                    None   \n",
       "16                                       5   \n",
       "11                                    None   \n",
       "1                                        3   \n",
       "2                                        3   \n",
       "17                                       5   \n",
       "5                                        5   \n",
       "4                                        5   \n",
       "8                                        7   \n",
       "7                                        7   \n",
       "\n",
       "   param_randomforestclassifier__n_estimators  \\\n",
       "12                                         10   \n",
       "15                                         10   \n",
       "0                                          10   \n",
       "3                                          10   \n",
       "21                                         10   \n",
       "18                                         10   \n",
       "9                                          10   \n",
       "22                                         25   \n",
       "20                                         50   \n",
       "14                                         50   \n",
       "6                                          10   \n",
       "19                                         25   \n",
       "13                                         25   \n",
       "23                                         50   \n",
       "10                                         25   \n",
       "16                                         25   \n",
       "11                                         50   \n",
       "1                                          25   \n",
       "2                                          50   \n",
       "17                                         50   \n",
       "5                                          50   \n",
       "4                                          25   \n",
       "8                                          50   \n",
       "7                                          25   \n",
       "\n",
       "                                               params  \\\n",
       "12  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "15  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "0   {'randomforestclassifier__criterion': 'entropy...   \n",
       "3   {'randomforestclassifier__criterion': 'entropy...   \n",
       "21  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "18  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "9   {'randomforestclassifier__criterion': 'entropy...   \n",
       "22  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "20  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "14  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "6   {'randomforestclassifier__criterion': 'entropy...   \n",
       "19  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "13  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "23  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "10  {'randomforestclassifier__criterion': 'entropy...   \n",
       "16  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "11  {'randomforestclassifier__criterion': 'entropy...   \n",
       "1   {'randomforestclassifier__criterion': 'entropy...   \n",
       "2   {'randomforestclassifier__criterion': 'entropy...   \n",
       "17  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "5   {'randomforestclassifier__criterion': 'entropy...   \n",
       "4   {'randomforestclassifier__criterion': 'entropy...   \n",
       "8   {'randomforestclassifier__criterion': 'entropy...   \n",
       "7   {'randomforestclassifier__criterion': 'entropy...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "12                  0.069194         0.030638        0.061276   \n",
       "15                  0.059836         0.026494        0.052989   \n",
       "0                   0.033438         0.014806        0.029611   \n",
       "3                   0.032696         0.014477        0.028955   \n",
       "21                  0.031846         0.034955        0.048823   \n",
       "18                  0.022987         0.010178        0.020357   \n",
       "9                   0.013110         0.011058        0.013746   \n",
       "22                  0.012976         0.017894        0.028093   \n",
       "20                  0.005931         0.014047        0.027079   \n",
       "14                  0.005695         0.002522        0.005043   \n",
       "6                   0.004889         0.002165        0.004329   \n",
       "19                  0.004706         0.002084        0.004167   \n",
       "13                  0.001703         0.000754        0.001508   \n",
       "23                  0.001649         0.003434        0.006366   \n",
       "10                  0.001609         0.004386        0.008772   \n",
       "16                  0.001239         0.000548        0.001097   \n",
       "11                  0.000970         0.002645        0.005290   \n",
       "1                   0.000465         0.000206        0.000412   \n",
       "2                   0.000310         0.000137        0.000275   \n",
       "17                  0.000310         0.000137        0.000275   \n",
       "5                   0.000109         0.000297        0.000593   \n",
       "4                   0.000000         0.000000        0.000000   \n",
       "8                   0.000000         0.000000        0.000000   \n",
       "7                   0.000000         0.000000        0.000000   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "12                1                   0.534256          0.543317   \n",
       "15                2                   0.607431          0.609282   \n",
       "0                 3                   0.516689          0.525094   \n",
       "3                 4                   0.595728          0.597879   \n",
       "21                5                   0.981347          0.980907   \n",
       "18                6                   0.651660          0.651633   \n",
       "9                 7                   0.981888          0.981400   \n",
       "22                8                   0.997764          0.997752   \n",
       "20                9                   0.656430          0.656150   \n",
       "14               10                   0.508335          0.516685   \n",
       "6                11                   0.646123          0.645816   \n",
       "19               12                   0.656260          0.655933   \n",
       "13               13                   0.541543          0.546057   \n",
       "23               14                   0.999560          0.999581   \n",
       "10               15                   0.997758          0.997783   \n",
       "16               16                   0.610333          0.611536   \n",
       "11               17                   0.999465          0.999467   \n",
       "1                18                   0.525805          0.532582   \n",
       "2                19                   0.505870          0.514458   \n",
       "17               20                   0.608555          0.609301   \n",
       "5                21                   0.598268          0.599894   \n",
       "4                22                   0.607802          0.608721   \n",
       "8                23                   0.650599          0.650195   \n",
       "7                24                   0.652195          0.651932   \n",
       "\n",
       "    std_train_score  \n",
       "12         0.067988  \n",
       "15         0.042804  \n",
       "0          0.046485  \n",
       "3          0.044461  \n",
       "21         0.005396  \n",
       "18         0.051226  \n",
       "9          0.005219  \n",
       "22         0.000560  \n",
       "20         0.049799  \n",
       "14         0.056589  \n",
       "6          0.049376  \n",
       "19         0.049123  \n",
       "13         0.044084  \n",
       "23         0.000119  \n",
       "10         0.000608  \n",
       "16         0.042725  \n",
       "11         0.000239  \n",
       "1          0.037788  \n",
       "2          0.054650  \n",
       "17         0.040199  \n",
       "5          0.042103  \n",
       "4          0.046051  \n",
       "8          0.051778  \n",
       "7          0.052774  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_class = RandomForestClassifier(random_state=seed)\n",
    "random_forest_class_pipeline = make_pipeline(preprocessing, random_forest_class)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [10, 25, 50],\n",
    "    'randomforestclassifier__max_depth': [3, 5, 7, None],\n",
    "    'randomforestclassifier__criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "random_forest_class_gs = optimize_params(random_forest_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Time: 41.63 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbclassifier__learning_rate</th>\n",
       "      <th>param_xgbclassifier__max_depth</th>\n",
       "      <th>param_xgbclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.712597</td>\n",
       "      <td>0.230525</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.046774</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.105070</td>\n",
       "      <td>0.098658</td>\n",
       "      <td>0.127549</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965894</td>\n",
       "      <td>0.969030</td>\n",
       "      <td>0.013899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.582612</td>\n",
       "      <td>0.088868</td>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.088136</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.199940</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821873</td>\n",
       "      <td>0.826492</td>\n",
       "      <td>0.026725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.479318</td>\n",
       "      <td>0.081010</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.084442</td>\n",
       "      <td>0.117336</td>\n",
       "      <td>0.184885</td>\n",
       "      <td>3</td>\n",
       "      <td>0.768467</td>\n",
       "      <td>0.771433</td>\n",
       "      <td>0.029499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.850488</td>\n",
       "      <td>0.111831</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.025947</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.084430</td>\n",
       "      <td>0.085191</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864552</td>\n",
       "      <td>0.869948</td>\n",
       "      <td>0.025521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.545121</td>\n",
       "      <td>0.092477</td>\n",
       "      <td>0.034482</td>\n",
       "      <td>0.018251</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.084299</td>\n",
       "      <td>0.087260</td>\n",
       "      <td>0.118228</td>\n",
       "      <td>5</td>\n",
       "      <td>0.777850</td>\n",
       "      <td>0.781675</td>\n",
       "      <td>0.027427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.414579</td>\n",
       "      <td>0.080251</td>\n",
       "      <td>0.020343</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.619293</td>\n",
       "      <td>0.107739</td>\n",
       "      <td>0.031019</td>\n",
       "      <td>0.017767</td>\n",
       "      <td>0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117</td>\n",
       "      <td>0.081257</td>\n",
       "      <td>0.111098</td>\n",
       "      <td>0.222197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.045306</td>\n",
       "      <td>0.025687</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.236436</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.169307</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.05, 'xgbcla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.153873</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.166178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "115       1.712597      0.230525         0.055914        0.046774   \n",
       "119       0.582612      0.088868         0.031095        0.023577   \n",
       "118       0.479318      0.081010         0.026221        0.011816   \n",
       "111       0.850488      0.111831         0.041344        0.025947   \n",
       "107       0.545121      0.092477         0.034482        0.018251   \n",
       "..             ...           ...              ...             ...   \n",
       "32        0.414579      0.080251         0.020343        0.009281   \n",
       "30        0.619293      0.107739         0.031019        0.017767   \n",
       "29        0.360784      0.045306         0.025687        0.013171   \n",
       "28        0.236436      0.036335         0.020113        0.009628   \n",
       "60        0.169307      0.030273         0.020282        0.006061   \n",
       "\n",
       "    param_xgbclassifier__learning_rate param_xgbclassifier__max_depth  \\\n",
       "115                                0.2                             10   \n",
       "119                                0.2                           None   \n",
       "118                                0.2                           None   \n",
       "111                                0.2                              7   \n",
       "107                                0.2                              5   \n",
       "..                                 ...                            ...   \n",
       "32                               0.005                             10   \n",
       "30                               0.005                              7   \n",
       "29                               0.005                              7   \n",
       "28                               0.005                              7   \n",
       "60                                0.05                              3   \n",
       "\n",
       "    param_xgbclassifier__n_estimators  \\\n",
       "115                               100   \n",
       "119                               100   \n",
       "118                                50   \n",
       "111                               100   \n",
       "107                               100   \n",
       "..                                ...   \n",
       "32                                 10   \n",
       "30                                 50   \n",
       "29                                 25   \n",
       "28                                 10   \n",
       "60                                 10   \n",
       "\n",
       "                                                params  \\\n",
       "115  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "119  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "118  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "111  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "107  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "..                                                 ...   \n",
       "32   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "30   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "29   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "28   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "60   {'xgbclassifier__learning_rate': 0.05, 'xgbcla...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "115                  0.105070         0.098658        0.127549   \n",
       "119                  0.088136         0.125447        0.199940   \n",
       "118                  0.084442         0.117336        0.184885   \n",
       "111                  0.084430         0.085191        0.113947   \n",
       "107                  0.084299         0.087260        0.118228   \n",
       "..                        ...              ...             ...   \n",
       "32                   0.000000         0.000000        0.000000   \n",
       "30                   0.000000         0.000000        0.000000   \n",
       "29                   0.000000         0.000000        0.000000   \n",
       "28                   0.000000         0.000000        0.000000   \n",
       "60                   0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "115                1                   0.965894          0.969030   \n",
       "119                2                   0.821873          0.826492   \n",
       "118                3                   0.768467          0.771433   \n",
       "111                4                   0.864552          0.869948   \n",
       "107                5                   0.777850          0.781675   \n",
       "..               ...                        ...               ...   \n",
       "32               116                   0.000000          0.000000   \n",
       "30               117                   0.081257          0.111098   \n",
       "29               118                   0.000000          0.000000   \n",
       "28               119                   0.000000          0.000000   \n",
       "60               120                   0.153873          0.162900   \n",
       "\n",
       "     std_train_score  \n",
       "115         0.013899  \n",
       "119         0.026725  \n",
       "118         0.029499  \n",
       "111         0.025521  \n",
       "107         0.027427  \n",
       "..               ...  \n",
       "32          0.000000  \n",
       "30          0.222197  \n",
       "29          0.000000  \n",
       "28          0.000000  \n",
       "60          0.166178  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state=seed)\n",
    "xgb_class_pipeline = make_pipeline(preprocessing, xgb_class)\n",
    "\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [10, 25, 50, 100],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_class_gs = optimize_params(xgb_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n",
      "Time: 25.27 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_sgdclassifier__alpha</th>\n",
       "      <th>param_sgdclassifier__class_weight</th>\n",
       "      <th>param_sgdclassifier__loss</th>\n",
       "      <th>param_sgdclassifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.106839</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.017499</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.337901</td>\n",
       "      <td>0.277461</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600978</td>\n",
       "      <td>0.597936</td>\n",
       "      <td>0.048680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.104661</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.337901</td>\n",
       "      <td>0.277461</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600978</td>\n",
       "      <td>0.597936</td>\n",
       "      <td>0.048680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.104099</td>\n",
       "      <td>0.025456</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.337901</td>\n",
       "      <td>0.277461</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600978</td>\n",
       "      <td>0.597936</td>\n",
       "      <td>0.048680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.101880</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.337901</td>\n",
       "      <td>0.277461</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>4</td>\n",
       "      <td>0.600978</td>\n",
       "      <td>0.597936</td>\n",
       "      <td>0.048680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.335687</td>\n",
       "      <td>0.291237</td>\n",
       "      <td>0.304136</td>\n",
       "      <td>5</td>\n",
       "      <td>0.402785</td>\n",
       "      <td>0.418621</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.092733</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248</td>\n",
       "      <td>0.591671</td>\n",
       "      <td>0.592637</td>\n",
       "      <td>0.041384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.078146</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249</td>\n",
       "      <td>0.591671</td>\n",
       "      <td>0.592637</td>\n",
       "      <td>0.041384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.074364</td>\n",
       "      <td>0.019181</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.009887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.070599</td>\n",
       "      <td>0.018896</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.009887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.068830</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.017960</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.009887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "109       0.106839      0.018703         0.017499        0.005096   \n",
       "108       0.104661      0.021770         0.017772        0.007673   \n",
       "111       0.104099      0.025456         0.017521        0.009164   \n",
       "110       0.101880      0.024350         0.018087        0.007478   \n",
       "88        0.080357      0.016031         0.016584        0.004624   \n",
       "..             ...           ...              ...             ...   \n",
       "77        0.092733      0.009524         0.013852        0.006441   \n",
       "76        0.078146      0.009345         0.015945        0.004734   \n",
       "235       0.074364      0.019181         0.016471        0.003737   \n",
       "234       0.070599      0.018896         0.017299        0.005178   \n",
       "232       0.068830      0.020293         0.017960        0.006515   \n",
       "\n",
       "    param_sgdclassifier__alpha param_sgdclassifier__class_weight  \\\n",
       "109                        0.1                          balanced   \n",
       "108                        0.1                          balanced   \n",
       "111                        0.1                          balanced   \n",
       "110                        0.1                          balanced   \n",
       "88                        0.01                              None   \n",
       "..                         ...                               ...   \n",
       "77                        0.01                          balanced   \n",
       "76                        0.01                          balanced   \n",
       "235                        0.8                              None   \n",
       "234                        0.8                              None   \n",
       "232                        0.8                              None   \n",
       "\n",
       "    param_sgdclassifier__loss param_sgdclassifier__max_iter  \\\n",
       "109                  log_loss                           100   \n",
       "108                  log_loss                            50   \n",
       "111                  log_loss                          1000   \n",
       "110                  log_loss                           500   \n",
       "88                      hinge                            50   \n",
       "..                        ...                           ...   \n",
       "77                      hinge                           100   \n",
       "76                      hinge                            50   \n",
       "235                     hinge                          1000   \n",
       "234                     hinge                           500   \n",
       "232                     hinge                            50   \n",
       "\n",
       "                                                params  \\\n",
       "109  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "108  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "111  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "110  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "88   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "..                                                 ...   \n",
       "77   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "76   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "235  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "234  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "232  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "109                  0.337901         0.277461        0.342654   \n",
       "108                  0.337901         0.277461        0.342654   \n",
       "111                  0.337901         0.277461        0.342654   \n",
       "110                  0.337901         0.277461        0.342654   \n",
       "88                   0.335687         0.291237        0.304136   \n",
       "..                        ...              ...             ...   \n",
       "77                   0.000000         0.000000        0.000000   \n",
       "76                   0.000000         0.000000        0.000000   \n",
       "235                  0.000000         0.000000        0.000000   \n",
       "234                  0.000000         0.000000        0.000000   \n",
       "232                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "109                1                   0.600978          0.597936   \n",
       "108                2                   0.600978          0.597936   \n",
       "111                3                   0.600978          0.597936   \n",
       "110                4                   0.600978          0.597936   \n",
       "88                 5                   0.402785          0.418621   \n",
       "..               ...                        ...               ...   \n",
       "77               248                   0.591671          0.592637   \n",
       "76               249                   0.591671          0.592637   \n",
       "235              250                   0.003616          0.004944   \n",
       "234              251                   0.003616          0.004944   \n",
       "232              252                   0.003616          0.004944   \n",
       "\n",
       "     std_train_score  \n",
       "109         0.048680  \n",
       "108         0.048680  \n",
       "111         0.048680  \n",
       "110         0.048680  \n",
       "88          0.078940  \n",
       "..               ...  \n",
       "77          0.041384  \n",
       "76          0.041384  \n",
       "235         0.009887  \n",
       "234         0.009887  \n",
       "232         0.009887  \n",
       "\n",
       "[252 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_class = SGDClassifier(random_state=seed)\n",
    "sgd_class_pipeline = make_pipeline(preprocessing, sgd_class)\n",
    "\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "    'sgdclassifier__max_iter': [50, 100, 500, 1000],\n",
    "    'sgdclassifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'sgdclassifier__class_weight': ['balanced', None, {0:1, 1:2}]\n",
    "}\n",
    "\n",
    "sgd_class_gs = optimize_params(sgd_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.337901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbol de decision</td>\n",
       "      <td>0.333756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresion logistica</td>\n",
       "      <td>0.161044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.105070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.069194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.040365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Mejor puntuacion\n",
       "5                  SGD          0.337901\n",
       "2    Arbol de decision          0.333756\n",
       "0  Regresion logistica          0.161044\n",
       "4              XGBoost          0.105070\n",
       "3        Random Forest          0.069194\n",
       "1           KNeighbors          0.040365"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = {\n",
    "    'Regresion logistica': logistic_reg_gs,\n",
    "    'KNeighbors' : k_neighbors_class_gs,\n",
    "    'Arbol de decision': decision_tree_class_gs,\n",
    "    'Random Forest': random_forest_class_gs,\n",
    "    'XGBoost': xgb_class_gs,\n",
    "    'SGD': sgd_class_gs\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Modelo': models_dict.keys(),\n",
    "    'Mejor puntuacion': [gs.best_score_ for gs in models_dict.values()]\n",
    "})\n",
    "df_results = df_results.sort_values(by='Mejor puntuacion', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model_4\\\\ab_cu\\\\model_mediaalta_alta.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[df_results.loc[df_results.index[0], 'Modelo']].best_estimator_\n",
    "model_path = os.path.join('models', 'experiment_4', 'AB_CU', 'model_mediaalta_alta.joblib')\n",
    "dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas predicci√≥n del test\n",
      "F1:        0.6170602151497567\n",
      "Recall:    0.7964968886840286\n",
      "Precision: 0.5036065573770492\n",
      "Accuracy:  0.7054319461612416\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('models', 'experiment_4', 'AB_CU', 'model_mediaalta_alta.joblib')\n",
    "model = load(model_path)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\"\"M√©tricas predicci√≥n del test\n",
    "F1:        {f1_score(y_test, pred)}\n",
    "Recall:    {recall_score(y_test, pred)}\n",
    "Precision: {precision_score(y_test, pred)}\n",
    "Accuracy:  {accuracy_score(y_test, pred)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicci√≥n final sobre los incendios de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join('models', 'experiment_4', 'AB_CU')\n",
    "final_model = {\n",
    "    'baja_alta': load(os.path.join(folder_path, 'model_baja_alta.joblib')),\n",
    "    'baja_mediabaja': load(os.path.join(folder_path, 'model_baja_mediabaja.joblib')),\n",
    "    'mediaalta_alta': load(os.path.join(folder_path, 'model_mediaalta_alta.joblib')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fire_name in test_fire_names:\n",
    "    df_fire = df_test[df_test['incendio'] == fire_name].reset_index(drop=True)\n",
    "\n",
    "    X_fire = df_fire[variables]\n",
    "    y_fire = df_fire[target_discrete]\n",
    "    coords_fire = df_fire[coords_columns]\n",
    "\n",
    "    pred = final_model['baja_alta'].predict(X_fire)\n",
    "    predictions_baja_alta = pred\n",
    "    pred_fire = np.zeros_like(predictions_baja_alta)\n",
    "\n",
    "    if np.count_nonzero(predictions_baja_alta == 0) > 0:\n",
    "        indexes_pred_baja = X_fire.index[predictions_baja_alta == 0]\n",
    "        pred = final_model['baja_mediabaja'].predict(X_fire.loc[predictions_baja_alta == 0])\n",
    "\n",
    "\n",
    "        predictions_baja_media = pred\n",
    "        predictions_baja_media = np.where(predictions_baja_media == 0, 0, 1)\n",
    "        pred_fire[indexes_pred_baja] = predictions_baja_media\n",
    "\n",
    "    if np.count_nonzero(predictions_baja_alta == 1) > 0:\n",
    "        indexes_pred_alta = X_fire.index[predictions_baja_alta == 1]\n",
    "        pred = final_model['mediaalta_alta'].predict(X_fire.loc[predictions_baja_alta == 1])\n",
    "\n",
    "        predictions_alta_muyalta = pred\n",
    "        predictions_alta_muyalta = np.where(predictions_alta_muyalta == 0, 2, 3)\n",
    "        pred_fire[indexes_pred_alta] = predictions_alta_muyalta\n",
    "\n",
    "    matrix_fire = sm.get_severity_matrix(y_fire, coords_fire)\n",
    "    matrix_pred = sm.get_severity_matrix(pred_fire, coords_fire)\n",
    "    sm.show_original_prediction_evaluation_severity_matrices(matrix_fire, matrix_pred, fig_title=fire_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zona TO_CR_GU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['Bustares', 'Cogolludo', 'Almorox', 'Cadalso', 'Montesion', 'Villanueva_de_Bogas']\n",
      "Test:  ['Malagon', 'La_Iglesuela']\n"
     ]
    }
   ],
   "source": [
    "fire_names = list(df[df['provincia'].isin(Zona.TO_CR_GU.value)]['incendio'].unique())\n",
    "test_fire_names = ['Malagon', 'La_Iglesuela']\n",
    "train_fire_names = [x for x in fire_names if x not in test_fire_names]\n",
    "\n",
    "print(f'Train: {train_fire_names}')\n",
    "print(f'Test:  {test_fire_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevacion</th>\n",
       "      <th>erodi</th>\n",
       "      <th>slope</th>\n",
       "      <th>orientacion_sen</th>\n",
       "      <th>orientacion_cos</th>\n",
       "      <th>altura</th>\n",
       "      <th>lfcc</th>\n",
       "      <th>inflam</th>\n",
       "      <th>mcroth</th>\n",
       "      <th>anomalia</th>\n",
       "      <th>dpv</th>\n",
       "      <th>vel_media_viento</th>\n",
       "      <th>severidad_real</th>\n",
       "      <th>severidad_discreta</th>\n",
       "      <th>coord_x_etrs89</th>\n",
       "      <th>coord_y_etrs89</th>\n",
       "      <th>incendio</th>\n",
       "      <th>provincia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1286.896973</td>\n",
       "      <td>4</td>\n",
       "      <td>23.457001</td>\n",
       "      <td>-0.055359</td>\n",
       "      <td>0.998467</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.383800</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.232872</td>\n",
       "      <td>2.447998</td>\n",
       "      <td>4.317896</td>\n",
       "      <td>0.237689</td>\n",
       "      <td>0</td>\n",
       "      <td>496920.0</td>\n",
       "      <td>4558830.0</td>\n",
       "      <td>Bustares</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1301.120972</td>\n",
       "      <td>4</td>\n",
       "      <td>21.378000</td>\n",
       "      <td>-0.231134</td>\n",
       "      <td>0.972922</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.801800</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.218384</td>\n",
       "      <td>2.447738</td>\n",
       "      <td>4.317962</td>\n",
       "      <td>0.235222</td>\n",
       "      <td>0</td>\n",
       "      <td>496920.0</td>\n",
       "      <td>4558800.0</td>\n",
       "      <td>Bustares</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1339.094971</td>\n",
       "      <td>4</td>\n",
       "      <td>20.363001</td>\n",
       "      <td>0.578251</td>\n",
       "      <td>0.815859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.369110</td>\n",
       "      <td>2.450908</td>\n",
       "      <td>4.318116</td>\n",
       "      <td>0.258634</td>\n",
       "      <td>0</td>\n",
       "      <td>496620.0</td>\n",
       "      <td>4558770.0</td>\n",
       "      <td>Bustares</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1313.015991</td>\n",
       "      <td>4</td>\n",
       "      <td>28.674999</td>\n",
       "      <td>-0.287109</td>\n",
       "      <td>0.957898</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.321201</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.203880</td>\n",
       "      <td>2.447479</td>\n",
       "      <td>4.318027</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0</td>\n",
       "      <td>496920.0</td>\n",
       "      <td>4558770.0</td>\n",
       "      <td>Bustares</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1375.686035</td>\n",
       "      <td>4</td>\n",
       "      <td>13.819000</td>\n",
       "      <td>0.611061</td>\n",
       "      <td>0.791583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.357872</td>\n",
       "      <td>2.450803</td>\n",
       "      <td>4.318330</td>\n",
       "      <td>0.284624</td>\n",
       "      <td>1</td>\n",
       "      <td>496560.0</td>\n",
       "      <td>4558680.0</td>\n",
       "      <td>Bustares</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     elevacion  erodi      slope  orientacion_sen  orientacion_cos  altura  \\\n",
       "0  1286.896973      4  23.457001        -0.055359         0.998467     2.0   \n",
       "1  1301.120972      4  21.378000        -0.231134         0.972922     2.0   \n",
       "2  1339.094971      4  20.363001         0.578251         0.815859     1.0   \n",
       "3  1313.015991      4  28.674999        -0.287109         0.957898     4.0   \n",
       "4  1375.686035      4  13.819000         0.611061         0.791583     1.0   \n",
       "\n",
       "        lfcc  inflam  mcroth   anomalia       dpv  vel_media_viento  \\\n",
       "0   6.383800       3       3  78.232872  2.447998          4.317896   \n",
       "1   1.801800       3       3  78.218384  2.447738          4.317962   \n",
       "2   0.444400       3       3  78.369110  2.450908          4.318116   \n",
       "3  28.321201       3       3  78.203880  2.447479          4.318027   \n",
       "4   0.101900       3       3  78.357872  2.450803          4.318330   \n",
       "\n",
       "   severidad_real  severidad_discreta  coord_x_etrs89  coord_y_etrs89  \\\n",
       "0        0.237689                   0        496920.0       4558830.0   \n",
       "1        0.235222                   0        496920.0       4558800.0   \n",
       "2        0.258634                   0        496620.0       4558770.0   \n",
       "3        0.253629                   0        496920.0       4558770.0   \n",
       "4        0.284624                   1        496560.0       4558680.0   \n",
       "\n",
       "   incendio    provincia  \n",
       "0  Bustares  Guadalajara  \n",
       "1  Bustares  Guadalajara  \n",
       "2  Bustares  Guadalajara  \n",
       "3  Bustares  Guadalajara  \n",
       "4  Bustares  Guadalajara  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['incendio'].isin(train_fire_names)].reset_index(drop=True)\n",
    "print(len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevacion</th>\n",
       "      <th>erodi</th>\n",
       "      <th>slope</th>\n",
       "      <th>orientacion_sen</th>\n",
       "      <th>orientacion_cos</th>\n",
       "      <th>altura</th>\n",
       "      <th>lfcc</th>\n",
       "      <th>inflam</th>\n",
       "      <th>mcroth</th>\n",
       "      <th>anomalia</th>\n",
       "      <th>dpv</th>\n",
       "      <th>vel_media_viento</th>\n",
       "      <th>severidad_real</th>\n",
       "      <th>severidad_discreta</th>\n",
       "      <th>coord_x_etrs89</th>\n",
       "      <th>coord_y_etrs89</th>\n",
       "      <th>incendio</th>\n",
       "      <th>provincia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834.695007</td>\n",
       "      <td>4</td>\n",
       "      <td>13.863</td>\n",
       "      <td>0.751454</td>\n",
       "      <td>0.659785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.668000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>81.601456</td>\n",
       "      <td>3.425242</td>\n",
       "      <td>3.003078</td>\n",
       "      <td>0.191698</td>\n",
       "      <td>0</td>\n",
       "      <td>407730.0</td>\n",
       "      <td>4350900.0</td>\n",
       "      <td>Malagon</td>\n",
       "      <td>Ciudad Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>829.068970</td>\n",
       "      <td>4</td>\n",
       "      <td>13.428</td>\n",
       "      <td>0.908389</td>\n",
       "      <td>0.418126</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.096100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>81.601067</td>\n",
       "      <td>3.425281</td>\n",
       "      <td>3.003020</td>\n",
       "      <td>0.197681</td>\n",
       "      <td>0</td>\n",
       "      <td>407760.0</td>\n",
       "      <td>4350900.0</td>\n",
       "      <td>Malagon</td>\n",
       "      <td>Ciudad Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850.950989</td>\n",
       "      <td>4</td>\n",
       "      <td>14.210</td>\n",
       "      <td>0.511204</td>\n",
       "      <td>0.859459</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.678999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>81.605385</td>\n",
       "      <td>3.425198</td>\n",
       "      <td>3.003275</td>\n",
       "      <td>0.201897</td>\n",
       "      <td>0</td>\n",
       "      <td>407640.0</td>\n",
       "      <td>4350870.0</td>\n",
       "      <td>Malagon</td>\n",
       "      <td>Ciudad Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>846.922974</td>\n",
       "      <td>4</td>\n",
       "      <td>12.434</td>\n",
       "      <td>0.627528</td>\n",
       "      <td>0.778594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.818200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>81.605011</td>\n",
       "      <td>3.425238</td>\n",
       "      <td>3.003217</td>\n",
       "      <td>0.229464</td>\n",
       "      <td>0</td>\n",
       "      <td>407670.0</td>\n",
       "      <td>4350870.0</td>\n",
       "      <td>Malagon</td>\n",
       "      <td>Ciudad Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>842.739990</td>\n",
       "      <td>4</td>\n",
       "      <td>12.307</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.649348</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>81.604637</td>\n",
       "      <td>3.425277</td>\n",
       "      <td>3.003159</td>\n",
       "      <td>0.247409</td>\n",
       "      <td>0</td>\n",
       "      <td>407700.0</td>\n",
       "      <td>4350870.0</td>\n",
       "      <td>Malagon</td>\n",
       "      <td>Ciudad Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elevacion  erodi   slope  orientacion_sen  orientacion_cos  altura  \\\n",
       "0  834.695007      4  13.863         0.751454         0.659785     2.0   \n",
       "1  829.068970      4  13.428         0.908389         0.418126     8.0   \n",
       "2  850.950989      4  14.210         0.511204         0.859459     3.0   \n",
       "3  846.922974      4  12.434         0.627528         0.778594     2.0   \n",
       "4  842.739990      4  12.307         0.760491         0.649348     5.0   \n",
       "\n",
       "        lfcc  inflam  mcroth   anomalia       dpv  vel_media_viento  \\\n",
       "0   5.668000       3       1  81.601456  3.425242          3.003078   \n",
       "1  33.096100       3       1  81.601067  3.425281          3.003020   \n",
       "2  19.678999       3       1  81.605385  3.425198          3.003275   \n",
       "3   6.818200       3       1  81.605011  3.425238          3.003217   \n",
       "4   0.431000       3       1  81.604637  3.425277          3.003159   \n",
       "\n",
       "   severidad_real  severidad_discreta  coord_x_etrs89  coord_y_etrs89  \\\n",
       "0        0.191698                   0        407730.0       4350900.0   \n",
       "1        0.197681                   0        407760.0       4350900.0   \n",
       "2        0.201897                   0        407640.0       4350870.0   \n",
       "3        0.229464                   0        407670.0       4350870.0   \n",
       "4        0.247409                   0        407700.0       4350870.0   \n",
       "\n",
       "  incendio    provincia  \n",
       "0  Malagon  Ciudad Real  \n",
       "1  Malagon  Ciudad Real  \n",
       "2  Malagon  Ciudad Real  \n",
       "3  Malagon  Ciudad Real  \n",
       "4  Malagon  Ciudad Real  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[df['incendio'].isin(test_fire_names)].reset_index(drop=True)\n",
    "print(len(df_test))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baja - Alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classification = {0:0, 1:0, 2:1, 3:1}\n",
    "\n",
    "df_train_reclass = reclass(new_classification, df_train)\n",
    "df_test_reclass = reclass(new_classification, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_reclass[variables]\n",
    "y_train = df_train_reclass[target_discrete]\n",
    "\n",
    "X_test = df_test_reclass[variables]\n",
    "y_test = df_test_reclass[target_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Train: 42079\tTest:2965\n",
      "Fold 1: Train: 29091\tTest:15953\n",
      "Fold 2: Train: 33979\tTest:11065\n",
      "Fold 3: Train: 38447\tTest:6597\n",
      "Fold 4: Train: 37270\tTest:7774\n",
      "Fold 5: Train: 44354\tTest:690\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "\n",
    "for name in train_fire_names:\n",
    "    fold_train_names = [x for x in train_fire_names if x != name]\n",
    "    fold_test_name = [x for x in train_fire_names if x == name]\n",
    "\n",
    "    fold_train_indices = df_train_reclass[(df_train_reclass['incendio'].isin(fold_train_names))].index\n",
    "    fold_test_indices = df_train_reclass[df_train_reclass['incendio'].isin(fold_test_name)].index\n",
    "    folds.append((fold_train_indices, fold_test_indices))\n",
    "\n",
    "[print(f'Fold {i}: Train: {x.size}\\tTest:{y.size}') for i, (x, y) in enumerate(folds)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
      "Time: 50.52 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.477468</td>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.034725</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.328067</td>\n",
       "      <td>0.269319</td>\n",
       "      <td>0.218063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434035</td>\n",
       "      <td>0.429944</td>\n",
       "      <td>0.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.867506</td>\n",
       "      <td>0.803585</td>\n",
       "      <td>0.069676</td>\n",
       "      <td>0.041012</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.310022</td>\n",
       "      <td>0.258108</td>\n",
       "      <td>0.217352</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430343</td>\n",
       "      <td>0.426345</td>\n",
       "      <td>0.062283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.855534</td>\n",
       "      <td>0.892481</td>\n",
       "      <td>0.067421</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.304387</td>\n",
       "      <td>0.253510</td>\n",
       "      <td>0.224449</td>\n",
       "      <td>3</td>\n",
       "      <td>0.432660</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.062005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.766811</td>\n",
       "      <td>0.862665</td>\n",
       "      <td>0.061423</td>\n",
       "      <td>0.039348</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.268624</td>\n",
       "      <td>0.230382</td>\n",
       "      <td>0.233379</td>\n",
       "      <td>4</td>\n",
       "      <td>0.427949</td>\n",
       "      <td>0.423954</td>\n",
       "      <td>0.059045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.570568</td>\n",
       "      <td>0.067407</td>\n",
       "      <td>0.023154</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.224211</td>\n",
       "      <td>0.173568</td>\n",
       "      <td>0.245711</td>\n",
       "      <td>5</td>\n",
       "      <td>0.275422</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.093899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.599396</td>\n",
       "      <td>0.083247</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.224211</td>\n",
       "      <td>0.173568</td>\n",
       "      <td>0.245711</td>\n",
       "      <td>6</td>\n",
       "      <td>0.275422</td>\n",
       "      <td>0.268304</td>\n",
       "      <td>0.093899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.607276</td>\n",
       "      <td>0.083226</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.173187</td>\n",
       "      <td>0.245141</td>\n",
       "      <td>7</td>\n",
       "      <td>0.275466</td>\n",
       "      <td>0.268355</td>\n",
       "      <td>0.093801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.223302</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.245097</td>\n",
       "      <td>8</td>\n",
       "      <td>0.275465</td>\n",
       "      <td>0.268354</td>\n",
       "      <td>0.093804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.821621</td>\n",
       "      <td>0.343426</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.221817</td>\n",
       "      <td>0.172442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>9</td>\n",
       "      <td>0.275465</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.093788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.617404</td>\n",
       "      <td>0.084822</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.221791</td>\n",
       "      <td>0.172377</td>\n",
       "      <td>0.243951</td>\n",
       "      <td>10</td>\n",
       "      <td>0.275472</td>\n",
       "      <td>0.268362</td>\n",
       "      <td>0.093799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.683994</td>\n",
       "      <td>0.080322</td>\n",
       "      <td>0.028949</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.218147</td>\n",
       "      <td>0.170715</td>\n",
       "      <td>0.241504</td>\n",
       "      <td>11</td>\n",
       "      <td>0.275299</td>\n",
       "      <td>0.268104</td>\n",
       "      <td>0.094539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.937257</td>\n",
       "      <td>0.112449</td>\n",
       "      <td>0.027696</td>\n",
       "      <td>0.011972</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.218092</td>\n",
       "      <td>0.170601</td>\n",
       "      <td>0.241348</td>\n",
       "      <td>12</td>\n",
       "      <td>0.275302</td>\n",
       "      <td>0.268113</td>\n",
       "      <td>0.094420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.817779</td>\n",
       "      <td>0.893825</td>\n",
       "      <td>0.067395</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>0.174120</td>\n",
       "      <td>0.202619</td>\n",
       "      <td>13</td>\n",
       "      <td>0.404192</td>\n",
       "      <td>0.400592</td>\n",
       "      <td>0.056999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.069586</td>\n",
       "      <td>0.434502</td>\n",
       "      <td>0.060682</td>\n",
       "      <td>0.030149</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.191109</td>\n",
       "      <td>0.174987</td>\n",
       "      <td>0.198218</td>\n",
       "      <td>14</td>\n",
       "      <td>0.419801</td>\n",
       "      <td>0.416612</td>\n",
       "      <td>0.058636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.066315</td>\n",
       "      <td>0.444570</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>0.038999</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.186921</td>\n",
       "      <td>0.199459</td>\n",
       "      <td>0.180097</td>\n",
       "      <td>15</td>\n",
       "      <td>0.419397</td>\n",
       "      <td>0.415993</td>\n",
       "      <td>0.060826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.086930</td>\n",
       "      <td>0.429892</td>\n",
       "      <td>0.063592</td>\n",
       "      <td>0.039037</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.180001</td>\n",
       "      <td>0.167690</td>\n",
       "      <td>0.194626</td>\n",
       "      <td>16</td>\n",
       "      <td>0.417517</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>0.053038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.066411</td>\n",
       "      <td>0.438644</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>0.031276</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.179796</td>\n",
       "      <td>0.168367</td>\n",
       "      <td>0.193982</td>\n",
       "      <td>17</td>\n",
       "      <td>0.417681</td>\n",
       "      <td>0.414517</td>\n",
       "      <td>0.060755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.712625</td>\n",
       "      <td>0.108517</td>\n",
       "      <td>0.028064</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.176413</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>18</td>\n",
       "      <td>0.274201</td>\n",
       "      <td>0.266845</td>\n",
       "      <td>0.095962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.662442</td>\n",
       "      <td>0.079478</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.176404</td>\n",
       "      <td>0.150336</td>\n",
       "      <td>0.214199</td>\n",
       "      <td>19</td>\n",
       "      <td>0.274195</td>\n",
       "      <td>0.266841</td>\n",
       "      <td>0.095966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.049945</td>\n",
       "      <td>0.443282</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.031275</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.170562</td>\n",
       "      <td>0.181595</td>\n",
       "      <td>0.183013</td>\n",
       "      <td>20</td>\n",
       "      <td>0.402666</td>\n",
       "      <td>0.399409</td>\n",
       "      <td>0.056575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.120071</td>\n",
       "      <td>0.511512</td>\n",
       "      <td>0.061710</td>\n",
       "      <td>0.031535</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.071881</td>\n",
       "      <td>0.123372</td>\n",
       "      <td>0.174308</td>\n",
       "      <td>21</td>\n",
       "      <td>0.375668</td>\n",
       "      <td>0.371674</td>\n",
       "      <td>0.059189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.276141</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.069567</td>\n",
       "      <td>0.035930</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.061144</td>\n",
       "      <td>0.113588</td>\n",
       "      <td>0.175488</td>\n",
       "      <td>22</td>\n",
       "      <td>0.375964</td>\n",
       "      <td>0.372002</td>\n",
       "      <td>0.058496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.436467</td>\n",
       "      <td>0.081820</td>\n",
       "      <td>0.029796</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>0.092112</td>\n",
       "      <td>0.157640</td>\n",
       "      <td>23</td>\n",
       "      <td>0.268281</td>\n",
       "      <td>0.260172</td>\n",
       "      <td>0.103080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.408548</td>\n",
       "      <td>0.085073</td>\n",
       "      <td>0.033048</td>\n",
       "      <td>0.012041</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>0.092112</td>\n",
       "      <td>0.157640</td>\n",
       "      <td>24</td>\n",
       "      <td>0.268281</td>\n",
       "      <td>0.260172</td>\n",
       "      <td>0.103080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "23       5.477468      0.403473         0.034725        0.028710   \n",
       "15       7.867506      0.803585         0.069676        0.041012   \n",
       "19       7.855534      0.892481         0.067421        0.041837   \n",
       "11       7.766811      0.862665         0.061423        0.039348   \n",
       "22       0.570568      0.067407         0.023154        0.011842   \n",
       "20       0.599396      0.083247         0.024015        0.005751   \n",
       "18       0.607276      0.083226         0.030326        0.007688   \n",
       "16       0.621951      0.075334         0.036427        0.018803   \n",
       "14       0.821621      0.343426         0.030206        0.012932   \n",
       "12       0.617404      0.084822         0.026697        0.007663   \n",
       "8        0.683994      0.080322         0.028949        0.010329   \n",
       "10       0.937257      0.112449         0.027696        0.011972   \n",
       "7        7.817779      0.893825         0.067395        0.039540   \n",
       "17       4.069586      0.434502         0.060682        0.030149   \n",
       "21       4.066315      0.444570         0.065614        0.038999   \n",
       "13       4.086930      0.429892         0.063592        0.039037   \n",
       "9        4.066411      0.438644         0.064298        0.031276   \n",
       "6        0.712625      0.108517         0.028064        0.009382   \n",
       "4        0.662442      0.079478         0.028654        0.007695   \n",
       "5        4.049945      0.443282         0.062645        0.031275   \n",
       "1        4.120071      0.511512         0.061710        0.031535   \n",
       "3        6.276141      0.770000         0.069567        0.035930   \n",
       "2        0.436467      0.081820         0.029796        0.009818   \n",
       "0        0.408548      0.085073         0.033048        0.012041   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__max_iter  \\\n",
       "23                          10                                200   \n",
       "15                           2                                200   \n",
       "19                           5                                200   \n",
       "11                           1                                200   \n",
       "22                          10                                200   \n",
       "20                          10                                100   \n",
       "18                           5                                200   \n",
       "16                           5                                100   \n",
       "14                           2                                200   \n",
       "12                           2                                100   \n",
       "8                            1                                100   \n",
       "10                           1                                200   \n",
       "7                          0.1                                200   \n",
       "17                           5                                100   \n",
       "21                          10                                100   \n",
       "13                           2                                100   \n",
       "9                            1                                100   \n",
       "6                          0.1                                200   \n",
       "4                          0.1                                100   \n",
       "5                          0.1                                100   \n",
       "1                         0.01                                100   \n",
       "3                         0.01                                200   \n",
       "2                         0.01                                200   \n",
       "0                         0.01                                100   \n",
       "\n",
       "   param_polynomialfeatures__degree  \\\n",
       "23                                2   \n",
       "15                                2   \n",
       "19                                2   \n",
       "11                                2   \n",
       "22                                1   \n",
       "20                                1   \n",
       "18                                1   \n",
       "16                                1   \n",
       "14                                1   \n",
       "12                                1   \n",
       "8                                 1   \n",
       "10                                1   \n",
       "7                                 2   \n",
       "17                                2   \n",
       "21                                2   \n",
       "13                                2   \n",
       "9                                 2   \n",
       "6                                 1   \n",
       "4                                 1   \n",
       "5                                 2   \n",
       "1                                 2   \n",
       "3                                 2   \n",
       "2                                 1   \n",
       "0                                 1   \n",
       "\n",
       "                                               params  \\\n",
       "23  {'logisticregression__C': 10, 'logisticregress...   \n",
       "15  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "19  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "11  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "22  {'logisticregression__C': 10, 'logisticregress...   \n",
       "20  {'logisticregression__C': 10, 'logisticregress...   \n",
       "18  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "14  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "12  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "8   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "10  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "7   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "17  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "21  {'logisticregression__C': 10, 'logisticregress...   \n",
       "13  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "9   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "1   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "2   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "0   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "23                  0.328067         0.269319        0.218063   \n",
       "15                  0.310022         0.258108        0.217352   \n",
       "19                  0.304387         0.253510        0.224449   \n",
       "11                  0.268624         0.230382        0.233379   \n",
       "22                  0.224211         0.173568        0.245711   \n",
       "20                  0.224211         0.173568        0.245711   \n",
       "18                  0.223364         0.173187        0.245141   \n",
       "16                  0.223302         0.173158        0.245097   \n",
       "14                  0.221817         0.172442        0.244039   \n",
       "12                  0.221791         0.172377        0.243951   \n",
       "8                   0.218147         0.170715        0.241504   \n",
       "10                  0.218092         0.170601        0.241348   \n",
       "7                   0.195265         0.174120        0.202619   \n",
       "17                  0.191109         0.174987        0.198218   \n",
       "21                  0.186921         0.199459        0.180097   \n",
       "13                  0.180001         0.167690        0.194626   \n",
       "9                   0.179796         0.168367        0.193982   \n",
       "6                   0.176413         0.150358        0.214233   \n",
       "4                   0.176404         0.150336        0.214199   \n",
       "5                   0.170562         0.181595        0.183013   \n",
       "1                   0.071881         0.123372        0.174308   \n",
       "3                   0.061144         0.113588        0.175488   \n",
       "2                   0.034324         0.092112        0.157640   \n",
       "0                   0.034324         0.092112        0.157640   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "23                1                   0.434035          0.429944   \n",
       "15                2                   0.430343          0.426345   \n",
       "19                3                   0.432660          0.428467   \n",
       "11                4                   0.427949          0.423954   \n",
       "22                5                   0.275422          0.268304   \n",
       "20                6                   0.275422          0.268304   \n",
       "18                7                   0.275466          0.268355   \n",
       "16                8                   0.275465          0.268354   \n",
       "14                9                   0.275465          0.268353   \n",
       "12               10                   0.275472          0.268362   \n",
       "8                11                   0.275299          0.268104   \n",
       "10               12                   0.275302          0.268113   \n",
       "7                13                   0.404192          0.400592   \n",
       "17               14                   0.419801          0.416612   \n",
       "21               15                   0.419397          0.415993   \n",
       "13               16                   0.417517          0.414859   \n",
       "9                17                   0.417681          0.414517   \n",
       "6                18                   0.274201          0.266845   \n",
       "4                19                   0.274195          0.266841   \n",
       "5                20                   0.402666          0.399409   \n",
       "1                21                   0.375668          0.371674   \n",
       "3                22                   0.375964          0.372002   \n",
       "2                23                   0.268281          0.260172   \n",
       "0                24                   0.268281          0.260172   \n",
       "\n",
       "    std_train_score  \n",
       "23         0.060300  \n",
       "15         0.062283  \n",
       "19         0.062005  \n",
       "11         0.059045  \n",
       "22         0.093899  \n",
       "20         0.093899  \n",
       "18         0.093801  \n",
       "16         0.093804  \n",
       "14         0.093788  \n",
       "12         0.093799  \n",
       "8          0.094539  \n",
       "10         0.094420  \n",
       "7          0.056999  \n",
       "17         0.058636  \n",
       "21         0.060826  \n",
       "13         0.053038  \n",
       "9          0.060755  \n",
       "6          0.095962  \n",
       "4          0.095966  \n",
       "5          0.056575  \n",
       "1          0.059189  \n",
       "3          0.058496  \n",
       "2          0.103080  \n",
       "0          0.103080  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "logistic_reg = LogisticRegression(random_state=seed)\n",
    "logistic_reg_pipeline = make_pipeline(preprocessing, poly, logistic_reg)\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "    'logisticregression__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "logistic_reg_gs = optimize_params(logistic_reg_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "Time: 125.1 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>param_kneighborsclassifier__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050578</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>2.919525</td>\n",
       "      <td>1.755149</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.208512</td>\n",
       "      <td>0.166156</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660902</td>\n",
       "      <td>0.658861</td>\n",
       "      <td>0.028359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043218</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>2.794157</td>\n",
       "      <td>1.595406</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.208512</td>\n",
       "      <td>0.166156</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>2.934788</td>\n",
       "      <td>1.682389</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.194966</td>\n",
       "      <td>0.151469</td>\n",
       "      <td>0.139869</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>2.918144</td>\n",
       "      <td>1.571829</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.185471</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>0.141092</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>3.148540</td>\n",
       "      <td>1.855879</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.178775</td>\n",
       "      <td>0.152768</td>\n",
       "      <td>0.124551</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.037945</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>3.100795</td>\n",
       "      <td>1.795769</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>0.148671</td>\n",
       "      <td>0.122325</td>\n",
       "      <td>6</td>\n",
       "      <td>0.482093</td>\n",
       "      <td>0.477629</td>\n",
       "      <td>0.058721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>2.849734</td>\n",
       "      <td>1.612831</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>0.125395</td>\n",
       "      <td>0.131892</td>\n",
       "      <td>7</td>\n",
       "      <td>0.518858</td>\n",
       "      <td>0.514748</td>\n",
       "      <td>0.054106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039208</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>2.699676</td>\n",
       "      <td>1.511666</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.169617</td>\n",
       "      <td>0.124934</td>\n",
       "      <td>0.125778</td>\n",
       "      <td>8</td>\n",
       "      <td>0.552802</td>\n",
       "      <td>0.549399</td>\n",
       "      <td>0.046818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.041572</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>3.478439</td>\n",
       "      <td>2.006017</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.168194</td>\n",
       "      <td>0.140960</td>\n",
       "      <td>0.118577</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040245</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>3.480617</td>\n",
       "      <td>1.971207</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.163046</td>\n",
       "      <td>0.135652</td>\n",
       "      <td>0.116903</td>\n",
       "      <td>10</td>\n",
       "      <td>0.457946</td>\n",
       "      <td>0.452750</td>\n",
       "      <td>0.068004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.050578      0.005925         2.919525        1.755149   \n",
       "1       0.043218      0.009501         2.794157        1.595406   \n",
       "3       0.040237      0.009290         2.934788        1.682389   \n",
       "5       0.041096      0.008145         2.918144        1.571829   \n",
       "7       0.043000      0.003753         3.148540        1.855879   \n",
       "6       0.037945      0.003211         3.100795        1.795769   \n",
       "4       0.036476      0.008207         2.849734        1.612831   \n",
       "2       0.039208      0.002432         2.699676        1.511666   \n",
       "9       0.041572      0.005625         3.478439        2.006017   \n",
       "8       0.040245      0.009216         3.480617        1.971207   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors param_kneighborsclassifier__weights  \\\n",
       "0                                       5                             uniform   \n",
       "1                                       5                            distance   \n",
       "3                                      10                            distance   \n",
       "5                                      20                            distance   \n",
       "7                                      50                            distance   \n",
       "6                                      50                             uniform   \n",
       "4                                      20                             uniform   \n",
       "2                                      10                             uniform   \n",
       "9                                     100                            distance   \n",
       "8                                     100                             uniform   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "1  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "3  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "5  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "7  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "6  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "4  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "2  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "9  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "8  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "\n",
       "   weighted_mean_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0                  0.208512         0.166156        0.135160                1   \n",
       "1                  0.208512         0.166156        0.135160                2   \n",
       "3                  0.194966         0.151469        0.139869                3   \n",
       "5                  0.185471         0.138344        0.141092                4   \n",
       "7                  0.178775         0.152768        0.124551                5   \n",
       "6                  0.172485         0.148671        0.122325                6   \n",
       "4                  0.171309         0.125395        0.131892                7   \n",
       "2                  0.169617         0.124934        0.125778                8   \n",
       "9                  0.168194         0.140960        0.118577                9   \n",
       "8                  0.163046         0.135652        0.116903               10   \n",
       "\n",
       "   weighted_mean_train_score  mean_train_score  std_train_score  \n",
       "0                   0.660902          0.658861         0.028359  \n",
       "1                   1.000000          1.000000         0.000000  \n",
       "3                   1.000000          1.000000         0.000000  \n",
       "5                   1.000000          1.000000         0.000000  \n",
       "7                   1.000000          1.000000         0.000000  \n",
       "6                   0.482093          0.477629         0.058721  \n",
       "4                   0.518858          0.514748         0.054106  \n",
       "2                   0.552802          0.549399         0.046818  \n",
       "9                   1.000000          1.000000         0.000000  \n",
       "8                   0.457946          0.452750         0.068004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_neighbors_class = KNeighborsClassifier()\n",
    "k_neighbours_class_pipeline = make_pipeline(preprocessing, k_neighbors_class)\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_neighbors_class_gs = optimize_params(k_neighbours_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 150 candidates, totalling 900 fits\n",
      "Time: 100.4 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_decisiontreeclassifier__ccp_alpha</th>\n",
       "      <th>param_decisiontreeclassifier__criterion</th>\n",
       "      <th>param_decisiontreeclassifier__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.089677</td>\n",
       "      <td>0.333167</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.209641</td>\n",
       "      <td>0.191772</td>\n",
       "      <td>0.179814</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.100108</td>\n",
       "      <td>0.347204</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.206224</td>\n",
       "      <td>0.183229</td>\n",
       "      <td>0.166381</td>\n",
       "      <td>2</td>\n",
       "      <td>0.939169</td>\n",
       "      <td>0.942227</td>\n",
       "      <td>0.023087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.912015</td>\n",
       "      <td>0.114310</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.199325</td>\n",
       "      <td>0.185757</td>\n",
       "      <td>0.200137</td>\n",
       "      <td>3</td>\n",
       "      <td>0.554861</td>\n",
       "      <td>0.552067</td>\n",
       "      <td>0.028727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.794849</td>\n",
       "      <td>0.258438</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.198891</td>\n",
       "      <td>0.231337</td>\n",
       "      <td>0.155278</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.614005</td>\n",
       "      <td>0.266050</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.190827</td>\n",
       "      <td>0.216659</td>\n",
       "      <td>0.161021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.767653</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>0.017396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.799221</td>\n",
       "      <td>0.108525</td>\n",
       "      <td>0.016107</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.788608</td>\n",
       "      <td>0.110631</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.120386</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.054196</td>\n",
       "      <td>0.154301</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.210828</td>\n",
       "      <td>0.140350</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12        2.089677      0.333167         0.011172        0.005989   \n",
       "42        2.100108      0.347204         0.015067        0.006691   \n",
       "21        0.912015      0.114310         0.014795        0.007239   \n",
       "27        1.794849      0.258438         0.013296        0.004729   \n",
       "28        1.614005      0.266050         0.010261        0.006480   \n",
       "..             ...           ...              ...             ...   \n",
       "123       0.799221      0.108525         0.016107        0.003225   \n",
       "124       0.788608      0.110631         0.015412        0.005534   \n",
       "125       0.809200      0.120386         0.013295        0.003947   \n",
       "126       1.054196      0.154301         0.014202        0.005385   \n",
       "149       1.210828      0.140350         0.009214        0.006690   \n",
       "\n",
       "    param_decisiontreeclassifier__ccp_alpha  \\\n",
       "12                                        0   \n",
       "42                                   0.0001   \n",
       "21                                        0   \n",
       "27                                        0   \n",
       "28                                        0   \n",
       "..                                      ...   \n",
       "123                                     0.1   \n",
       "124                                     0.1   \n",
       "125                                     0.1   \n",
       "126                                     0.1   \n",
       "149                                     0.1   \n",
       "\n",
       "    param_decisiontreeclassifier__criterion  \\\n",
       "12                                  entropy   \n",
       "42                                  entropy   \n",
       "21                                     gini   \n",
       "27                                     gini   \n",
       "28                                     gini   \n",
       "..                                      ...   \n",
       "123                                 entropy   \n",
       "124                                 entropy   \n",
       "125                                 entropy   \n",
       "126                                 entropy   \n",
       "149                                    gini   \n",
       "\n",
       "    param_decisiontreeclassifier__max_depth  \\\n",
       "12                                     None   \n",
       "42                                     None   \n",
       "21                                        7   \n",
       "27                                     None   \n",
       "28                                     None   \n",
       "..                                      ...   \n",
       "123                                       5   \n",
       "124                                       5   \n",
       "125                                       5   \n",
       "126                                       7   \n",
       "149                                    None   \n",
       "\n",
       "                                                params  \\\n",
       "12   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "42   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "21   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "27   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "28   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "..                                                 ...   \n",
       "123  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "124  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "125  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "126  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "149  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "12                   0.209641         0.191772        0.179814   \n",
       "42                   0.206224         0.183229        0.166381   \n",
       "21                   0.199325         0.185757        0.200137   \n",
       "27                   0.198891         0.231337        0.155278   \n",
       "28                   0.190827         0.216659        0.161021   \n",
       "..                        ...              ...             ...   \n",
       "123                  0.000000         0.000000        0.000000   \n",
       "124                  0.000000         0.000000        0.000000   \n",
       "125                  0.000000         0.000000        0.000000   \n",
       "126                  0.000000         0.000000        0.000000   \n",
       "149                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "12                 1                   1.000000          1.000000   \n",
       "42                 2                   0.939169          0.942227   \n",
       "21                 3                   0.554861          0.552067   \n",
       "27                 4                   1.000000          1.000000   \n",
       "28                 5                   0.767653          0.766394   \n",
       "..               ...                        ...               ...   \n",
       "123              146                   0.000000          0.000000   \n",
       "124              147                   0.000000          0.000000   \n",
       "125              148                   0.000000          0.000000   \n",
       "126              149                   0.000000          0.000000   \n",
       "149              150                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "12          0.000000  \n",
       "42          0.023087  \n",
       "21          0.028727  \n",
       "27          0.000000  \n",
       "28          0.017396  \n",
       "..               ...  \n",
       "123         0.000000  \n",
       "124         0.000000  \n",
       "125         0.000000  \n",
       "126         0.000000  \n",
       "149         0.000000  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_class = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree_class_pipeline = make_pipeline(preprocessing, decision_tree_class)\n",
    "\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 50, 200],\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "decision_tree_class_gs = optimize_params(decision_tree_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
      "Time: 77.34 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.171900</td>\n",
       "      <td>0.498045</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.020372</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979732</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.698221</td>\n",
       "      <td>0.610301</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>2</td>\n",
       "      <td>0.980207</td>\n",
       "      <td>0.979952</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.607409</td>\n",
       "      <td>1.179570</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997644</td>\n",
       "      <td>0.997645</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.140020</td>\n",
       "      <td>0.155199</td>\n",
       "      <td>0.022280</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>4</td>\n",
       "      <td>0.317270</td>\n",
       "      <td>0.306951</td>\n",
       "      <td>0.123796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.922751</td>\n",
       "      <td>1.388711</td>\n",
       "      <td>0.032179</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>5</td>\n",
       "      <td>0.997637</td>\n",
       "      <td>0.997626</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.931243</td>\n",
       "      <td>2.823568</td>\n",
       "      <td>0.061179</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.437154</td>\n",
       "      <td>1.223580</td>\n",
       "      <td>0.040189</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.999522</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.752847</td>\n",
       "      <td>0.274002</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>8</td>\n",
       "      <td>0.273091</td>\n",
       "      <td>0.262658</td>\n",
       "      <td>0.119916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.317367</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.036758</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.274492</td>\n",
       "      <td>0.264153</td>\n",
       "      <td>0.120903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.018546</td>\n",
       "      <td>1.066555</td>\n",
       "      <td>0.045140</td>\n",
       "      <td>0.025577</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.385494</td>\n",
       "      <td>0.379306</td>\n",
       "      <td>0.087973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.606024</td>\n",
       "      <td>0.520345</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.393115</td>\n",
       "      <td>0.388093</td>\n",
       "      <td>0.075763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.515740</td>\n",
       "      <td>0.218661</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.401531</td>\n",
       "      <td>0.397753</td>\n",
       "      <td>0.069457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.240625</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.044493</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.324308</td>\n",
       "      <td>0.314716</td>\n",
       "      <td>0.118562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.685109</td>\n",
       "      <td>0.434446</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.319267</td>\n",
       "      <td>0.309781</td>\n",
       "      <td>0.118331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840929</td>\n",
       "      <td>0.138953</td>\n",
       "      <td>0.021073</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.273145</td>\n",
       "      <td>0.263072</td>\n",
       "      <td>0.121272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.107905</td>\n",
       "      <td>0.350272</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.273456</td>\n",
       "      <td>0.263045</td>\n",
       "      <td>0.120948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.374861</td>\n",
       "      <td>1.239344</td>\n",
       "      <td>0.046213</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.375007</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.092855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.407828</td>\n",
       "      <td>0.637572</td>\n",
       "      <td>0.033084</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.378491</td>\n",
       "      <td>0.373848</td>\n",
       "      <td>0.081393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.759074</td>\n",
       "      <td>0.265548</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.383881</td>\n",
       "      <td>0.378613</td>\n",
       "      <td>0.085116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.372582</td>\n",
       "      <td>0.936827</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>0.024485</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.320672</td>\n",
       "      <td>0.311146</td>\n",
       "      <td>0.123174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.243508</td>\n",
       "      <td>0.476261</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>0.304443</td>\n",
       "      <td>0.123976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.325341</td>\n",
       "      <td>0.210083</td>\n",
       "      <td>0.023532</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.308863</td>\n",
       "      <td>0.299125</td>\n",
       "      <td>0.127120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.976352</td>\n",
       "      <td>0.586813</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.023189</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.274861</td>\n",
       "      <td>0.264547</td>\n",
       "      <td>0.121058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.747117</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.010043</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.269245</td>\n",
       "      <td>0.259114</td>\n",
       "      <td>0.118328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "21       3.171900      0.498045         0.024750        0.012124   \n",
       "9        3.698221      0.610301         0.022213        0.010605   \n",
       "22       7.607409      1.179570         0.035084        0.017852   \n",
       "15       1.140020      0.155199         0.022280        0.011285   \n",
       "10       8.922751      1.388711         0.032179        0.020007   \n",
       "11      17.931243      2.823568         0.061179        0.030759   \n",
       "23      12.437154      1.223580         0.040189        0.023316   \n",
       "13       1.752847      0.274002         0.025833        0.009991   \n",
       "14       3.317367      0.499505         0.036758        0.017910   \n",
       "20       7.018546      1.066555         0.045140        0.025577   \n",
       "19       3.606024      0.520345         0.028627        0.016545   \n",
       "18       1.515740      0.218661         0.021722        0.010463   \n",
       "17       5.240625      0.708848         0.044493        0.020255   \n",
       "16       2.685109      0.434446         0.028771        0.010131   \n",
       "0        0.840929      0.138953         0.021073        0.008077   \n",
       "1        2.107905      0.350272         0.030491        0.011832   \n",
       "8        8.374861      1.239344         0.046213        0.020305   \n",
       "7        4.407828      0.637572         0.033084        0.012185   \n",
       "6        1.759074      0.265548         0.021676        0.009736   \n",
       "5        6.372582      0.936827         0.050233        0.024485   \n",
       "4        3.243508      0.476261         0.032120        0.014562   \n",
       "3        1.325341      0.210083         0.023532        0.006223   \n",
       "2        3.976352      0.586813         0.047625        0.023189   \n",
       "12       0.747117      0.137209         0.019274        0.010043   \n",
       "\n",
       "   param_randomforestclassifier__criterion  \\\n",
       "21                                    gini   \n",
       "9                                  entropy   \n",
       "22                                    gini   \n",
       "15                                    gini   \n",
       "10                                 entropy   \n",
       "11                                 entropy   \n",
       "23                                    gini   \n",
       "13                                    gini   \n",
       "14                                    gini   \n",
       "20                                    gini   \n",
       "19                                    gini   \n",
       "18                                    gini   \n",
       "17                                    gini   \n",
       "16                                    gini   \n",
       "0                                  entropy   \n",
       "1                                  entropy   \n",
       "8                                  entropy   \n",
       "7                                  entropy   \n",
       "6                                  entropy   \n",
       "5                                  entropy   \n",
       "4                                  entropy   \n",
       "3                                  entropy   \n",
       "2                                  entropy   \n",
       "12                                    gini   \n",
       "\n",
       "   param_randomforestclassifier__max_depth  \\\n",
       "21                                    None   \n",
       "9                                     None   \n",
       "22                                    None   \n",
       "15                                       5   \n",
       "10                                    None   \n",
       "11                                    None   \n",
       "23                                    None   \n",
       "13                                       3   \n",
       "14                                       3   \n",
       "20                                       7   \n",
       "19                                       7   \n",
       "18                                       7   \n",
       "17                                       5   \n",
       "16                                       5   \n",
       "0                                        3   \n",
       "1                                        3   \n",
       "8                                        7   \n",
       "7                                        7   \n",
       "6                                        7   \n",
       "5                                        5   \n",
       "4                                        5   \n",
       "3                                        5   \n",
       "2                                        3   \n",
       "12                                       3   \n",
       "\n",
       "   param_randomforestclassifier__n_estimators  \\\n",
       "21                                         10   \n",
       "9                                          10   \n",
       "22                                         25   \n",
       "15                                         10   \n",
       "10                                         25   \n",
       "11                                         50   \n",
       "23                                         50   \n",
       "13                                         25   \n",
       "14                                         50   \n",
       "20                                         50   \n",
       "19                                         25   \n",
       "18                                         10   \n",
       "17                                         50   \n",
       "16                                         25   \n",
       "0                                          10   \n",
       "1                                          25   \n",
       "8                                          50   \n",
       "7                                          25   \n",
       "6                                          10   \n",
       "5                                          50   \n",
       "4                                          25   \n",
       "3                                          10   \n",
       "2                                          50   \n",
       "12                                         10   \n",
       "\n",
       "                                               params  \\\n",
       "21  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "9   {'randomforestclassifier__criterion': 'entropy...   \n",
       "22  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "15  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "10  {'randomforestclassifier__criterion': 'entropy...   \n",
       "11  {'randomforestclassifier__criterion': 'entropy...   \n",
       "23  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "13  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "14  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "20  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "19  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "18  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "17  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "16  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "0   {'randomforestclassifier__criterion': 'entropy...   \n",
       "1   {'randomforestclassifier__criterion': 'entropy...   \n",
       "8   {'randomforestclassifier__criterion': 'entropy...   \n",
       "7   {'randomforestclassifier__criterion': 'entropy...   \n",
       "6   {'randomforestclassifier__criterion': 'entropy...   \n",
       "5   {'randomforestclassifier__criterion': 'entropy...   \n",
       "4   {'randomforestclassifier__criterion': 'entropy...   \n",
       "3   {'randomforestclassifier__criterion': 'entropy...   \n",
       "2   {'randomforestclassifier__criterion': 'entropy...   \n",
       "12  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "21                  0.004173         0.014632        0.020372   \n",
       "9                   0.003520         0.003849        0.008313   \n",
       "22                  0.002921         0.004387        0.005696   \n",
       "15                  0.000561         0.000638        0.001427   \n",
       "10                  0.000375         0.000427        0.000954   \n",
       "11                  0.000353         0.000166        0.000371   \n",
       "23                  0.000306         0.000269        0.000470   \n",
       "13                  0.000134         0.000338        0.000756   \n",
       "14                  0.000000         0.000000        0.000000   \n",
       "20                  0.000000         0.000000        0.000000   \n",
       "19                  0.000000         0.000000        0.000000   \n",
       "18                  0.000000         0.000000        0.000000   \n",
       "17                  0.000000         0.000000        0.000000   \n",
       "16                  0.000000         0.000000        0.000000   \n",
       "0                   0.000000         0.000000        0.000000   \n",
       "1                   0.000000         0.000000        0.000000   \n",
       "8                   0.000000         0.000000        0.000000   \n",
       "7                   0.000000         0.000000        0.000000   \n",
       "6                   0.000000         0.000000        0.000000   \n",
       "5                   0.000000         0.000000        0.000000   \n",
       "4                   0.000000         0.000000        0.000000   \n",
       "3                   0.000000         0.000000        0.000000   \n",
       "2                   0.000000         0.000000        0.000000   \n",
       "12                  0.000000         0.000000        0.000000   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "21                1                   0.979732          0.979472   \n",
       "9                 2                   0.980207          0.979952   \n",
       "22                3                   0.997644          0.997645   \n",
       "15                4                   0.317270          0.306951   \n",
       "10                5                   0.997637          0.997626   \n",
       "11                6                   0.999506          0.999490   \n",
       "23                7                   0.999546          0.999522   \n",
       "13                8                   0.273091          0.262658   \n",
       "14                9                   0.274492          0.264153   \n",
       "20               10                   0.385494          0.379306   \n",
       "19               11                   0.393115          0.388093   \n",
       "18               12                   0.401531          0.397753   \n",
       "17               13                   0.324308          0.314716   \n",
       "16               14                   0.319267          0.309781   \n",
       "0                15                   0.273145          0.263072   \n",
       "1                16                   0.273456          0.263045   \n",
       "8                17                   0.375007          0.368918   \n",
       "7                18                   0.378491          0.373848   \n",
       "6                19                   0.383881          0.378613   \n",
       "5                20                   0.320672          0.311146   \n",
       "4                21                   0.314136          0.304443   \n",
       "3                22                   0.308863          0.299125   \n",
       "2                23                   0.274861          0.264547   \n",
       "12               24                   0.269245          0.259114   \n",
       "\n",
       "    std_train_score  \n",
       "21         0.002980  \n",
       "9          0.002563  \n",
       "22         0.000279  \n",
       "15         0.123796  \n",
       "10         0.000252  \n",
       "11         0.000208  \n",
       "23         0.000208  \n",
       "13         0.119916  \n",
       "14         0.120903  \n",
       "20         0.087973  \n",
       "19         0.075763  \n",
       "18         0.069457  \n",
       "17         0.118562  \n",
       "16         0.118331  \n",
       "0          0.121272  \n",
       "1          0.120948  \n",
       "8          0.092855  \n",
       "7          0.081393  \n",
       "6          0.085116  \n",
       "5          0.123174  \n",
       "4          0.123976  \n",
       "3          0.127120  \n",
       "2          0.121058  \n",
       "12         0.118328  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_class = RandomForestClassifier(random_state=seed)\n",
    "random_forest_class_pipeline = make_pipeline(preprocessing, random_forest_class)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [10, 25, 50],\n",
    "    'randomforestclassifier__max_depth': [3, 5, 7, None],\n",
    "    'randomforestclassifier__criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "random_forest_class_gs = optimize_params(random_forest_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 120 candidates, totalling 720 fits\n",
      "Time: 74.82 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbclassifier__learning_rate</th>\n",
       "      <th>param_xgbclassifier__max_depth</th>\n",
       "      <th>param_xgbclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.619826</td>\n",
       "      <td>0.056978</td>\n",
       "      <td>0.025741</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.042758</td>\n",
       "      <td>0.079593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.743411</td>\n",
       "      <td>0.019498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4.528680</td>\n",
       "      <td>0.296047</td>\n",
       "      <td>0.068455</td>\n",
       "      <td>0.037767</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.01, 'xgbcla...</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.050547</td>\n",
       "      <td>0.111124</td>\n",
       "      <td>2</td>\n",
       "      <td>0.624439</td>\n",
       "      <td>0.622239</td>\n",
       "      <td>0.045611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.343019</td>\n",
       "      <td>0.044042</td>\n",
       "      <td>0.022404</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>0.029190</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>3</td>\n",
       "      <td>0.578310</td>\n",
       "      <td>0.576625</td>\n",
       "      <td>0.037305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.329848</td>\n",
       "      <td>0.091318</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.05, 'xgbcla...</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>0.058597</td>\n",
       "      <td>4</td>\n",
       "      <td>0.681105</td>\n",
       "      <td>0.680112</td>\n",
       "      <td>0.031764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.675671</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.1, 'xgbclas...</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.026705</td>\n",
       "      <td>0.057838</td>\n",
       "      <td>5</td>\n",
       "      <td>0.641850</td>\n",
       "      <td>0.639759</td>\n",
       "      <td>0.038148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.503565</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.364597</td>\n",
       "      <td>0.136188</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.686232</td>\n",
       "      <td>0.081455</td>\n",
       "      <td>0.027669</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.642012</td>\n",
       "      <td>0.121735</td>\n",
       "      <td>0.052642</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>0.005</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>0.121341</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>0.043511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.254655</td>\n",
       "      <td>0.037887</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.05, 'xgbcla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "112       0.619826      0.056978         0.025741        0.006026   \n",
       "55        4.528680      0.296047         0.068455        0.037767   \n",
       "108       0.343019      0.044042         0.022404        0.010285   \n",
       "73        1.329848      0.091318         0.034103        0.017067   \n",
       "92        0.675671      0.052347         0.026636        0.011221   \n",
       "..             ...           ...              ...             ...   \n",
       "34        2.503565      0.269800         0.047105        0.023195   \n",
       "33        1.364597      0.136188         0.036662        0.015801   \n",
       "32        0.686232      0.081455         0.027669        0.009226   \n",
       "31        1.642012      0.121735         0.052642        0.028866   \n",
       "60        0.254655      0.037887         0.021281        0.008480   \n",
       "\n",
       "    param_xgbclassifier__learning_rate param_xgbclassifier__max_depth  \\\n",
       "112                                0.2                             10   \n",
       "55                                0.01                             10   \n",
       "108                                0.2                              7   \n",
       "73                                0.05                             10   \n",
       "92                                 0.1                             10   \n",
       "..                                 ...                            ...   \n",
       "34                               0.005                             10   \n",
       "33                               0.005                             10   \n",
       "32                               0.005                             10   \n",
       "31                               0.005                              7   \n",
       "60                                0.05                              3   \n",
       "\n",
       "    param_xgbclassifier__n_estimators  \\\n",
       "112                                10   \n",
       "55                                100   \n",
       "108                                10   \n",
       "73                                 25   \n",
       "92                                 10   \n",
       "..                                ...   \n",
       "34                                 50   \n",
       "33                                 25   \n",
       "32                                 10   \n",
       "31                                100   \n",
       "60                                 10   \n",
       "\n",
       "                                                params  \\\n",
       "112  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "55   {'xgbclassifier__learning_rate': 0.01, 'xgbcla...   \n",
       "108  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "73   {'xgbclassifier__learning_rate': 0.05, 'xgbcla...   \n",
       "92   {'xgbclassifier__learning_rate': 0.1, 'xgbclas...   \n",
       "..                                                 ...   \n",
       "34   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "33   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "32   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "31   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "60   {'xgbclassifier__learning_rate': 0.05, 'xgbcla...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "112                  0.021082         0.042758        0.079593   \n",
       "55                   0.020926         0.050547        0.111124   \n",
       "108                  0.012481         0.029190        0.063804   \n",
       "73                   0.012210         0.027501        0.058597   \n",
       "92                   0.011701         0.026705        0.057838   \n",
       "..                        ...              ...             ...   \n",
       "34                   0.000000         0.000000        0.000000   \n",
       "33                   0.000000         0.000000        0.000000   \n",
       "32                   0.000000         0.000000        0.000000   \n",
       "31                   0.000000         0.000000        0.000000   \n",
       "60                   0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "112                1                   0.743651          0.743411   \n",
       "55                 2                   0.624439          0.622239   \n",
       "108                3                   0.578310          0.576625   \n",
       "73                 4                   0.681105          0.680112   \n",
       "92                 5                   0.641850          0.639759   \n",
       "..               ...                        ...               ...   \n",
       "34               116                   0.000000          0.000000   \n",
       "33               117                   0.000000          0.000000   \n",
       "32               118                   0.000000          0.000000   \n",
       "31               119                   0.121341          0.118194   \n",
       "60               120                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "112         0.019498  \n",
       "55          0.045611  \n",
       "108         0.037305  \n",
       "73          0.031764  \n",
       "92          0.038148  \n",
       "..               ...  \n",
       "34          0.000000  \n",
       "33          0.000000  \n",
       "32          0.000000  \n",
       "31          0.043511  \n",
       "60          0.000000  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state=seed)\n",
    "xgb_class_pipeline = make_pipeline(preprocessing, xgb_class)\n",
    "\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [10, 25, 50, 100],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_class_gs = optimize_params(xgb_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 252 candidates, totalling 1512 fits\n",
      "Time: 45.14 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_sgdclassifier__alpha</th>\n",
       "      <th>param_sgdclassifier__class_weight</th>\n",
       "      <th>param_sgdclassifier__loss</th>\n",
       "      <th>param_sgdclassifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.152726</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.350674</td>\n",
       "      <td>0.268210</td>\n",
       "      <td>0.190779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.457453</td>\n",
       "      <td>0.021084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.150715</td>\n",
       "      <td>0.021639</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.350674</td>\n",
       "      <td>0.268210</td>\n",
       "      <td>0.190779</td>\n",
       "      <td>2</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.457453</td>\n",
       "      <td>0.021084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.157201</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.350674</td>\n",
       "      <td>0.268210</td>\n",
       "      <td>0.190779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.457453</td>\n",
       "      <td>0.021084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.157612</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.350674</td>\n",
       "      <td>0.268210</td>\n",
       "      <td>0.190779</td>\n",
       "      <td>4</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.457453</td>\n",
       "      <td>0.021084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372286</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>0.019853</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.0001, 'sgdclassifie...</td>\n",
       "      <td>0.331102</td>\n",
       "      <td>0.276159</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>5</td>\n",
       "      <td>0.481231</td>\n",
       "      <td>0.479786</td>\n",
       "      <td>0.026106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.122780</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.5, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.126336</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.5, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.209552</td>\n",
       "      <td>0.026349</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.198323</td>\n",
       "      <td>0.019910</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.126633</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "216       0.152726      0.023964         0.017435        0.007774   \n",
       "219       0.150715      0.021639         0.019129        0.004361   \n",
       "218       0.157201      0.028433         0.015185        0.006900   \n",
       "217       0.157612      0.023902         0.015475        0.004819   \n",
       "0         0.372286      0.044180         0.019853        0.008268   \n",
       "..             ...           ...              ...             ...   \n",
       "197       0.122780      0.017267         0.016116        0.006597   \n",
       "199       0.126336      0.015238         0.018314        0.005445   \n",
       "55        0.209552      0.026349         0.019240        0.006696   \n",
       "54        0.198323      0.019910         0.016726        0.008971   \n",
       "126       0.126633      0.014881         0.015457        0.003453   \n",
       "\n",
       "    param_sgdclassifier__alpha param_sgdclassifier__class_weight  \\\n",
       "216                        0.8                          balanced   \n",
       "219                        0.8                          balanced   \n",
       "218                        0.8                          balanced   \n",
       "217                        0.8                          balanced   \n",
       "0                       0.0001                          balanced   \n",
       "..                         ...                               ...   \n",
       "197                        0.5                              None   \n",
       "199                        0.5                              None   \n",
       "55                       0.001                              None   \n",
       "54                       0.001                              None   \n",
       "126                        0.1                              None   \n",
       "\n",
       "    param_sgdclassifier__loss param_sgdclassifier__max_iter  \\\n",
       "216                  log_loss                            50   \n",
       "219                  log_loss                          1000   \n",
       "218                  log_loss                           500   \n",
       "217                  log_loss                           100   \n",
       "0                    log_loss                            50   \n",
       "..                        ...                           ...   \n",
       "197                     hinge                           100   \n",
       "199                     hinge                          1000   \n",
       "55                      hinge                          1000   \n",
       "54                      hinge                           500   \n",
       "126                     hinge                           500   \n",
       "\n",
       "                                                params  \\\n",
       "216  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "219  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "218  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "217  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "0    {'sgdclassifier__alpha': 0.0001, 'sgdclassifie...   \n",
       "..                                                 ...   \n",
       "197  {'sgdclassifier__alpha': 0.5, 'sgdclassifier__...   \n",
       "199  {'sgdclassifier__alpha': 0.5, 'sgdclassifier__...   \n",
       "55   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "54   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "126  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "216                  0.350674         0.268210        0.190779   \n",
       "219                  0.350674         0.268210        0.190779   \n",
       "218                  0.350674         0.268210        0.190779   \n",
       "217                  0.350674         0.268210        0.190779   \n",
       "0                    0.331102         0.276159        0.205440   \n",
       "..                        ...              ...             ...   \n",
       "197                  0.000000         0.000000        0.000000   \n",
       "199                  0.000000         0.000000        0.000000   \n",
       "55                   0.000000         0.000000        0.000000   \n",
       "54                   0.000000         0.000000        0.000000   \n",
       "126                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "216                1                   0.457606          0.457453   \n",
       "219                2                   0.457606          0.457453   \n",
       "218                3                   0.457606          0.457453   \n",
       "217                4                   0.457606          0.457453   \n",
       "0                  5                   0.481231          0.479786   \n",
       "..               ...                        ...               ...   \n",
       "197              248                   0.000000          0.000000   \n",
       "199              249                   0.000000          0.000000   \n",
       "55               250                   0.000000          0.000000   \n",
       "54               251                   0.000000          0.000000   \n",
       "126              252                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "216         0.021084  \n",
       "219         0.021084  \n",
       "218         0.021084  \n",
       "217         0.021084  \n",
       "0           0.026106  \n",
       "..               ...  \n",
       "197         0.000000  \n",
       "199         0.000000  \n",
       "55          0.000000  \n",
       "54          0.000000  \n",
       "126         0.000000  \n",
       "\n",
       "[252 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_class = SGDClassifier(random_state=seed)\n",
    "sgd_class_pipeline = make_pipeline(preprocessing, sgd_class)\n",
    "\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "    'sgdclassifier__max_iter': [50, 100, 500, 1000],\n",
    "    'sgdclassifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'sgdclassifier__class_weight': ['balanced', None, {0:1, 1:2}]\n",
    "}\n",
    "\n",
    "sgd_class_gs = optimize_params(sgd_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.350674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresion logistica</td>\n",
       "      <td>0.328067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbol de decision</td>\n",
       "      <td>0.209641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.208512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.021082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.004173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Mejor puntuacion\n",
       "5                  SGD          0.350674\n",
       "0  Regresion logistica          0.328067\n",
       "2    Arbol de decision          0.209641\n",
       "1           KNeighbors          0.208512\n",
       "4              XGBoost          0.021082\n",
       "3        Random Forest          0.004173"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = {\n",
    "    'Regresion logistica': logistic_reg_gs,\n",
    "    'KNeighbors' : k_neighbors_class_gs,\n",
    "    'Arbol de decision': decision_tree_class_gs,\n",
    "    'Random Forest': random_forest_class_gs,\n",
    "    'XGBoost': xgb_class_gs,\n",
    "    'SGD': sgd_class_gs\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Modelo': models_dict.keys(),\n",
    "    'Mejor puntuacion': [gs.best_score_ for gs in models_dict.values()]\n",
    "})\n",
    "df_results = df_results.sort_values(by='Mejor puntuacion', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model_4\\\\to_cr_gu\\\\model_baja_alta.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[df_results.loc[df_results.index[0], 'Modelo']].best_estimator_\n",
    "model_path = os.path.join('models', 'experiment_4', 'TO_CR_GU', 'model_baja_alta.joblib')\n",
    "dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas predicci√≥n del test\n",
      "F1:        0.4301196774359237\n",
      "Recall:    0.3691588785046729\n",
      "Precision: 0.5151962593823058\n",
      "Accuracy:  0.4431059579380615\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('models', 'experiment_4', 'TO_CR_GU', 'model_baja_alta.joblib')\n",
    "model = load(model_path)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\"\"M√©tricas predicci√≥n del test\n",
    "F1:        {f1_score(y_test, pred)}\n",
    "Recall:    {recall_score(y_test, pred)}\n",
    "Precision: {precision_score(y_test, pred)}\n",
    "Accuracy:  {accuracy_score(y_test, pred)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baja - Media baja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classification = {0:0, 1:1}\n",
    "\n",
    "df_train_reclass = reclass(new_classification, df_train)\n",
    "df_test_reclass = reclass(new_classification, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_reclass[variables]\n",
    "y_train = df_train_reclass[target_discrete]\n",
    "\n",
    "X_test = df_test_reclass[variables]\n",
    "y_test = df_test_reclass[target_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Train: 29816\tTest:1981\n",
      "Fold 1: Train: 21861\tTest:9936\n",
      "Fold 2: Train: 24104\tTest:7693\n",
      "Fold 3: Train: 26757\tTest:5040\n",
      "Fold 4: Train: 25329\tTest:6468\n",
      "Fold 5: Train: 31118\tTest:679\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "\n",
    "for name in train_fire_names:\n",
    "    fold_train_names = [x for x in train_fire_names if x != name]\n",
    "    fold_test_name = [x for x in train_fire_names if x == name]\n",
    "\n",
    "    fold_train_indices = df_train_reclass[(df_train_reclass['incendio'].isin(fold_train_names))].index\n",
    "    fold_test_indices = df_train_reclass[df_train_reclass['incendio'].isin(fold_test_name)].index\n",
    "    folds.append((fold_train_indices, fold_test_indices))\n",
    "\n",
    "[print(f'Fold {i}: Train: {x.size}\\tTest:{y.size}') for i, (x, y) in enumerate(folds)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
      "Time: 35.72 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.026008</td>\n",
       "      <td>0.314447</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>0.022974</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.480431</td>\n",
       "      <td>0.450903</td>\n",
       "      <td>0.323727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742848</td>\n",
       "      <td>0.743425</td>\n",
       "      <td>0.018818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.340935</td>\n",
       "      <td>0.384898</td>\n",
       "      <td>0.051452</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.479706</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.319535</td>\n",
       "      <td>2</td>\n",
       "      <td>0.742678</td>\n",
       "      <td>0.743273</td>\n",
       "      <td>0.018711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211677</td>\n",
       "      <td>0.043713</td>\n",
       "      <td>0.017601</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.387618</td>\n",
       "      <td>0.386613</td>\n",
       "      <td>0.284936</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714579</td>\n",
       "      <td>0.715370</td>\n",
       "      <td>0.022997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260102</td>\n",
       "      <td>0.042648</td>\n",
       "      <td>0.022684</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.387618</td>\n",
       "      <td>0.386613</td>\n",
       "      <td>0.284936</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714579</td>\n",
       "      <td>0.715370</td>\n",
       "      <td>0.022997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.339276</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.375032</td>\n",
       "      <td>0.347372</td>\n",
       "      <td>0.332697</td>\n",
       "      <td>5</td>\n",
       "      <td>0.712902</td>\n",
       "      <td>0.713697</td>\n",
       "      <td>0.025149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.358246</td>\n",
       "      <td>0.123557</td>\n",
       "      <td>0.023455</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.375032</td>\n",
       "      <td>0.347372</td>\n",
       "      <td>0.332697</td>\n",
       "      <td>6</td>\n",
       "      <td>0.712902</td>\n",
       "      <td>0.713697</td>\n",
       "      <td>0.025149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.382517</td>\n",
       "      <td>0.139918</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.374746</td>\n",
       "      <td>0.346656</td>\n",
       "      <td>0.333305</td>\n",
       "      <td>7</td>\n",
       "      <td>0.712905</td>\n",
       "      <td>0.713712</td>\n",
       "      <td>0.025096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.368383</td>\n",
       "      <td>0.127230</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.374746</td>\n",
       "      <td>0.346656</td>\n",
       "      <td>0.333305</td>\n",
       "      <td>8</td>\n",
       "      <td>0.712906</td>\n",
       "      <td>0.713713</td>\n",
       "      <td>0.025098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.098755</td>\n",
       "      <td>0.021748</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.374744</td>\n",
       "      <td>0.346651</td>\n",
       "      <td>0.333310</td>\n",
       "      <td>9</td>\n",
       "      <td>0.712929</td>\n",
       "      <td>0.713730</td>\n",
       "      <td>0.025174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.088989</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.374744</td>\n",
       "      <td>0.346651</td>\n",
       "      <td>0.333310</td>\n",
       "      <td>10</td>\n",
       "      <td>0.712929</td>\n",
       "      <td>0.713730</td>\n",
       "      <td>0.025174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.384660</td>\n",
       "      <td>0.098816</td>\n",
       "      <td>0.024905</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.374314</td>\n",
       "      <td>0.345501</td>\n",
       "      <td>0.334370</td>\n",
       "      <td>11</td>\n",
       "      <td>0.712885</td>\n",
       "      <td>0.713697</td>\n",
       "      <td>0.024999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.381327</td>\n",
       "      <td>0.118396</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.374314</td>\n",
       "      <td>0.345501</td>\n",
       "      <td>0.334370</td>\n",
       "      <td>12</td>\n",
       "      <td>0.712876</td>\n",
       "      <td>0.713686</td>\n",
       "      <td>0.024983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.446293</td>\n",
       "      <td>0.074790</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.372636</td>\n",
       "      <td>0.341542</td>\n",
       "      <td>0.337876</td>\n",
       "      <td>13</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.714412</td>\n",
       "      <td>0.024265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.436937</td>\n",
       "      <td>0.072158</td>\n",
       "      <td>0.028325</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.372636</td>\n",
       "      <td>0.341542</td>\n",
       "      <td>0.337876</td>\n",
       "      <td>14</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.714412</td>\n",
       "      <td>0.024265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.650173</td>\n",
       "      <td>0.602522</td>\n",
       "      <td>0.047999</td>\n",
       "      <td>0.024332</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.353287</td>\n",
       "      <td>0.358177</td>\n",
       "      <td>0.364517</td>\n",
       "      <td>15</td>\n",
       "      <td>0.745390</td>\n",
       "      <td>0.745986</td>\n",
       "      <td>0.018496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.902292</td>\n",
       "      <td>0.309739</td>\n",
       "      <td>0.054734</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.352002</td>\n",
       "      <td>0.357478</td>\n",
       "      <td>0.364075</td>\n",
       "      <td>16</td>\n",
       "      <td>0.745021</td>\n",
       "      <td>0.745604</td>\n",
       "      <td>0.018630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.929957</td>\n",
       "      <td>0.289367</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.022050</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.331051</td>\n",
       "      <td>0.346323</td>\n",
       "      <td>0.358136</td>\n",
       "      <td>17</td>\n",
       "      <td>0.745273</td>\n",
       "      <td>0.745835</td>\n",
       "      <td>0.019082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.946281</td>\n",
       "      <td>0.360669</td>\n",
       "      <td>0.046236</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.331008</td>\n",
       "      <td>0.346299</td>\n",
       "      <td>0.358125</td>\n",
       "      <td>18</td>\n",
       "      <td>0.745122</td>\n",
       "      <td>0.745728</td>\n",
       "      <td>0.018870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.847145</td>\n",
       "      <td>0.341780</td>\n",
       "      <td>0.047279</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.328308</td>\n",
       "      <td>0.344859</td>\n",
       "      <td>0.357476</td>\n",
       "      <td>19</td>\n",
       "      <td>0.744911</td>\n",
       "      <td>0.745463</td>\n",
       "      <td>0.019033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.979507</td>\n",
       "      <td>0.349732</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.327958</td>\n",
       "      <td>0.344673</td>\n",
       "      <td>0.357394</td>\n",
       "      <td>20</td>\n",
       "      <td>0.744888</td>\n",
       "      <td>0.745466</td>\n",
       "      <td>0.018835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.579978</td>\n",
       "      <td>0.570797</td>\n",
       "      <td>0.047831</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.327528</td>\n",
       "      <td>0.344443</td>\n",
       "      <td>0.357294</td>\n",
       "      <td>21</td>\n",
       "      <td>0.745770</td>\n",
       "      <td>0.746384</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.589689</td>\n",
       "      <td>0.563305</td>\n",
       "      <td>0.050249</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.325104</td>\n",
       "      <td>0.343150</td>\n",
       "      <td>0.356742</td>\n",
       "      <td>22</td>\n",
       "      <td>0.745918</td>\n",
       "      <td>0.746485</td>\n",
       "      <td>0.018914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.700857</td>\n",
       "      <td>0.539210</td>\n",
       "      <td>0.046287</td>\n",
       "      <td>0.024738</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.323267</td>\n",
       "      <td>0.342171</td>\n",
       "      <td>0.356339</td>\n",
       "      <td>23</td>\n",
       "      <td>0.745613</td>\n",
       "      <td>0.746232</td>\n",
       "      <td>0.019165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.921487</td>\n",
       "      <td>0.256541</td>\n",
       "      <td>0.024695</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.322325</td>\n",
       "      <td>0.341668</td>\n",
       "      <td>0.356137</td>\n",
       "      <td>24</td>\n",
       "      <td>0.745494</td>\n",
       "      <td>0.746137</td>\n",
       "      <td>0.019371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1        3.026008      0.314447         0.053672        0.022974   \n",
       "3        4.340935      0.384898         0.051452        0.023202   \n",
       "0        0.211677      0.043713         0.017601        0.003493   \n",
       "2        0.260102      0.042648         0.022684        0.006969   \n",
       "22       0.339276      0.092883         0.022816        0.011926   \n",
       "20       0.358246      0.123557         0.023455        0.003712   \n",
       "14       0.382517      0.139918         0.023334        0.008015   \n",
       "12       0.368383      0.127230         0.022800        0.006664   \n",
       "16       0.348225      0.098755         0.021748        0.008080   \n",
       "18       0.327869      0.088989         0.022906        0.006724   \n",
       "8        0.384660      0.098816         0.024905        0.003619   \n",
       "10       0.381327      0.118396         0.024391        0.009920   \n",
       "6        0.446293      0.074790         0.022108        0.005895   \n",
       "4        0.436937      0.072158         0.028325        0.009151   \n",
       "7        5.650173      0.602522         0.047999        0.024332   \n",
       "5        2.902292      0.309739         0.054734        0.022857   \n",
       "9        2.929957      0.289367         0.049064        0.022050   \n",
       "13       2.946281      0.360669         0.046236        0.021886   \n",
       "21       2.847145      0.341780         0.047279        0.022954   \n",
       "17       2.979507      0.349732         0.051062        0.026117   \n",
       "11       5.579978      0.570797         0.047831        0.021488   \n",
       "15       5.589689      0.563305         0.050249        0.022318   \n",
       "19       5.700857      0.539210         0.046287        0.024738   \n",
       "23       3.921487      0.256541         0.024695        0.020840   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__max_iter  \\\n",
       "1                         0.01                                100   \n",
       "3                         0.01                                200   \n",
       "0                         0.01                                100   \n",
       "2                         0.01                                200   \n",
       "22                          10                                200   \n",
       "20                          10                                100   \n",
       "14                           2                                200   \n",
       "12                           2                                100   \n",
       "16                           5                                100   \n",
       "18                           5                                200   \n",
       "8                            1                                100   \n",
       "10                           1                                200   \n",
       "6                          0.1                                200   \n",
       "4                          0.1                                100   \n",
       "7                          0.1                                200   \n",
       "5                          0.1                                100   \n",
       "9                            1                                100   \n",
       "13                           2                                100   \n",
       "21                          10                                100   \n",
       "17                           5                                100   \n",
       "11                           1                                200   \n",
       "15                           2                                200   \n",
       "19                           5                                200   \n",
       "23                          10                                200   \n",
       "\n",
       "   param_polynomialfeatures__degree  \\\n",
       "1                                 2   \n",
       "3                                 2   \n",
       "0                                 1   \n",
       "2                                 1   \n",
       "22                                1   \n",
       "20                                1   \n",
       "14                                1   \n",
       "12                                1   \n",
       "16                                1   \n",
       "18                                1   \n",
       "8                                 1   \n",
       "10                                1   \n",
       "6                                 1   \n",
       "4                                 1   \n",
       "7                                 2   \n",
       "5                                 2   \n",
       "9                                 2   \n",
       "13                                2   \n",
       "21                                2   \n",
       "17                                2   \n",
       "11                                2   \n",
       "15                                2   \n",
       "19                                2   \n",
       "23                                2   \n",
       "\n",
       "                                               params  \\\n",
       "1   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "0   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "2   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "22  {'logisticregression__C': 10, 'logisticregress...   \n",
       "20  {'logisticregression__C': 10, 'logisticregress...   \n",
       "14  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "12  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "18  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "8   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "10  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "7   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "9   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "13  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "21  {'logisticregression__C': 10, 'logisticregress...   \n",
       "17  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "11  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "19  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "23  {'logisticregression__C': 10, 'logisticregress...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "1                   0.480431         0.450903        0.323727   \n",
       "3                   0.479706         0.453200        0.319535   \n",
       "0                   0.387618         0.386613        0.284936   \n",
       "2                   0.387618         0.386613        0.284936   \n",
       "22                  0.375032         0.347372        0.332697   \n",
       "20                  0.375032         0.347372        0.332697   \n",
       "14                  0.374746         0.346656        0.333305   \n",
       "12                  0.374746         0.346656        0.333305   \n",
       "16                  0.374744         0.346651        0.333310   \n",
       "18                  0.374744         0.346651        0.333310   \n",
       "8                   0.374314         0.345501        0.334370   \n",
       "10                  0.374314         0.345501        0.334370   \n",
       "6                   0.372636         0.341542        0.337876   \n",
       "4                   0.372636         0.341542        0.337876   \n",
       "7                   0.353287         0.358177        0.364517   \n",
       "5                   0.352002         0.357478        0.364075   \n",
       "9                   0.331051         0.346323        0.358136   \n",
       "13                  0.331008         0.346299        0.358125   \n",
       "21                  0.328308         0.344859        0.357476   \n",
       "17                  0.327958         0.344673        0.357394   \n",
       "11                  0.327528         0.344443        0.357294   \n",
       "15                  0.325104         0.343150        0.356742   \n",
       "19                  0.323267         0.342171        0.356339   \n",
       "23                  0.322325         0.341668        0.356137   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "1                 1                   0.742848          0.743425   \n",
       "3                 2                   0.742678          0.743273   \n",
       "0                 3                   0.714579          0.715370   \n",
       "2                 4                   0.714579          0.715370   \n",
       "22                5                   0.712902          0.713697   \n",
       "20                6                   0.712902          0.713697   \n",
       "14                7                   0.712905          0.713712   \n",
       "12                8                   0.712906          0.713713   \n",
       "16                9                   0.712929          0.713730   \n",
       "18               10                   0.712929          0.713730   \n",
       "8                11                   0.712885          0.713697   \n",
       "10               12                   0.712876          0.713686   \n",
       "6                13                   0.713580          0.714412   \n",
       "4                14                   0.713580          0.714412   \n",
       "7                15                   0.745390          0.745986   \n",
       "5                16                   0.745021          0.745604   \n",
       "9                17                   0.745273          0.745835   \n",
       "13               18                   0.745122          0.745728   \n",
       "21               19                   0.744911          0.745463   \n",
       "17               20                   0.744888          0.745466   \n",
       "11               21                   0.745770          0.746384   \n",
       "15               22                   0.745918          0.746485   \n",
       "19               23                   0.745613          0.746232   \n",
       "23               24                   0.745494          0.746137   \n",
       "\n",
       "    std_train_score  \n",
       "1          0.018818  \n",
       "3          0.018711  \n",
       "0          0.022997  \n",
       "2          0.022997  \n",
       "22         0.025149  \n",
       "20         0.025149  \n",
       "14         0.025096  \n",
       "12         0.025098  \n",
       "16         0.025174  \n",
       "18         0.025174  \n",
       "8          0.024999  \n",
       "10         0.024983  \n",
       "6          0.024265  \n",
       "4          0.024265  \n",
       "7          0.018496  \n",
       "5          0.018630  \n",
       "9          0.019082  \n",
       "13         0.018870  \n",
       "21         0.019033  \n",
       "17         0.018835  \n",
       "11         0.019200  \n",
       "15         0.018914  \n",
       "19         0.019165  \n",
       "23         0.019371  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "logistic_reg = LogisticRegression(random_state=seed)\n",
    "logistic_reg_pipeline = make_pipeline(preprocessing, poly, logistic_reg)\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "    'logisticregression__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "logistic_reg_gs = optimize_params(logistic_reg_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "Time: 66.27 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>param_kneighborsclassifier__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.036361</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>2.113520</td>\n",
       "      <td>1.147870</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.576050</td>\n",
       "      <td>0.573447</td>\n",
       "      <td>0.108429</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>1.738308</td>\n",
       "      <td>0.911750</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.573137</td>\n",
       "      <td>0.561617</td>\n",
       "      <td>0.096263</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.032525</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>2.023561</td>\n",
       "      <td>1.070854</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.570402</td>\n",
       "      <td>0.569010</td>\n",
       "      <td>0.112740</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750195</td>\n",
       "      <td>0.750469</td>\n",
       "      <td>0.016627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028093</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>1.490033</td>\n",
       "      <td>0.756451</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.564404</td>\n",
       "      <td>0.548180</td>\n",
       "      <td>0.084426</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030545</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>1.601805</td>\n",
       "      <td>0.810624</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.561725</td>\n",
       "      <td>0.550016</td>\n",
       "      <td>0.103627</td>\n",
       "      <td>5</td>\n",
       "      <td>0.754201</td>\n",
       "      <td>0.754440</td>\n",
       "      <td>0.016042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030062</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>1.481652</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.550411</td>\n",
       "      <td>0.532522</td>\n",
       "      <td>0.075176</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>1.470849</td>\n",
       "      <td>0.757384</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.542220</td>\n",
       "      <td>0.524205</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>7</td>\n",
       "      <td>0.763603</td>\n",
       "      <td>0.763844</td>\n",
       "      <td>0.015506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028763</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>1.468466</td>\n",
       "      <td>0.812599</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.541723</td>\n",
       "      <td>0.524965</td>\n",
       "      <td>0.066807</td>\n",
       "      <td>8</td>\n",
       "      <td>0.806647</td>\n",
       "      <td>0.806782</td>\n",
       "      <td>0.010303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029025</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>1.434684</td>\n",
       "      <td>0.829881</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.541723</td>\n",
       "      <td>0.524965</td>\n",
       "      <td>0.066807</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>1.432568</td>\n",
       "      <td>0.775834</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.507485</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0.090242</td>\n",
       "      <td>10</td>\n",
       "      <td>0.769547</td>\n",
       "      <td>0.769655</td>\n",
       "      <td>0.013647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9       0.036361      0.003293         2.113520        1.147870   \n",
       "7       0.033969      0.004955         1.738308        0.911750   \n",
       "8       0.032525      0.006608         2.023561        1.070854   \n",
       "5       0.028093      0.005311         1.490033        0.756451   \n",
       "6       0.030545      0.004865         1.601805        0.810624   \n",
       "3       0.030062      0.003148         1.481652        0.741855   \n",
       "4       0.030956      0.002534         1.470849        0.757384   \n",
       "0       0.028763      0.006480         1.468466        0.812599   \n",
       "1       0.029025      0.006769         1.434684        0.829881   \n",
       "2       0.032831      0.004321         1.432568        0.775834   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors param_kneighborsclassifier__weights  \\\n",
       "9                                     100                            distance   \n",
       "7                                      50                            distance   \n",
       "8                                     100                             uniform   \n",
       "5                                      20                            distance   \n",
       "6                                      50                             uniform   \n",
       "3                                      10                            distance   \n",
       "4                                      20                             uniform   \n",
       "0                                       5                             uniform   \n",
       "1                                       5                            distance   \n",
       "2                                      10                             uniform   \n",
       "\n",
       "                                              params  \\\n",
       "9  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "7  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "8  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "5  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "6  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "3  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "4  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "0  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "1  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "2  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "\n",
       "   weighted_mean_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "9                  0.576050         0.573447        0.108429                1   \n",
       "7                  0.573137         0.561617        0.096263                2   \n",
       "8                  0.570402         0.569010        0.112740                3   \n",
       "5                  0.564404         0.548180        0.084426                4   \n",
       "6                  0.561725         0.550016        0.103627                5   \n",
       "3                  0.550411         0.532522        0.075176                6   \n",
       "4                  0.542220         0.524205        0.096507                7   \n",
       "0                  0.541723         0.524965        0.066807                8   \n",
       "1                  0.541723         0.524965        0.066807                9   \n",
       "2                  0.507485         0.489460        0.090242               10   \n",
       "\n",
       "   weighted_mean_train_score  mean_train_score  std_train_score  \n",
       "9                   1.000000          1.000000         0.000000  \n",
       "7                   1.000000          1.000000         0.000000  \n",
       "8                   0.750195          0.750469         0.016627  \n",
       "5                   1.000000          1.000000         0.000000  \n",
       "6                   0.754201          0.754440         0.016042  \n",
       "3                   1.000000          1.000000         0.000000  \n",
       "4                   0.763603          0.763844         0.015506  \n",
       "0                   0.806647          0.806782         0.010303  \n",
       "1                   1.000000          1.000000         0.000000  \n",
       "2                   0.769547          0.769655         0.013647  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_neighbors_class = KNeighborsClassifier()\n",
    "k_neighbours_class_pipeline = make_pipeline(preprocessing, k_neighbors_class)\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_neighbors_class_gs = optimize_params(k_neighbours_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 150 candidates, totalling 900 fits\n",
      "Time: 74.15 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_decisiontreeclassifier__ccp_alpha</th>\n",
       "      <th>param_decisiontreeclassifier__criterion</th>\n",
       "      <th>param_decisiontreeclassifier__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.921354</td>\n",
       "      <td>0.111465</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.852438</td>\n",
       "      <td>0.109921</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.01, 'd...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.560944</td>\n",
       "      <td>0.076352</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.572912</td>\n",
       "      <td>0.069958</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>4</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.576260</td>\n",
       "      <td>0.071428</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.692539</td>\n",
       "      <td>0.251594</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.333847</td>\n",
       "      <td>0.320870</td>\n",
       "      <td>0.196445</td>\n",
       "      <td>146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.693329</td>\n",
       "      <td>0.227995</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.329611</td>\n",
       "      <td>0.311085</td>\n",
       "      <td>0.204682</td>\n",
       "      <td>147</td>\n",
       "      <td>0.987825</td>\n",
       "      <td>0.988613</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.431747</td>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.315588</td>\n",
       "      <td>0.257296</td>\n",
       "      <td>0.158078</td>\n",
       "      <td>148</td>\n",
       "      <td>0.890990</td>\n",
       "      <td>0.892780</td>\n",
       "      <td>0.015456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.463434</td>\n",
       "      <td>0.202717</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.272299</td>\n",
       "      <td>0.241860</td>\n",
       "      <td>0.194869</td>\n",
       "      <td>149</td>\n",
       "      <td>0.849787</td>\n",
       "      <td>0.849794</td>\n",
       "      <td>0.006669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.468702</td>\n",
       "      <td>0.221797</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.272299</td>\n",
       "      <td>0.241860</td>\n",
       "      <td>0.194869</td>\n",
       "      <td>150</td>\n",
       "      <td>0.849818</td>\n",
       "      <td>0.849826</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "149       0.921354      0.111465         0.008386        0.002556   \n",
       "115       0.852438      0.109921         0.009630        0.004817   \n",
       "125       0.560944      0.076352         0.011825        0.001863   \n",
       "124       0.572912      0.069958         0.012900        0.003777   \n",
       "123       0.576260      0.071428         0.012063        0.002605   \n",
       "..             ...           ...              ...             ...   \n",
       "12        1.692539      0.251594         0.012386        0.006143   \n",
       "42        1.693329      0.227995         0.012422        0.002244   \n",
       "57        1.431747      0.176352         0.010643        0.003571   \n",
       "13        1.463434      0.202717         0.012122        0.004065   \n",
       "43        1.468702      0.221797         0.010344        0.004641   \n",
       "\n",
       "    param_decisiontreeclassifier__ccp_alpha  \\\n",
       "149                                     0.1   \n",
       "115                                    0.01   \n",
       "125                                     0.1   \n",
       "124                                     0.1   \n",
       "123                                     0.1   \n",
       "..                                      ...   \n",
       "12                                        0   \n",
       "42                                   0.0001   \n",
       "57                                   0.0001   \n",
       "13                                        0   \n",
       "43                                   0.0001   \n",
       "\n",
       "    param_decisiontreeclassifier__criterion  \\\n",
       "149                                    gini   \n",
       "115                                    gini   \n",
       "125                                 entropy   \n",
       "124                                 entropy   \n",
       "123                                 entropy   \n",
       "..                                      ...   \n",
       "12                                  entropy   \n",
       "42                                  entropy   \n",
       "57                                     gini   \n",
       "13                                  entropy   \n",
       "43                                  entropy   \n",
       "\n",
       "    param_decisiontreeclassifier__max_depth  \\\n",
       "149                                    None   \n",
       "115                                      10   \n",
       "125                                       5   \n",
       "124                                       5   \n",
       "123                                       5   \n",
       "..                                      ...   \n",
       "12                                     None   \n",
       "42                                     None   \n",
       "57                                     None   \n",
       "13                                     None   \n",
       "43                                     None   \n",
       "\n",
       "                                                params  \\\n",
       "149  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "115  {'decisiontreeclassifier__ccp_alpha': 0.01, 'd...   \n",
       "125  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "124  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "123  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "..                                                 ...   \n",
       "12   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "42   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "57   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "13   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "43   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "149                  0.743240         0.738487        0.062646   \n",
       "115                  0.743240         0.738487        0.062646   \n",
       "125                  0.743240         0.738487        0.062646   \n",
       "124                  0.743240         0.738487        0.062646   \n",
       "123                  0.743240         0.738487        0.062646   \n",
       "..                        ...              ...             ...   \n",
       "12                   0.333847         0.320870        0.196445   \n",
       "42                   0.329611         0.311085        0.204682   \n",
       "57                   0.315588         0.257296        0.158078   \n",
       "13                   0.272299         0.241860        0.194869   \n",
       "43                   0.272299         0.241860        0.194869   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "149                1                   0.745740          0.746037   \n",
       "115                2                   0.745740          0.746037   \n",
       "125                3                   0.745740          0.746037   \n",
       "124                4                   0.745740          0.746037   \n",
       "123                5                   0.745740          0.746037   \n",
       "..               ...                        ...               ...   \n",
       "12               146                   1.000000          1.000000   \n",
       "42               147                   0.987825          0.988613   \n",
       "57               148                   0.890990          0.892780   \n",
       "13               149                   0.849787          0.849794   \n",
       "43               150                   0.849818          0.849826   \n",
       "\n",
       "     std_train_score  \n",
       "149         0.015123  \n",
       "115         0.015123  \n",
       "125         0.015123  \n",
       "124         0.015123  \n",
       "123         0.015123  \n",
       "..               ...  \n",
       "12          0.000000  \n",
       "42          0.006825  \n",
       "57          0.015456  \n",
       "13          0.006669  \n",
       "43          0.006648  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_class = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree_class_pipeline = make_pipeline(preprocessing, decision_tree_class)\n",
    "\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 50, 200],\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "decision_tree_class_gs = optimize_params(decision_tree_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
      "Time: 56.27 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.511360</td>\n",
       "      <td>0.077231</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.596624</td>\n",
       "      <td>0.636858</td>\n",
       "      <td>0.178788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747545</td>\n",
       "      <td>0.747447</td>\n",
       "      <td>0.018910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.551261</td>\n",
       "      <td>0.110491</td>\n",
       "      <td>0.017035</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.588691</td>\n",
       "      <td>0.631393</td>\n",
       "      <td>0.190595</td>\n",
       "      <td>2</td>\n",
       "      <td>0.748029</td>\n",
       "      <td>0.747981</td>\n",
       "      <td>0.018247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.225585</td>\n",
       "      <td>0.195835</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.545696</td>\n",
       "      <td>0.600574</td>\n",
       "      <td>0.259948</td>\n",
       "      <td>3</td>\n",
       "      <td>0.749989</td>\n",
       "      <td>0.750243</td>\n",
       "      <td>0.016825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478304</td>\n",
       "      <td>0.220728</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.544828</td>\n",
       "      <td>0.600074</td>\n",
       "      <td>0.261648</td>\n",
       "      <td>4</td>\n",
       "      <td>0.749942</td>\n",
       "      <td>0.750303</td>\n",
       "      <td>0.016286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.344600</td>\n",
       "      <td>0.332377</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.540530</td>\n",
       "      <td>0.597040</td>\n",
       "      <td>0.268752</td>\n",
       "      <td>5</td>\n",
       "      <td>0.750736</td>\n",
       "      <td>0.751003</td>\n",
       "      <td>0.016040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.803078</td>\n",
       "      <td>0.346155</td>\n",
       "      <td>0.033593</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.539586</td>\n",
       "      <td>0.595842</td>\n",
       "      <td>0.269301</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750926</td>\n",
       "      <td>0.751207</td>\n",
       "      <td>0.015542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.796835</td>\n",
       "      <td>0.101844</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.509629</td>\n",
       "      <td>0.534366</td>\n",
       "      <td>0.191986</td>\n",
       "      <td>7</td>\n",
       "      <td>0.765557</td>\n",
       "      <td>0.765729</td>\n",
       "      <td>0.014806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.026513</td>\n",
       "      <td>0.135729</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.488182</td>\n",
       "      <td>0.513212</td>\n",
       "      <td>0.232767</td>\n",
       "      <td>8</td>\n",
       "      <td>0.787179</td>\n",
       "      <td>0.787799</td>\n",
       "      <td>0.012069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.705121</td>\n",
       "      <td>0.443969</td>\n",
       "      <td>0.035728</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.486136</td>\n",
       "      <td>0.530161</td>\n",
       "      <td>0.253302</td>\n",
       "      <td>9</td>\n",
       "      <td>0.771936</td>\n",
       "      <td>0.772245</td>\n",
       "      <td>0.012009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.375771</td>\n",
       "      <td>0.502989</td>\n",
       "      <td>0.033385</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.483385</td>\n",
       "      <td>0.519633</td>\n",
       "      <td>0.246014</td>\n",
       "      <td>10</td>\n",
       "      <td>0.773334</td>\n",
       "      <td>0.773675</td>\n",
       "      <td>0.012441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.745372</td>\n",
       "      <td>0.784359</td>\n",
       "      <td>0.036276</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.465544</td>\n",
       "      <td>0.471670</td>\n",
       "      <td>0.225384</td>\n",
       "      <td>11</td>\n",
       "      <td>0.793518</td>\n",
       "      <td>0.794023</td>\n",
       "      <td>0.011755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937876</td>\n",
       "      <td>0.129132</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.464850</td>\n",
       "      <td>0.518520</td>\n",
       "      <td>0.236497</td>\n",
       "      <td>12</td>\n",
       "      <td>0.768002</td>\n",
       "      <td>0.768429</td>\n",
       "      <td>0.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.233281</td>\n",
       "      <td>0.311312</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.461903</td>\n",
       "      <td>0.498959</td>\n",
       "      <td>0.258946</td>\n",
       "      <td>13</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>0.772602</td>\n",
       "      <td>0.013754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.891893</td>\n",
       "      <td>0.244229</td>\n",
       "      <td>0.026020</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.461291</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.259852</td>\n",
       "      <td>14</td>\n",
       "      <td>0.771205</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.013355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.890234</td>\n",
       "      <td>0.533719</td>\n",
       "      <td>0.037494</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.460616</td>\n",
       "      <td>0.474938</td>\n",
       "      <td>0.235103</td>\n",
       "      <td>15</td>\n",
       "      <td>0.793816</td>\n",
       "      <td>0.794263</td>\n",
       "      <td>0.011405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.518754</td>\n",
       "      <td>0.327909</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.454232</td>\n",
       "      <td>0.474907</td>\n",
       "      <td>0.236917</td>\n",
       "      <td>16</td>\n",
       "      <td>0.792074</td>\n",
       "      <td>0.792623</td>\n",
       "      <td>0.012058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.997723</td>\n",
       "      <td>0.373822</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.426301</td>\n",
       "      <td>0.422341</td>\n",
       "      <td>0.248485</td>\n",
       "      <td>17</td>\n",
       "      <td>0.790327</td>\n",
       "      <td>0.790784</td>\n",
       "      <td>0.012660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.242968</td>\n",
       "      <td>0.152631</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.398475</td>\n",
       "      <td>0.382838</td>\n",
       "      <td>0.258985</td>\n",
       "      <td>18</td>\n",
       "      <td>0.785473</td>\n",
       "      <td>0.786200</td>\n",
       "      <td>0.011614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.781014</td>\n",
       "      <td>0.414813</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.329479</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.170398</td>\n",
       "      <td>19</td>\n",
       "      <td>0.990472</td>\n",
       "      <td>0.990507</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.647384</td>\n",
       "      <td>0.701412</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.316341</td>\n",
       "      <td>0.232681</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>20</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.998792</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.775483</td>\n",
       "      <td>1.000745</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>0.013027</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.303247</td>\n",
       "      <td>0.252523</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>21</td>\n",
       "      <td>0.998624</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.536568</td>\n",
       "      <td>1.941167</td>\n",
       "      <td>0.051654</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.284567</td>\n",
       "      <td>0.211033</td>\n",
       "      <td>0.203894</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.334015</td>\n",
       "      <td>1.001431</td>\n",
       "      <td>0.027369</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.256323</td>\n",
       "      <td>0.172771</td>\n",
       "      <td>0.200362</td>\n",
       "      <td>23</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.340653</td>\n",
       "      <td>0.354452</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.255345</td>\n",
       "      <td>0.219447</td>\n",
       "      <td>0.134845</td>\n",
       "      <td>24</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.990794</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12       0.511360      0.077231         0.014243        0.004823   \n",
       "0        0.551261      0.110491         0.017035        0.005675   \n",
       "13       1.225585      0.195835         0.021109        0.008853   \n",
       "1        1.478304      0.220728         0.025472        0.009054   \n",
       "14       2.344600      0.332377         0.031492        0.014294   \n",
       "2        2.803078      0.346155         0.033593        0.013779   \n",
       "15       0.796835      0.101844         0.018958        0.006489   \n",
       "18       1.026513      0.135729         0.021546        0.007837   \n",
       "17       3.705121      0.443969         0.035728        0.017152   \n",
       "5        4.375771      0.502989         0.033385        0.015299   \n",
       "8        5.745372      0.784359         0.036276        0.015090   \n",
       "3        0.937876      0.129132         0.019157        0.004767   \n",
       "4        2.233281      0.311312         0.024900        0.010334   \n",
       "16       1.891893      0.244229         0.026020        0.009275   \n",
       "20       4.890234      0.533719         0.037494        0.016187   \n",
       "19       2.518754      0.327909         0.024504        0.010240   \n",
       "7        2.997723      0.373822         0.024190        0.011034   \n",
       "6        1.242968      0.152631         0.017910        0.008214   \n",
       "9        2.781014      0.414813         0.017216        0.006792   \n",
       "22       5.647384      0.701412         0.031050        0.013662   \n",
       "10       6.775483      1.000745         0.031459        0.013027   \n",
       "11      13.536568      1.941167         0.051654        0.021440   \n",
       "23       9.334015      1.001431         0.027369        0.017048   \n",
       "21       2.340653      0.354452         0.019224        0.006945   \n",
       "\n",
       "   param_randomforestclassifier__criterion  \\\n",
       "12                                    gini   \n",
       "0                                  entropy   \n",
       "13                                    gini   \n",
       "1                                  entropy   \n",
       "14                                    gini   \n",
       "2                                  entropy   \n",
       "15                                    gini   \n",
       "18                                    gini   \n",
       "17                                    gini   \n",
       "5                                  entropy   \n",
       "8                                  entropy   \n",
       "3                                  entropy   \n",
       "4                                  entropy   \n",
       "16                                    gini   \n",
       "20                                    gini   \n",
       "19                                    gini   \n",
       "7                                  entropy   \n",
       "6                                  entropy   \n",
       "9                                  entropy   \n",
       "22                                    gini   \n",
       "10                                 entropy   \n",
       "11                                 entropy   \n",
       "23                                    gini   \n",
       "21                                    gini   \n",
       "\n",
       "   param_randomforestclassifier__max_depth  \\\n",
       "12                                       3   \n",
       "0                                        3   \n",
       "13                                       3   \n",
       "1                                        3   \n",
       "14                                       3   \n",
       "2                                        3   \n",
       "15                                       5   \n",
       "18                                       7   \n",
       "17                                       5   \n",
       "5                                        5   \n",
       "8                                        7   \n",
       "3                                        5   \n",
       "4                                        5   \n",
       "16                                       5   \n",
       "20                                       7   \n",
       "19                                       7   \n",
       "7                                        7   \n",
       "6                                        7   \n",
       "9                                     None   \n",
       "22                                    None   \n",
       "10                                    None   \n",
       "11                                    None   \n",
       "23                                    None   \n",
       "21                                    None   \n",
       "\n",
       "   param_randomforestclassifier__n_estimators  \\\n",
       "12                                         10   \n",
       "0                                          10   \n",
       "13                                         25   \n",
       "1                                          25   \n",
       "14                                         50   \n",
       "2                                          50   \n",
       "15                                         10   \n",
       "18                                         10   \n",
       "17                                         50   \n",
       "5                                          50   \n",
       "8                                          50   \n",
       "3                                          10   \n",
       "4                                          25   \n",
       "16                                         25   \n",
       "20                                         50   \n",
       "19                                         25   \n",
       "7                                          25   \n",
       "6                                          10   \n",
       "9                                          10   \n",
       "22                                         25   \n",
       "10                                         25   \n",
       "11                                         50   \n",
       "23                                         50   \n",
       "21                                         10   \n",
       "\n",
       "                                               params  \\\n",
       "12  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "0   {'randomforestclassifier__criterion': 'entropy...   \n",
       "13  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "1   {'randomforestclassifier__criterion': 'entropy...   \n",
       "14  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "2   {'randomforestclassifier__criterion': 'entropy...   \n",
       "15  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "18  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "17  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "5   {'randomforestclassifier__criterion': 'entropy...   \n",
       "8   {'randomforestclassifier__criterion': 'entropy...   \n",
       "3   {'randomforestclassifier__criterion': 'entropy...   \n",
       "4   {'randomforestclassifier__criterion': 'entropy...   \n",
       "16  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "20  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "19  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "7   {'randomforestclassifier__criterion': 'entropy...   \n",
       "6   {'randomforestclassifier__criterion': 'entropy...   \n",
       "9   {'randomforestclassifier__criterion': 'entropy...   \n",
       "22  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "10  {'randomforestclassifier__criterion': 'entropy...   \n",
       "11  {'randomforestclassifier__criterion': 'entropy...   \n",
       "23  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "21  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "12                  0.596624         0.636858        0.178788   \n",
       "0                   0.588691         0.631393        0.190595   \n",
       "13                  0.545696         0.600574        0.259948   \n",
       "1                   0.544828         0.600074        0.261648   \n",
       "14                  0.540530         0.597040        0.268752   \n",
       "2                   0.539586         0.595842        0.269301   \n",
       "15                  0.509629         0.534366        0.191986   \n",
       "18                  0.488182         0.513212        0.232767   \n",
       "17                  0.486136         0.530161        0.253302   \n",
       "5                   0.483385         0.519633        0.246014   \n",
       "8                   0.465544         0.471670        0.225384   \n",
       "3                   0.464850         0.518520        0.236497   \n",
       "4                   0.461903         0.498959        0.258946   \n",
       "16                  0.461291         0.498049        0.259852   \n",
       "20                  0.460616         0.474938        0.235103   \n",
       "19                  0.454232         0.474907        0.236917   \n",
       "7                   0.426301         0.422341        0.248485   \n",
       "6                   0.398475         0.382838        0.258985   \n",
       "9                   0.329479         0.258587        0.170398   \n",
       "22                  0.316341         0.232681        0.215878   \n",
       "10                  0.303247         0.252523        0.185570   \n",
       "11                  0.284567         0.211033        0.203894   \n",
       "23                  0.256323         0.172771        0.200362   \n",
       "21                  0.255345         0.219447        0.134845   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "12                1                   0.747545          0.747447   \n",
       "0                 2                   0.748029          0.747981   \n",
       "13                3                   0.749989          0.750243   \n",
       "1                 4                   0.749942          0.750303   \n",
       "14                5                   0.750736          0.751003   \n",
       "2                 6                   0.750926          0.751207   \n",
       "15                7                   0.765557          0.765729   \n",
       "18                8                   0.787179          0.787799   \n",
       "17                9                   0.771936          0.772245   \n",
       "5                10                   0.773334          0.773675   \n",
       "8                11                   0.793518          0.794023   \n",
       "3                12                   0.768002          0.768429   \n",
       "4                13                   0.772308          0.772602   \n",
       "16               14                   0.771205          0.771451   \n",
       "20               15                   0.793816          0.794263   \n",
       "19               16                   0.792074          0.792623   \n",
       "7                17                   0.790327          0.790784   \n",
       "6                18                   0.785473          0.786200   \n",
       "9                19                   0.990472          0.990507   \n",
       "22               20                   0.998772          0.998792   \n",
       "10               21                   0.998624          0.998645   \n",
       "11               22                   0.999909          0.999911   \n",
       "23               23                   0.999958          0.999960   \n",
       "21               24                   0.990745          0.990794   \n",
       "\n",
       "    std_train_score  \n",
       "12         0.018910  \n",
       "0          0.018247  \n",
       "13         0.016825  \n",
       "1          0.016286  \n",
       "14         0.016040  \n",
       "2          0.015542  \n",
       "15         0.014806  \n",
       "18         0.012069  \n",
       "17         0.012009  \n",
       "5          0.012441  \n",
       "8          0.011755  \n",
       "3          0.013589  \n",
       "4          0.013754  \n",
       "16         0.013355  \n",
       "20         0.011405  \n",
       "19         0.012058  \n",
       "7          0.012660  \n",
       "6          0.011614  \n",
       "9          0.000735  \n",
       "22         0.000262  \n",
       "10         0.000215  \n",
       "11         0.000049  \n",
       "23         0.000048  \n",
       "21         0.000682  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_class = RandomForestClassifier(random_state=seed)\n",
    "random_forest_class_pipeline = make_pipeline(preprocessing, random_forest_class)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [10, 25, 50],\n",
    "    'randomforestclassifier__max_depth': [3, 5, 7, None],\n",
    "    'randomforestclassifier__criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "random_forest_class_gs = optimize_params(random_forest_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 120 candidates, totalling 720 fits\n",
      "Time: 61.39 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbclassifier__learning_rate</th>\n",
       "      <th>param_xgbclassifier__max_depth</th>\n",
       "      <th>param_xgbclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.138880</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.001, 'xgbcl...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.576339</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.200245</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.260447</td>\n",
       "      <td>0.027251</td>\n",
       "      <td>0.024095</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>4</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.219524</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.743240</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.732453</td>\n",
       "      <td>0.071440</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.207685</td>\n",
       "      <td>0.136909</td>\n",
       "      <td>0.173798</td>\n",
       "      <td>116</td>\n",
       "      <td>0.864801</td>\n",
       "      <td>0.865457</td>\n",
       "      <td>0.008081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.814187</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>0.036318</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.1, 'xgbclas...</td>\n",
       "      <td>0.203939</td>\n",
       "      <td>0.135792</td>\n",
       "      <td>0.164289</td>\n",
       "      <td>117</td>\n",
       "      <td>0.834763</td>\n",
       "      <td>0.835394</td>\n",
       "      <td>0.010901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.645105</td>\n",
       "      <td>0.041691</td>\n",
       "      <td>0.032607</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.190460</td>\n",
       "      <td>0.130630</td>\n",
       "      <td>0.157186</td>\n",
       "      <td>118</td>\n",
       "      <td>0.835033</td>\n",
       "      <td>0.835661</td>\n",
       "      <td>0.011710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.647642</td>\n",
       "      <td>0.072187</td>\n",
       "      <td>0.031501</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.1, 'xgbclas...</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>0.107826</td>\n",
       "      <td>0.152360</td>\n",
       "      <td>119</td>\n",
       "      <td>0.812409</td>\n",
       "      <td>0.812973</td>\n",
       "      <td>0.011924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.454126</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>0.025038</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.172880</td>\n",
       "      <td>0.101784</td>\n",
       "      <td>0.175544</td>\n",
       "      <td>120</td>\n",
       "      <td>0.788823</td>\n",
       "      <td>0.789335</td>\n",
       "      <td>0.013059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.138880      0.023195         0.018550        0.004111   \n",
       "32        0.576339      0.033855         0.022289        0.008044   \n",
       "20        0.200245      0.011330         0.019616        0.005352   \n",
       "21        0.260447      0.027251         0.024095        0.005702   \n",
       "24        0.219524      0.022605         0.020322        0.007923   \n",
       "..             ...           ...              ...             ...   \n",
       "119       0.732453      0.071440         0.026545        0.016658   \n",
       "99        0.814187      0.052075         0.036318        0.016340   \n",
       "107       0.645105      0.041691         0.032607        0.013493   \n",
       "87        0.647642      0.072187         0.031501        0.016318   \n",
       "103       0.454126      0.060207         0.025038        0.006128   \n",
       "\n",
       "    param_xgbclassifier__learning_rate param_xgbclassifier__max_depth  \\\n",
       "0                                0.001                              3   \n",
       "32                               0.005                             10   \n",
       "20                               0.005                              3   \n",
       "21                               0.005                              3   \n",
       "24                               0.005                              5   \n",
       "..                                 ...                            ...   \n",
       "119                                0.2                           None   \n",
       "99                                 0.1                           None   \n",
       "107                                0.2                              5   \n",
       "87                                 0.1                              5   \n",
       "103                                0.2                              3   \n",
       "\n",
       "    param_xgbclassifier__n_estimators  \\\n",
       "0                                  10   \n",
       "32                                 10   \n",
       "20                                 10   \n",
       "21                                 25   \n",
       "24                                 10   \n",
       "..                                ...   \n",
       "119                               100   \n",
       "99                                100   \n",
       "107                               100   \n",
       "87                                100   \n",
       "103                               100   \n",
       "\n",
       "                                                params  \\\n",
       "0    {'xgbclassifier__learning_rate': 0.001, 'xgbcl...   \n",
       "32   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "20   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "21   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "24   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "..                                                 ...   \n",
       "119  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "99   {'xgbclassifier__learning_rate': 0.1, 'xgbclas...   \n",
       "107  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "87   {'xgbclassifier__learning_rate': 0.1, 'xgbclas...   \n",
       "103  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "0                    0.743240         0.738487        0.062646   \n",
       "32                   0.743240         0.738487        0.062646   \n",
       "20                   0.743240         0.738487        0.062646   \n",
       "21                   0.743240         0.738487        0.062646   \n",
       "24                   0.743240         0.738487        0.062646   \n",
       "..                        ...              ...             ...   \n",
       "119                  0.207685         0.136909        0.173798   \n",
       "99                   0.203939         0.135792        0.164289   \n",
       "107                  0.190460         0.130630        0.157186   \n",
       "87                   0.173620         0.107826        0.152360   \n",
       "103                  0.172880         0.101784        0.175544   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "0                  1                   0.745740          0.746037   \n",
       "32                 2                   0.745740          0.746037   \n",
       "20                 3                   0.745740          0.746037   \n",
       "21                 4                   0.745740          0.746037   \n",
       "24                 5                   0.745740          0.746037   \n",
       "..               ...                        ...               ...   \n",
       "119              116                   0.864801          0.865457   \n",
       "99               117                   0.834763          0.835394   \n",
       "107              118                   0.835033          0.835661   \n",
       "87               119                   0.812409          0.812973   \n",
       "103              120                   0.788823          0.789335   \n",
       "\n",
       "     std_train_score  \n",
       "0           0.015123  \n",
       "32          0.015123  \n",
       "20          0.015123  \n",
       "21          0.015123  \n",
       "24          0.015123  \n",
       "..               ...  \n",
       "119         0.008081  \n",
       "99          0.010901  \n",
       "107         0.011710  \n",
       "87          0.011924  \n",
       "103         0.013059  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state=seed)\n",
    "xgb_class_pipeline = make_pipeline(preprocessing, xgb_class)\n",
    "\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [10, 25, 50, 100],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_class_gs = optimize_params(xgb_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 252 candidates, totalling 1512 fits\n",
      "Time: 34.97 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_sgdclassifier__alpha</th>\n",
       "      <th>param_sgdclassifier__class_weight</th>\n",
       "      <th>param_sgdclassifier__loss</th>\n",
       "      <th>param_sgdclassifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.74324</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.088368</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.1, 'sgdclassifier__...</td>\n",
       "      <td>0.74324</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.081002</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.2, 'sgdclassifier__...</td>\n",
       "      <td>0.74324</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.015123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.104408</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.2, 'sgdclassifier__...</td>\n",
       "      <td>0.74324</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>4</td>\n",
       "      <td>0.745736</td>\n",
       "      <td>0.746031</td>\n",
       "      <td>0.015116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.098826</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.013827</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.2, 'sgdclassifier__...</td>\n",
       "      <td>0.74324</td>\n",
       "      <td>0.738487</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745736</td>\n",
       "      <td>0.746031</td>\n",
       "      <td>0.015116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>0.016153</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.28824</td>\n",
       "      <td>0.238229</td>\n",
       "      <td>0.318708</td>\n",
       "      <td>248</td>\n",
       "      <td>0.371389</td>\n",
       "      <td>0.373835</td>\n",
       "      <td>0.254182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.090654</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.15414</td>\n",
       "      <td>0.220045</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>249</td>\n",
       "      <td>0.534063</td>\n",
       "      <td>0.536462</td>\n",
       "      <td>0.051740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.099882</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.15414</td>\n",
       "      <td>0.220045</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>250</td>\n",
       "      <td>0.534063</td>\n",
       "      <td>0.536462</td>\n",
       "      <td>0.051740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.109196</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.15414</td>\n",
       "      <td>0.220045</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>251</td>\n",
       "      <td>0.534063</td>\n",
       "      <td>0.536462</td>\n",
       "      <td>0.051740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.102917</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.017289</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.15414</td>\n",
       "      <td>0.220045</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>252</td>\n",
       "      <td>0.534063</td>\n",
       "      <td>0.536462</td>\n",
       "      <td>0.051740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "126       0.088900      0.008329         0.014133        0.004206   \n",
       "136       0.088368      0.008735         0.015536        0.004495   \n",
       "172       0.081002      0.010139         0.017067        0.003782   \n",
       "171       0.104408      0.012939         0.016100        0.003512   \n",
       "170       0.098826      0.010327         0.013827        0.004548   \n",
       "..             ...           ...              ...             ...   \n",
       "222       0.096718      0.021776         0.016153        0.004248   \n",
       "76        0.090654      0.005615         0.014383        0.006302   \n",
       "77        0.099882      0.015268         0.017613        0.003994   \n",
       "78        0.109196      0.008403         0.018167        0.005077   \n",
       "79        0.102917      0.002632         0.017289        0.001762   \n",
       "\n",
       "    param_sgdclassifier__alpha param_sgdclassifier__class_weight  \\\n",
       "126                        0.1                              None   \n",
       "136                        0.1                      {0: 1, 1: 2}   \n",
       "172                        0.2                      {0: 1, 1: 2}   \n",
       "171                        0.2                      {0: 1, 1: 2}   \n",
       "170                        0.2                      {0: 1, 1: 2}   \n",
       "..                         ...                               ...   \n",
       "222                        0.8                          balanced   \n",
       "76                        0.01                          balanced   \n",
       "77                        0.01                          balanced   \n",
       "78                        0.01                          balanced   \n",
       "79                        0.01                          balanced   \n",
       "\n",
       "    param_sgdclassifier__loss param_sgdclassifier__max_iter  \\\n",
       "126                     hinge                           500   \n",
       "136                     hinge                            50   \n",
       "172                     hinge                            50   \n",
       "171                  log_loss                          1000   \n",
       "170                  log_loss                           500   \n",
       "..                        ...                           ...   \n",
       "222                     hinge                           500   \n",
       "76                      hinge                            50   \n",
       "77                      hinge                           100   \n",
       "78                      hinge                           500   \n",
       "79                      hinge                          1000   \n",
       "\n",
       "                                                params  \\\n",
       "126  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "136  {'sgdclassifier__alpha': 0.1, 'sgdclassifier__...   \n",
       "172  {'sgdclassifier__alpha': 0.2, 'sgdclassifier__...   \n",
       "171  {'sgdclassifier__alpha': 0.2, 'sgdclassifier__...   \n",
       "170  {'sgdclassifier__alpha': 0.2, 'sgdclassifier__...   \n",
       "..                                                 ...   \n",
       "222  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "76   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "77   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "78   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "79   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "126                   0.74324         0.738487        0.062646   \n",
       "136                   0.74324         0.738487        0.062646   \n",
       "172                   0.74324         0.738487        0.062646   \n",
       "171                   0.74324         0.738487        0.062646   \n",
       "170                   0.74324         0.738487        0.062646   \n",
       "..                        ...              ...             ...   \n",
       "222                   0.28824         0.238229        0.318708   \n",
       "76                    0.15414         0.220045        0.297297   \n",
       "77                    0.15414         0.220045        0.297297   \n",
       "78                    0.15414         0.220045        0.297297   \n",
       "79                    0.15414         0.220045        0.297297   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "126                1                   0.745740          0.746037   \n",
       "136                2                   0.745740          0.746037   \n",
       "172                3                   0.745740          0.746037   \n",
       "171                4                   0.745736          0.746031   \n",
       "170                5                   0.745736          0.746031   \n",
       "..               ...                        ...               ...   \n",
       "222              248                   0.371389          0.373835   \n",
       "76               249                   0.534063          0.536462   \n",
       "77               250                   0.534063          0.536462   \n",
       "78               251                   0.534063          0.536462   \n",
       "79               252                   0.534063          0.536462   \n",
       "\n",
       "     std_train_score  \n",
       "126         0.015123  \n",
       "136         0.015123  \n",
       "172         0.015123  \n",
       "171         0.015116  \n",
       "170         0.015116  \n",
       "..               ...  \n",
       "222         0.254182  \n",
       "76          0.051740  \n",
       "77          0.051740  \n",
       "78          0.051740  \n",
       "79          0.051740  \n",
       "\n",
       "[252 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_class = SGDClassifier(random_state=seed)\n",
    "sgd_class_pipeline = make_pipeline(preprocessing, sgd_class)\n",
    "\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "    'sgdclassifier__max_iter': [50, 100, 500, 1000],\n",
    "    'sgdclassifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'sgdclassifier__class_weight': ['balanced', None, {0:1, 1:2}]\n",
    "}\n",
    "\n",
    "sgd_class_gs = optimize_params(sgd_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbol de decision</td>\n",
       "      <td>0.743240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.743240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.743240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.596624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.576050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresion logistica</td>\n",
       "      <td>0.480431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Mejor puntuacion\n",
       "2    Arbol de decision          0.743240\n",
       "4              XGBoost          0.743240\n",
       "5                  SGD          0.743240\n",
       "3        Random Forest          0.596624\n",
       "1           KNeighbors          0.576050\n",
       "0  Regresion logistica          0.480431"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = {\n",
    "    'Regresion logistica': logistic_reg_gs,\n",
    "    'KNeighbors' : k_neighbors_class_gs,\n",
    "    'Arbol de decision': decision_tree_class_gs,\n",
    "    'Random Forest': random_forest_class_gs,\n",
    "    'XGBoost': xgb_class_gs,\n",
    "    'SGD': sgd_class_gs\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Modelo': models_dict.keys(),\n",
    "    'Mejor puntuacion': [gs.best_score_ for gs in models_dict.values()]\n",
    "})\n",
    "df_results = df_results.sort_values(by='Mejor puntuacion', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model_4\\\\to_cr_gu\\\\model_baja_mediabaja.joblib']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[df_results.loc[df_results.index[0], 'Modelo']].best_estimator_\n",
    "model_path = os.path.join('models', 'experiment_4', 'TO_CR_GU', 'model_baja_mediabaja.joblib')\n",
    "dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas predicci√≥n del test\n",
      "F1:        0.7459030941253031\n",
      "Recall:    1.0\n",
      "Precision: 0.5947730918011133\n",
      "Accuracy:  0.5947730918011133\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('models', 'experiment_4', 'TO_CR_GU', 'model_baja_mediabaja.joblib')\n",
    "model = load(model_path)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\"\"M√©tricas predicci√≥n del test\n",
    "F1:        {f1_score(y_test, pred)}\n",
    "Recall:    {recall_score(y_test, pred)}\n",
    "Precision: {precision_score(y_test, pred)}\n",
    "Accuracy:  {accuracy_score(y_test, pred)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media alta - Alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classification = {2:0, 3:1}\n",
    "\n",
    "df_train_reclass = reclass(new_classification, df_train)\n",
    "df_test_reclass = reclass(new_classification, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_reclass[variables]\n",
    "y_train = df_train_reclass[target_discrete]\n",
    "\n",
    "X_test = df_test_reclass[variables]\n",
    "y_test = df_test_reclass[target_discrete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Train: 12263\tTest:984\n",
      "Fold 1: Train: 7230\tTest:6017\n",
      "Fold 2: Train: 9875\tTest:3372\n",
      "Fold 3: Train: 11690\tTest:1557\n",
      "Fold 4: Train: 11941\tTest:1306\n",
      "Fold 5: Train: 13236\tTest:11\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "\n",
    "for name in train_fire_names:\n",
    "    fold_train_names = [x for x in train_fire_names if x != name]\n",
    "    fold_test_name = [x for x in train_fire_names if x == name]\n",
    "\n",
    "    fold_train_indices = df_train_reclass[(df_train_reclass['incendio'].isin(fold_train_names))].index\n",
    "    fold_test_indices = df_train_reclass[df_train_reclass['incendio'].isin(fold_test_name)].index\n",
    "    folds.append((fold_train_indices, fold_test_indices))\n",
    "\n",
    "[print(f'Fold {i}: Train: {x.size}\\tTest:{y.size}') for i, (x, y) in enumerate(folds)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
      "Time: 15.18 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.208123</td>\n",
       "      <td>0.192957</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.054402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560342</td>\n",
       "      <td>0.527820</td>\n",
       "      <td>0.214074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.190298</td>\n",
       "      <td>0.177671</td>\n",
       "      <td>0.027622</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.040775</td>\n",
       "      <td>0.047815</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>2</td>\n",
       "      <td>0.562630</td>\n",
       "      <td>0.530401</td>\n",
       "      <td>0.211816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.590740</td>\n",
       "      <td>0.204316</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.040203</td>\n",
       "      <td>0.052930</td>\n",
       "      <td>0.070116</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567631</td>\n",
       "      <td>0.538485</td>\n",
       "      <td>0.191817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.372503</td>\n",
       "      <td>0.342362</td>\n",
       "      <td>0.024916</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.039328</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.068352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.566640</td>\n",
       "      <td>0.536380</td>\n",
       "      <td>0.199254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.265306</td>\n",
       "      <td>0.381029</td>\n",
       "      <td>0.026940</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.038897</td>\n",
       "      <td>0.046678</td>\n",
       "      <td>0.058418</td>\n",
       "      <td>5</td>\n",
       "      <td>0.563921</td>\n",
       "      <td>0.532157</td>\n",
       "      <td>0.209042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.337848</td>\n",
       "      <td>0.365152</td>\n",
       "      <td>0.026418</td>\n",
       "      <td>0.016849</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.038752</td>\n",
       "      <td>0.049237</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>6</td>\n",
       "      <td>0.566130</td>\n",
       "      <td>0.534941</td>\n",
       "      <td>0.205116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.233559</td>\n",
       "      <td>0.138596</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>0.018502</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.038650</td>\n",
       "      <td>0.046521</td>\n",
       "      <td>0.053295</td>\n",
       "      <td>7</td>\n",
       "      <td>0.564751</td>\n",
       "      <td>0.532881</td>\n",
       "      <td>0.209401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.173817</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>0.027793</td>\n",
       "      <td>0.017153</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.038123</td>\n",
       "      <td>0.045809</td>\n",
       "      <td>0.052128</td>\n",
       "      <td>8</td>\n",
       "      <td>0.563966</td>\n",
       "      <td>0.532169</td>\n",
       "      <td>0.209064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.370483</td>\n",
       "      <td>0.370918</td>\n",
       "      <td>0.027790</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>0.031749</td>\n",
       "      <td>0.052393</td>\n",
       "      <td>9</td>\n",
       "      <td>0.551841</td>\n",
       "      <td>0.517756</td>\n",
       "      <td>0.224216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059088</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>10</td>\n",
       "      <td>0.493819</td>\n",
       "      <td>0.462362</td>\n",
       "      <td>0.207012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090053</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>11</td>\n",
       "      <td>0.493819</td>\n",
       "      <td>0.462362</td>\n",
       "      <td>0.207012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.189653</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>0.021714</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>0.048499</td>\n",
       "      <td>12</td>\n",
       "      <td>0.503480</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.210986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200538</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>0.026020</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>0.048499</td>\n",
       "      <td>13</td>\n",
       "      <td>0.503480</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.210986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.264263</td>\n",
       "      <td>0.191683</td>\n",
       "      <td>0.028114</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>0.047206</td>\n",
       "      <td>14</td>\n",
       "      <td>0.550955</td>\n",
       "      <td>0.516680</td>\n",
       "      <td>0.225598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.253650</td>\n",
       "      <td>0.044354</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>15</td>\n",
       "      <td>0.505188</td>\n",
       "      <td>0.472950</td>\n",
       "      <td>0.211726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.066146</td>\n",
       "      <td>0.242585</td>\n",
       "      <td>0.036355</td>\n",
       "      <td>0.019476</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>16</td>\n",
       "      <td>0.543614</td>\n",
       "      <td>0.508930</td>\n",
       "      <td>0.227791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.093916</td>\n",
       "      <td>0.212263</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>17</td>\n",
       "      <td>0.543614</td>\n",
       "      <td>0.508930</td>\n",
       "      <td>0.227791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.291788</td>\n",
       "      <td>0.075998</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregressi...</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>0.034889</td>\n",
       "      <td>18</td>\n",
       "      <td>0.504919</td>\n",
       "      <td>0.472726</td>\n",
       "      <td>0.211633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.325808</td>\n",
       "      <td>0.084864</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>19</td>\n",
       "      <td>0.505404</td>\n",
       "      <td>0.473166</td>\n",
       "      <td>0.211812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.226569</td>\n",
       "      <td>0.043855</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>20</td>\n",
       "      <td>0.505336</td>\n",
       "      <td>0.473050</td>\n",
       "      <td>0.211744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.214473</td>\n",
       "      <td>0.049202</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 2, 'logisticregressi...</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>21</td>\n",
       "      <td>0.504977</td>\n",
       "      <td>0.472729</td>\n",
       "      <td>0.211619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.320136</td>\n",
       "      <td>0.063089</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 5, 'logisticregressi...</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>22</td>\n",
       "      <td>0.505238</td>\n",
       "      <td>0.472968</td>\n",
       "      <td>0.211719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.246102</td>\n",
       "      <td>0.061091</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>23</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.472732</td>\n",
       "      <td>0.211590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.354136</td>\n",
       "      <td>0.051730</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>24</td>\n",
       "      <td>0.505300</td>\n",
       "      <td>0.472999</td>\n",
       "      <td>0.211718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9        1.208123      0.192957         0.025983        0.016301   \n",
       "13       1.190298      0.177671         0.027622        0.016705   \n",
       "23       1.590740      0.204316         0.019738        0.010970   \n",
       "19       2.372503      0.342362         0.024916        0.012342   \n",
       "11       2.265306      0.381029         0.026940        0.014971   \n",
       "15       2.337848      0.365152         0.026418        0.016849   \n",
       "21       1.233559      0.138596         0.025243        0.018502   \n",
       "17       1.173817      0.153944         0.027793        0.017153   \n",
       "7        2.370483      0.370918         0.027790        0.012427   \n",
       "0        0.059088      0.019944         0.013306        0.002398   \n",
       "2        0.090053      0.020590         0.015005        0.003136   \n",
       "6        0.189653      0.037931         0.021714        0.005866   \n",
       "4        0.200538      0.049707         0.026020        0.018410   \n",
       "5        1.264263      0.191683         0.028114        0.013779   \n",
       "8        0.253650      0.044354         0.017912        0.003959   \n",
       "1        1.066146      0.242585         0.036355        0.019476   \n",
       "3        1.093916      0.212263         0.031421        0.018394   \n",
       "10       0.291788      0.075998         0.016664        0.007260   \n",
       "14       0.325808      0.084864         0.016766        0.004611   \n",
       "16       0.226569      0.043855         0.017698        0.006267   \n",
       "12       0.214473      0.049202         0.018238        0.005314   \n",
       "18       0.320136      0.063089         0.013895        0.004174   \n",
       "20       0.246102      0.061091         0.018340        0.005976   \n",
       "22       0.354136      0.051730         0.014576        0.004307   \n",
       "\n",
       "   param_logisticregression__C param_logisticregression__max_iter  \\\n",
       "9                            1                                100   \n",
       "13                           2                                100   \n",
       "23                          10                                200   \n",
       "19                           5                                200   \n",
       "11                           1                                200   \n",
       "15                           2                                200   \n",
       "21                          10                                100   \n",
       "17                           5                                100   \n",
       "7                          0.1                                200   \n",
       "0                         0.01                                100   \n",
       "2                         0.01                                200   \n",
       "6                          0.1                                200   \n",
       "4                          0.1                                100   \n",
       "5                          0.1                                100   \n",
       "8                            1                                100   \n",
       "1                         0.01                                100   \n",
       "3                         0.01                                200   \n",
       "10                           1                                200   \n",
       "14                           2                                200   \n",
       "16                           5                                100   \n",
       "12                           2                                100   \n",
       "18                           5                                200   \n",
       "20                          10                                100   \n",
       "22                          10                                200   \n",
       "\n",
       "   param_polynomialfeatures__degree  \\\n",
       "9                                 2   \n",
       "13                                2   \n",
       "23                                2   \n",
       "19                                2   \n",
       "11                                2   \n",
       "15                                2   \n",
       "21                                2   \n",
       "17                                2   \n",
       "7                                 2   \n",
       "0                                 1   \n",
       "2                                 1   \n",
       "6                                 1   \n",
       "4                                 1   \n",
       "5                                 2   \n",
       "8                                 1   \n",
       "1                                 2   \n",
       "3                                 2   \n",
       "10                                1   \n",
       "14                                1   \n",
       "16                                1   \n",
       "12                                1   \n",
       "18                                1   \n",
       "20                                1   \n",
       "22                                1   \n",
       "\n",
       "                                               params  \\\n",
       "9   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "13  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "23  {'logisticregression__C': 10, 'logisticregress...   \n",
       "19  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "11  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "15  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "21  {'logisticregression__C': 10, 'logisticregress...   \n",
       "17  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "7   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "0   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "2   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "6   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "4   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "5   {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "8   {'logisticregression__C': 1, 'logisticregressi...   \n",
       "1   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "3   {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "10  {'logisticregression__C': 1, 'logisticregressi...   \n",
       "14  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "16  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "12  {'logisticregression__C': 2, 'logisticregressi...   \n",
       "18  {'logisticregression__C': 5, 'logisticregressi...   \n",
       "20  {'logisticregression__C': 10, 'logisticregress...   \n",
       "22  {'logisticregression__C': 10, 'logisticregress...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "9                   0.042577         0.048052        0.054402   \n",
       "13                  0.040775         0.047815        0.053804   \n",
       "23                  0.040203         0.052930        0.070116   \n",
       "19                  0.039328         0.051888        0.068352   \n",
       "11                  0.038897         0.046678        0.058418   \n",
       "15                  0.038752         0.049237        0.062238   \n",
       "21                  0.038650         0.046521        0.053295   \n",
       "17                  0.038123         0.045809        0.052128   \n",
       "7                   0.022891         0.031749        0.052393   \n",
       "0                   0.009700         0.021764        0.048666   \n",
       "2                   0.009700         0.021764        0.048666   \n",
       "6                   0.009667         0.021689        0.048499   \n",
       "4                   0.009667         0.021689        0.048499   \n",
       "5                   0.009409         0.021111        0.047206   \n",
       "8                   0.009142         0.020513        0.045868   \n",
       "1                   0.008315         0.018657        0.041718   \n",
       "3                   0.008315         0.018657        0.041718   \n",
       "10                  0.006954         0.015603        0.034889   \n",
       "14                  0.003455         0.007752        0.017334   \n",
       "16                  0.003258         0.007310        0.016346   \n",
       "12                  0.002713         0.006088        0.013614   \n",
       "18                  0.001402         0.003145        0.007032   \n",
       "20                  0.000711         0.001595        0.003566   \n",
       "22                  0.000707         0.001587        0.003549   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "9                 1                   0.560342          0.527820   \n",
       "13                2                   0.562630          0.530401   \n",
       "23                3                   0.567631          0.538485   \n",
       "19                4                   0.566640          0.536380   \n",
       "11                5                   0.563921          0.532157   \n",
       "15                6                   0.566130          0.534941   \n",
       "21                7                   0.564751          0.532881   \n",
       "17                8                   0.563966          0.532169   \n",
       "7                 9                   0.551841          0.517756   \n",
       "0                10                   0.493819          0.462362   \n",
       "2                11                   0.493819          0.462362   \n",
       "6                12                   0.503480          0.471300   \n",
       "4                13                   0.503480          0.471300   \n",
       "5                14                   0.550955          0.516680   \n",
       "8                15                   0.505188          0.472950   \n",
       "1                16                   0.543614          0.508930   \n",
       "3                17                   0.543614          0.508930   \n",
       "10               18                   0.504919          0.472726   \n",
       "14               19                   0.505404          0.473166   \n",
       "16               20                   0.505336          0.473050   \n",
       "12               21                   0.504977          0.472729   \n",
       "18               22                   0.505238          0.472968   \n",
       "20               23                   0.504993          0.472732   \n",
       "22               24                   0.505300          0.472999   \n",
       "\n",
       "    std_train_score  \n",
       "9          0.214074  \n",
       "13         0.211816  \n",
       "23         0.191817  \n",
       "19         0.199254  \n",
       "11         0.209042  \n",
       "15         0.205116  \n",
       "21         0.209401  \n",
       "17         0.209064  \n",
       "7          0.224216  \n",
       "0          0.207012  \n",
       "2          0.207012  \n",
       "6          0.210986  \n",
       "4          0.210986  \n",
       "5          0.225598  \n",
       "8          0.211726  \n",
       "1          0.227791  \n",
       "3          0.227791  \n",
       "10         0.211633  \n",
       "14         0.211812  \n",
       "16         0.211744  \n",
       "12         0.211619  \n",
       "18         0.211719  \n",
       "20         0.211590  \n",
       "22         0.211718  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro.Martinez\\AppData\\Local\\miniconda3\\envs\\nuevoEntorno\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "logistic_reg = LogisticRegression(random_state=seed)\n",
    "logistic_reg_pipeline = make_pipeline(preprocessing, poly, logistic_reg)\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1, 2],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "    'logisticregression__max_iter': [100, 200]\n",
    "}\n",
    "\n",
    "logistic_reg_gs = optimize_params(logistic_reg_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "Time: 12.97 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>param_kneighborsclassifier__weights</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016136</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.248561</td>\n",
       "      <td>0.174254</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>0.073855</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>1</td>\n",
       "      <td>0.673177</td>\n",
       "      <td>0.655004</td>\n",
       "      <td>0.121582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.233823</td>\n",
       "      <td>0.115770</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 5, 'knei...</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>0.073855</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.240015</td>\n",
       "      <td>0.170373</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>0.069280</td>\n",
       "      <td>0.110197</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018924</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.151128</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 10, 'kne...</td>\n",
       "      <td>0.132451</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.096561</td>\n",
       "      <td>4</td>\n",
       "      <td>0.589131</td>\n",
       "      <td>0.561124</td>\n",
       "      <td>0.185797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018203</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.277215</td>\n",
       "      <td>0.178841</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.086996</td>\n",
       "      <td>0.049641</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.271133</td>\n",
       "      <td>0.180640</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 20, 'kne...</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>0.028952</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>6</td>\n",
       "      <td>0.560888</td>\n",
       "      <td>0.526487</td>\n",
       "      <td>0.226257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017404</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.366196</td>\n",
       "      <td>0.242812</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.046562</td>\n",
       "      <td>7</td>\n",
       "      <td>0.549269</td>\n",
       "      <td>0.514175</td>\n",
       "      <td>0.230125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019988</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.379578</td>\n",
       "      <td>0.265927</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 100, 'kn...</td>\n",
       "      <td>0.021996</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.046548</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016727</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.313667</td>\n",
       "      <td>0.203279</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.039609</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018770</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.322449</td>\n",
       "      <td>0.210136</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'kneighborsclassifier__n_neighbors': 50, 'kne...</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.035757</td>\n",
       "      <td>10</td>\n",
       "      <td>0.550886</td>\n",
       "      <td>0.515696</td>\n",
       "      <td>0.230783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.016136      0.003739         0.248561        0.174254   \n",
       "1       0.015358      0.004148         0.233823        0.115770   \n",
       "3       0.014950      0.003938         0.240015        0.170373   \n",
       "2       0.018924      0.004438         0.255519        0.151128   \n",
       "5       0.018203      0.002604         0.277215        0.178841   \n",
       "4       0.019429      0.005746         0.271133        0.180640   \n",
       "8       0.017404      0.002973         0.366196        0.242812   \n",
       "9       0.019988      0.006375         0.379578        0.265927   \n",
       "7       0.016727      0.002967         0.313667        0.203279   \n",
       "6       0.018770      0.003871         0.322449        0.210136   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors param_kneighborsclassifier__weights  \\\n",
       "0                                       5                             uniform   \n",
       "1                                       5                            distance   \n",
       "3                                      10                            distance   \n",
       "2                                      10                             uniform   \n",
       "5                                      20                            distance   \n",
       "4                                      20                             uniform   \n",
       "8                                     100                             uniform   \n",
       "9                                     100                            distance   \n",
       "7                                      50                            distance   \n",
       "6                                      50                             uniform   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "1  {'kneighborsclassifier__n_neighbors': 5, 'knei...   \n",
       "3  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "2  {'kneighborsclassifier__n_neighbors': 10, 'kne...   \n",
       "5  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "4  {'kneighborsclassifier__n_neighbors': 20, 'kne...   \n",
       "8  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "9  {'kneighborsclassifier__n_neighbors': 100, 'kn...   \n",
       "7  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "6  {'kneighborsclassifier__n_neighbors': 50, 'kne...   \n",
       "\n",
       "   weighted_mean_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0                  0.161107         0.073855        0.118176                1   \n",
       "1                  0.161107         0.073855        0.118176                2   \n",
       "3                  0.150625         0.069280        0.110197                3   \n",
       "2                  0.132451         0.059179        0.096561                4   \n",
       "5                  0.086996         0.049641        0.059517                5   \n",
       "4                  0.034988         0.028952        0.030922                6   \n",
       "8                  0.022102         0.031352        0.046562                7   \n",
       "9                  0.021996         0.031283        0.046548                8   \n",
       "7                  0.013532         0.021663        0.039609                9   \n",
       "6                  0.012776         0.019921        0.035757               10   \n",
       "\n",
       "   weighted_mean_train_score  mean_train_score  std_train_score  \n",
       "0                   0.673177          0.655004         0.121582  \n",
       "1                   1.000000          1.000000         0.000000  \n",
       "3                   1.000000          1.000000         0.000000  \n",
       "2                   0.589131          0.561124         0.185797  \n",
       "5                   1.000000          1.000000         0.000000  \n",
       "4                   0.560888          0.526487         0.226257  \n",
       "8                   0.549269          0.514175         0.230125  \n",
       "9                   1.000000          1.000000         0.000000  \n",
       "7                   1.000000          1.000000         0.000000  \n",
       "6                   0.550886          0.515696         0.230783  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_neighbors_class = KNeighborsClassifier()\n",
    "k_neighbours_class_pipeline = make_pipeline(preprocessing, k_neighbors_class)\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [5, 10, 20, 50, 100],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "k_neighbors_class_gs = optimize_params(k_neighbours_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 150 candidates, totalling 900 fits\n",
      "Time: 28.51 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_decisiontreeclassifier__ccp_alpha</th>\n",
       "      <th>param_decisiontreeclassifier__criterion</th>\n",
       "      <th>param_decisiontreeclassifier__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.477605</td>\n",
       "      <td>0.094831</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.136212</td>\n",
       "      <td>0.078956</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.466849</td>\n",
       "      <td>0.082711</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.134989</td>\n",
       "      <td>0.074525</td>\n",
       "      <td>0.075035</td>\n",
       "      <td>2</td>\n",
       "      <td>0.968497</td>\n",
       "      <td>0.970952</td>\n",
       "      <td>0.013815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.273272</td>\n",
       "      <td>0.041060</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0, 'deci...</td>\n",
       "      <td>0.127538</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.077801</td>\n",
       "      <td>3</td>\n",
       "      <td>0.652188</td>\n",
       "      <td>0.637932</td>\n",
       "      <td>0.090702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.270008</td>\n",
       "      <td>0.050252</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.127397</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>0.077696</td>\n",
       "      <td>4</td>\n",
       "      <td>0.651673</td>\n",
       "      <td>0.637444</td>\n",
       "      <td>0.090488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.346070</td>\n",
       "      <td>0.064355</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.0001, ...</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.045392</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>5</td>\n",
       "      <td>0.740199</td>\n",
       "      <td>0.739309</td>\n",
       "      <td>0.016274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.391527</td>\n",
       "      <td>0.080982</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.001, '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146</td>\n",
       "      <td>0.627718</td>\n",
       "      <td>0.611340</td>\n",
       "      <td>0.116589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.392829</td>\n",
       "      <td>0.078197</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.001, '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>0.638875</td>\n",
       "      <td>0.626149</td>\n",
       "      <td>0.096322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.293723</td>\n",
       "      <td>0.051468</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.001, '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148</td>\n",
       "      <td>0.591225</td>\n",
       "      <td>0.558798</td>\n",
       "      <td>0.210185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.305413</td>\n",
       "      <td>0.058106</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.001</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.001, '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149</td>\n",
       "      <td>0.609069</td>\n",
       "      <td>0.582826</td>\n",
       "      <td>0.170873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.317309</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>{'decisiontreeclassifier__ccp_alpha': 0.1, 'de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "27        0.477605      0.094831         0.010128        0.002407   \n",
       "57        0.466849      0.082711         0.009921        0.003071   \n",
       "21        0.273272      0.041060         0.009913        0.000773   \n",
       "51        0.270008      0.050252         0.009834        0.002244   \n",
       "54        0.346070      0.064355         0.006861        0.003298   \n",
       "..             ...           ...              ...             ...   \n",
       "70        0.391527      0.080982         0.009891        0.001825   \n",
       "69        0.392829      0.078197         0.009316        0.001044   \n",
       "68        0.293723      0.051468         0.009918        0.002886   \n",
       "67        0.305413      0.058106         0.009908        0.003484   \n",
       "149       0.317309      0.052045         0.008249        0.002965   \n",
       "\n",
       "    param_decisiontreeclassifier__ccp_alpha  \\\n",
       "27                                        0   \n",
       "57                                   0.0001   \n",
       "21                                        0   \n",
       "51                                   0.0001   \n",
       "54                                   0.0001   \n",
       "..                                      ...   \n",
       "70                                    0.001   \n",
       "69                                    0.001   \n",
       "68                                    0.001   \n",
       "67                                    0.001   \n",
       "149                                     0.1   \n",
       "\n",
       "    param_decisiontreeclassifier__criterion  \\\n",
       "27                                     gini   \n",
       "57                                     gini   \n",
       "21                                     gini   \n",
       "51                                     gini   \n",
       "54                                     gini   \n",
       "..                                      ...   \n",
       "70                                  entropy   \n",
       "69                                  entropy   \n",
       "68                                  entropy   \n",
       "67                                  entropy   \n",
       "149                                    gini   \n",
       "\n",
       "    param_decisiontreeclassifier__max_depth  \\\n",
       "27                                     None   \n",
       "57                                     None   \n",
       "21                                        7   \n",
       "51                                        7   \n",
       "54                                       10   \n",
       "..                                      ...   \n",
       "70                                       10   \n",
       "69                                       10   \n",
       "68                                        7   \n",
       "67                                        7   \n",
       "149                                    None   \n",
       "\n",
       "                                                params  \\\n",
       "27   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "57   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "21   {'decisiontreeclassifier__ccp_alpha': 0, 'deci...   \n",
       "51   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "54   {'decisiontreeclassifier__ccp_alpha': 0.0001, ...   \n",
       "..                                                 ...   \n",
       "70   {'decisiontreeclassifier__ccp_alpha': 0.001, '...   \n",
       "69   {'decisiontreeclassifier__ccp_alpha': 0.001, '...   \n",
       "68   {'decisiontreeclassifier__ccp_alpha': 0.001, '...   \n",
       "67   {'decisiontreeclassifier__ccp_alpha': 0.001, '...   \n",
       "149  {'decisiontreeclassifier__ccp_alpha': 0.1, 'de...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "27                   0.136212         0.078956        0.073301   \n",
       "57                   0.134989         0.074525        0.075035   \n",
       "21                   0.127538         0.065223        0.077801   \n",
       "51                   0.127397         0.065023        0.077696   \n",
       "54                   0.065201         0.045392        0.040782   \n",
       "..                        ...              ...             ...   \n",
       "70                   0.000000         0.000000        0.000000   \n",
       "69                   0.000000         0.000000        0.000000   \n",
       "68                   0.000000         0.000000        0.000000   \n",
       "67                   0.000000         0.000000        0.000000   \n",
       "149                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "27                 1                   1.000000          1.000000   \n",
       "57                 2                   0.968497          0.970952   \n",
       "21                 3                   0.652188          0.637932   \n",
       "51                 4                   0.651673          0.637444   \n",
       "54                 5                   0.740199          0.739309   \n",
       "..               ...                        ...               ...   \n",
       "70               146                   0.627718          0.611340   \n",
       "69               147                   0.638875          0.626149   \n",
       "68               148                   0.591225          0.558798   \n",
       "67               149                   0.609069          0.582826   \n",
       "149              150                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "27          0.000000  \n",
       "57          0.013815  \n",
       "21          0.090702  \n",
       "51          0.090488  \n",
       "54          0.016274  \n",
       "..               ...  \n",
       "70          0.116589  \n",
       "69          0.096322  \n",
       "68          0.210185  \n",
       "67          0.170873  \n",
       "149         0.000000  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_class = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree_class_pipeline = make_pipeline(preprocessing, decision_tree_class)\n",
    "\n",
    "param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 50, 200],\n",
    "    'decisiontreeclassifier__criterion': ['entropy', 'gini'],\n",
    "    'decisiontreeclassifier__ccp_alpha': [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "decision_tree_class_gs = optimize_params(decision_tree_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
      "Time: 20.54 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.801561</td>\n",
       "      <td>0.391381</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995650</td>\n",
       "      <td>0.995361</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.428319</td>\n",
       "      <td>0.076130</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.013541</td>\n",
       "      <td>2</td>\n",
       "      <td>0.627270</td>\n",
       "      <td>0.602725</td>\n",
       "      <td>0.164072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.344155</td>\n",
       "      <td>0.061708</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>3</td>\n",
       "      <td>0.558606</td>\n",
       "      <td>0.523982</td>\n",
       "      <td>0.227149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230662</td>\n",
       "      <td>0.056107</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.513772</td>\n",
       "      <td>0.481469</td>\n",
       "      <td>0.215710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640014</td>\n",
       "      <td>0.130718</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.510964</td>\n",
       "      <td>0.478471</td>\n",
       "      <td>0.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.735495</td>\n",
       "      <td>0.173595</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.973067</td>\n",
       "      <td>0.971350</td>\n",
       "      <td>0.011598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.046521</td>\n",
       "      <td>0.358196</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.628087</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.178331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.041002</td>\n",
       "      <td>0.197376</td>\n",
       "      <td>0.016451</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.628350</td>\n",
       "      <td>0.601578</td>\n",
       "      <td>0.178209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.552898</td>\n",
       "      <td>0.266671</td>\n",
       "      <td>0.024863</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.535655</td>\n",
       "      <td>0.221119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.808124</td>\n",
       "      <td>0.141517</td>\n",
       "      <td>0.013511</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.565377</td>\n",
       "      <td>0.531820</td>\n",
       "      <td>0.219392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.051569</td>\n",
       "      <td>0.162269</td>\n",
       "      <td>0.021712</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.512893</td>\n",
       "      <td>0.480332</td>\n",
       "      <td>0.215242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.554788</td>\n",
       "      <td>0.099405</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.511445</td>\n",
       "      <td>0.478831</td>\n",
       "      <td>0.214536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.226164</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.512283</td>\n",
       "      <td>0.479176</td>\n",
       "      <td>0.214547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.054893</td>\n",
       "      <td>0.947236</td>\n",
       "      <td>0.023569</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.998994</td>\n",
       "      <td>0.998845</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.068908</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>0.994909</td>\n",
       "      <td>0.002635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.164041</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.970772</td>\n",
       "      <td>0.015504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.359078</td>\n",
       "      <td>0.477194</td>\n",
       "      <td>0.023808</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.612313</td>\n",
       "      <td>0.581809</td>\n",
       "      <td>0.201377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.208631</td>\n",
       "      <td>0.239788</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.616235</td>\n",
       "      <td>0.587404</td>\n",
       "      <td>0.190752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.488629</td>\n",
       "      <td>0.085371</td>\n",
       "      <td>0.010770</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.618094</td>\n",
       "      <td>0.592490</td>\n",
       "      <td>0.166690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.825027</td>\n",
       "      <td>0.335326</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.566263</td>\n",
       "      <td>0.532971</td>\n",
       "      <td>0.221810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986342</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.559230</td>\n",
       "      <td>0.526173</td>\n",
       "      <td>0.218572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408715</td>\n",
       "      <td>0.065167</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.564960</td>\n",
       "      <td>0.530810</td>\n",
       "      <td>0.220761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.294220</td>\n",
       "      <td>0.234812</td>\n",
       "      <td>0.022942</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'entropy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.515834</td>\n",
       "      <td>0.483010</td>\n",
       "      <td>0.216255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.930640</td>\n",
       "      <td>0.458231</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'randomforestclassifier__criterion': 'gini', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.998799</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "22       1.801561      0.391381         0.015987        0.008061   \n",
       "18       0.428319      0.076130         0.013548        0.004706   \n",
       "15       0.344155      0.061708         0.013782        0.003982   \n",
       "0        0.230662      0.056107         0.010474        0.003007   \n",
       "1        0.640014      0.130718         0.016100        0.005692   \n",
       "21       0.735495      0.173595         0.013622        0.004317   \n",
       "20       2.046521      0.358196         0.021057        0.007994   \n",
       "19       1.041002      0.197376         0.016451        0.008600   \n",
       "17       1.552898      0.266671         0.024863        0.010137   \n",
       "16       0.808124      0.141517         0.013511        0.005685   \n",
       "14       1.051569      0.162269         0.021712        0.006917   \n",
       "13       0.554788      0.099405         0.016123        0.006743   \n",
       "12       0.226164      0.039536         0.009764        0.000419   \n",
       "11       4.054893      0.947236         0.023569        0.010301   \n",
       "10       2.068908      0.446146         0.018737        0.006997   \n",
       "9        0.827889      0.164041         0.013215        0.003269   \n",
       "8        2.359078      0.477194         0.023808        0.007856   \n",
       "7        1.208631      0.239788         0.013375        0.006131   \n",
       "6        0.488629      0.085371         0.010770        0.005173   \n",
       "5        1.825027      0.335326         0.024573        0.010262   \n",
       "4        0.986342      0.193300         0.017294        0.005954   \n",
       "3        0.408715      0.065167         0.017231        0.016448   \n",
       "2        1.294220      0.234812         0.022942        0.007068   \n",
       "23       2.930640      0.458231         0.016796        0.010818   \n",
       "\n",
       "   param_randomforestclassifier__criterion  \\\n",
       "22                                    gini   \n",
       "18                                    gini   \n",
       "15                                    gini   \n",
       "0                                  entropy   \n",
       "1                                  entropy   \n",
       "21                                    gini   \n",
       "20                                    gini   \n",
       "19                                    gini   \n",
       "17                                    gini   \n",
       "16                                    gini   \n",
       "14                                    gini   \n",
       "13                                    gini   \n",
       "12                                    gini   \n",
       "11                                 entropy   \n",
       "10                                 entropy   \n",
       "9                                  entropy   \n",
       "8                                  entropy   \n",
       "7                                  entropy   \n",
       "6                                  entropy   \n",
       "5                                  entropy   \n",
       "4                                  entropy   \n",
       "3                                  entropy   \n",
       "2                                  entropy   \n",
       "23                                    gini   \n",
       "\n",
       "   param_randomforestclassifier__max_depth  \\\n",
       "22                                    None   \n",
       "18                                       7   \n",
       "15                                       5   \n",
       "0                                        3   \n",
       "1                                        3   \n",
       "21                                    None   \n",
       "20                                       7   \n",
       "19                                       7   \n",
       "17                                       5   \n",
       "16                                       5   \n",
       "14                                       3   \n",
       "13                                       3   \n",
       "12                                       3   \n",
       "11                                    None   \n",
       "10                                    None   \n",
       "9                                     None   \n",
       "8                                        7   \n",
       "7                                        7   \n",
       "6                                        7   \n",
       "5                                        5   \n",
       "4                                        5   \n",
       "3                                        5   \n",
       "2                                        3   \n",
       "23                                    None   \n",
       "\n",
       "   param_randomforestclassifier__n_estimators  \\\n",
       "22                                         25   \n",
       "18                                         10   \n",
       "15                                         10   \n",
       "0                                          10   \n",
       "1                                          25   \n",
       "21                                         10   \n",
       "20                                         50   \n",
       "19                                         25   \n",
       "17                                         50   \n",
       "16                                         25   \n",
       "14                                         50   \n",
       "13                                         25   \n",
       "12                                         10   \n",
       "11                                         50   \n",
       "10                                         25   \n",
       "9                                          10   \n",
       "8                                          50   \n",
       "7                                          25   \n",
       "6                                          10   \n",
       "5                                          50   \n",
       "4                                          25   \n",
       "3                                          10   \n",
       "2                                          50   \n",
       "23                                         50   \n",
       "\n",
       "                                               params  \\\n",
       "22  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "18  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "15  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "0   {'randomforestclassifier__criterion': 'entropy...   \n",
       "1   {'randomforestclassifier__criterion': 'entropy...   \n",
       "21  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "20  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "19  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "17  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "16  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "14  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "13  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "12  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "11  {'randomforestclassifier__criterion': 'entropy...   \n",
       "10  {'randomforestclassifier__criterion': 'entropy...   \n",
       "9   {'randomforestclassifier__criterion': 'entropy...   \n",
       "8   {'randomforestclassifier__criterion': 'entropy...   \n",
       "7   {'randomforestclassifier__criterion': 'entropy...   \n",
       "6   {'randomforestclassifier__criterion': 'entropy...   \n",
       "5   {'randomforestclassifier__criterion': 'entropy...   \n",
       "4   {'randomforestclassifier__criterion': 'entropy...   \n",
       "3   {'randomforestclassifier__criterion': 'entropy...   \n",
       "2   {'randomforestclassifier__criterion': 'entropy...   \n",
       "23  {'randomforestclassifier__criterion': 'gini', ...   \n",
       "\n",
       "    weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "22                  0.013986         0.009158        0.020477   \n",
       "18                  0.005928         0.008213        0.013541   \n",
       "15                  0.002251         0.005051        0.011293   \n",
       "0                   0.000000         0.000000        0.000000   \n",
       "1                   0.000000         0.000000        0.000000   \n",
       "21                  0.000000         0.000000        0.000000   \n",
       "20                  0.000000         0.000000        0.000000   \n",
       "19                  0.000000         0.000000        0.000000   \n",
       "17                  0.000000         0.000000        0.000000   \n",
       "16                  0.000000         0.000000        0.000000   \n",
       "14                  0.000000         0.000000        0.000000   \n",
       "13                  0.000000         0.000000        0.000000   \n",
       "12                  0.000000         0.000000        0.000000   \n",
       "11                  0.000000         0.000000        0.000000   \n",
       "10                  0.000000         0.000000        0.000000   \n",
       "9                   0.000000         0.000000        0.000000   \n",
       "8                   0.000000         0.000000        0.000000   \n",
       "7                   0.000000         0.000000        0.000000   \n",
       "6                   0.000000         0.000000        0.000000   \n",
       "5                   0.000000         0.000000        0.000000   \n",
       "4                   0.000000         0.000000        0.000000   \n",
       "3                   0.000000         0.000000        0.000000   \n",
       "2                   0.000000         0.000000        0.000000   \n",
       "23                  0.000000         0.000000        0.000000   \n",
       "\n",
       "    rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "22                1                   0.995650          0.995361   \n",
       "18                2                   0.627270          0.602725   \n",
       "15                3                   0.558606          0.523982   \n",
       "0                 4                   0.513772          0.481469   \n",
       "1                 5                   0.510964          0.478471   \n",
       "21                6                   0.973067          0.971350   \n",
       "20                7                   0.628087          0.601496   \n",
       "19                8                   0.628350          0.601578   \n",
       "17                9                   0.568966          0.535655   \n",
       "16               10                   0.565377          0.531820   \n",
       "14               11                   0.512893          0.480332   \n",
       "13               12                   0.511445          0.478831   \n",
       "12               13                   0.512283          0.479176   \n",
       "11               14                   0.998994          0.998845   \n",
       "10               15                   0.995297          0.994909   \n",
       "9                16                   0.973070          0.970772   \n",
       "8                17                   0.612313          0.581809   \n",
       "7                18                   0.616235          0.587404   \n",
       "6                19                   0.618094          0.592490   \n",
       "5                20                   0.566263          0.532971   \n",
       "4                21                   0.559230          0.526173   \n",
       "3                22                   0.564960          0.530810   \n",
       "2                23                   0.515834          0.483010   \n",
       "23               24                   0.998799          0.998600   \n",
       "\n",
       "    std_train_score  \n",
       "22         0.001892  \n",
       "18         0.164072  \n",
       "15         0.227149  \n",
       "0          0.215710  \n",
       "1          0.214300  \n",
       "21         0.011598  \n",
       "20         0.178331  \n",
       "19         0.178209  \n",
       "17         0.221119  \n",
       "16         0.219392  \n",
       "14         0.215242  \n",
       "13         0.214536  \n",
       "12         0.214547  \n",
       "11         0.000968  \n",
       "10         0.002635  \n",
       "9          0.015504  \n",
       "8          0.201377  \n",
       "7          0.190752  \n",
       "6          0.166690  \n",
       "5          0.221810  \n",
       "4          0.218572  \n",
       "3          0.220761  \n",
       "2          0.216255  \n",
       "23         0.001303  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_class = RandomForestClassifier(random_state=seed)\n",
    "random_forest_class_pipeline = make_pipeline(preprocessing, random_forest_class)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [10, 25, 50],\n",
    "    'randomforestclassifier__max_depth': [3, 5, 7, None],\n",
    "    'randomforestclassifier__criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "random_forest_class_gs = optimize_params(random_forest_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 120 candidates, totalling 720 fits\n",
      "Time: 32.47 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbclassifier__learning_rate</th>\n",
       "      <th>param_xgbclassifier__max_depth</th>\n",
       "      <th>param_xgbclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.267942</td>\n",
       "      <td>0.030168</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>0.024788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765817</td>\n",
       "      <td>0.758357</td>\n",
       "      <td>0.057437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.191052</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.017029</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683965</td>\n",
       "      <td>0.662624</td>\n",
       "      <td>0.145783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.377042</td>\n",
       "      <td>0.053106</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.015295</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>3</td>\n",
       "      <td>0.863804</td>\n",
       "      <td>0.863570</td>\n",
       "      <td>0.013060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.619128</td>\n",
       "      <td>0.119256</td>\n",
       "      <td>0.026303</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>4</td>\n",
       "      <td>0.945788</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.007597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.411911</td>\n",
       "      <td>0.097179</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.2, 'xgbclas...</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>5</td>\n",
       "      <td>0.881677</td>\n",
       "      <td>0.877305</td>\n",
       "      <td>0.035725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.965026</td>\n",
       "      <td>0.356935</td>\n",
       "      <td>0.024146</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.029931</td>\n",
       "      <td>0.064922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.073963</td>\n",
       "      <td>0.181548</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.590069</td>\n",
       "      <td>0.109462</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.268515</td>\n",
       "      <td>0.034406</td>\n",
       "      <td>0.015536</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.005, 'xgbcl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.093048</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'xgbclassifier__learning_rate': 0.05, 'xgbcla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "118       0.267942      0.030168         0.017321        0.007399   \n",
       "117       0.191052      0.027417         0.015968        0.003214   \n",
       "119       0.377042      0.053106         0.015930        0.011660   \n",
       "114       0.619128      0.119256         0.026303        0.011891   \n",
       "113       0.411911      0.097179         0.016391        0.003007   \n",
       "..             ...           ...              ...             ...   \n",
       "35        1.965026      0.356935         0.024146        0.012823   \n",
       "34        1.073963      0.181548         0.023417        0.005467   \n",
       "33        0.590069      0.109462         0.017219        0.005851   \n",
       "32        0.268515      0.034406         0.015536        0.004706   \n",
       "60        0.093048      0.016355         0.015398        0.003357   \n",
       "\n",
       "    param_xgbclassifier__learning_rate param_xgbclassifier__max_depth  \\\n",
       "118                                0.2                           None   \n",
       "117                                0.2                           None   \n",
       "119                                0.2                           None   \n",
       "114                                0.2                             10   \n",
       "113                                0.2                             10   \n",
       "..                                 ...                            ...   \n",
       "35                               0.005                             10   \n",
       "34                               0.005                             10   \n",
       "33                               0.005                             10   \n",
       "32                               0.005                             10   \n",
       "60                                0.05                              3   \n",
       "\n",
       "    param_xgbclassifier__n_estimators  \\\n",
       "118                                50   \n",
       "117                                25   \n",
       "119                               100   \n",
       "114                                50   \n",
       "113                                25   \n",
       "..                                ...   \n",
       "35                                100   \n",
       "34                                 50   \n",
       "33                                 25   \n",
       "32                                 10   \n",
       "60                                 10   \n",
       "\n",
       "                                                params  \\\n",
       "118  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "117  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "119  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "114  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "113  {'xgbclassifier__learning_rate': 0.2, 'xgbclas...   \n",
       "..                                                 ...   \n",
       "35   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "34   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "33   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "32   {'xgbclassifier__learning_rate': 0.005, 'xgbcl...   \n",
       "60   {'xgbclassifier__learning_rate': 0.05, 'xgbcla...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "118                  0.019250         0.014124        0.024788   \n",
       "117                  0.017029         0.012670        0.021655   \n",
       "119                  0.015295         0.010014        0.022393   \n",
       "114                  0.014720         0.011158        0.018440   \n",
       "113                  0.011440         0.007491        0.016750   \n",
       "..                        ...              ...             ...   \n",
       "35                   0.000000         0.000000        0.000000   \n",
       "34                   0.000000         0.000000        0.000000   \n",
       "33                   0.000000         0.000000        0.000000   \n",
       "32                   0.000000         0.000000        0.000000   \n",
       "60                   0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "118                1                   0.765817          0.758357   \n",
       "117                2                   0.683965          0.662624   \n",
       "119                3                   0.863804          0.863570   \n",
       "114                4                   0.945788          0.946823   \n",
       "113                5                   0.881677          0.877305   \n",
       "..               ...                        ...               ...   \n",
       "35               116                   0.026916          0.029931   \n",
       "34               117                   0.000000          0.000000   \n",
       "33               118                   0.000000          0.000000   \n",
       "32               119                   0.000000          0.000000   \n",
       "60               120                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "118         0.057437  \n",
       "117         0.145783  \n",
       "119         0.013060  \n",
       "114         0.007597  \n",
       "113         0.035725  \n",
       "..               ...  \n",
       "35          0.064922  \n",
       "34          0.000000  \n",
       "33          0.000000  \n",
       "32          0.000000  \n",
       "60          0.000000  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state=seed)\n",
    "xgb_class_pipeline = make_pipeline(preprocessing, xgb_class)\n",
    "\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [10, 25, 50, 100],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, None],\n",
    "    'xgbclassifier__learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_class_gs = optimize_params(xgb_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 252 candidates, totalling 1512 fits\n",
      "Time: 15.64 seg.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_sgdclassifier__alpha</th>\n",
       "      <th>param_sgdclassifier__class_weight</th>\n",
       "      <th>param_sgdclassifier__loss</th>\n",
       "      <th>param_sgdclassifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>weighted_mean_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>weighted_mean_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.342562</td>\n",
       "      <td>0.184508</td>\n",
       "      <td>0.229919</td>\n",
       "      <td>1</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.136147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.342562</td>\n",
       "      <td>0.184508</td>\n",
       "      <td>0.229919</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.136147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.064414</td>\n",
       "      <td>0.019641</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.342562</td>\n",
       "      <td>0.184508</td>\n",
       "      <td>0.229919</td>\n",
       "      <td>3</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.136147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.062145</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.001, 'sgdclassifier...</td>\n",
       "      <td>0.342562</td>\n",
       "      <td>0.184508</td>\n",
       "      <td>0.229919</td>\n",
       "      <td>4</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>0.136147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.049923</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.01, 'sgdclassifier_...</td>\n",
       "      <td>0.323738</td>\n",
       "      <td>0.169558</td>\n",
       "      <td>0.235409</td>\n",
       "      <td>5</td>\n",
       "      <td>0.550728</td>\n",
       "      <td>0.528610</td>\n",
       "      <td>0.149525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.045774</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>50</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.034353</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.2, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.036464</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.2, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.033112</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.2</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>100</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.2, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.036851</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>{'sgdclassifier__alpha': 0.8, 'sgdclassifier__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "40        0.064236      0.015682         0.010896        0.002341   \n",
       "43        0.065355      0.015197         0.013241        0.002068   \n",
       "42        0.064414      0.019641         0.011592        0.003958   \n",
       "41        0.062145      0.021610         0.012322        0.004808   \n",
       "76        0.049923      0.012775         0.011452        0.002429   \n",
       "..             ...           ...              ...             ...   \n",
       "228       0.045774      0.006115         0.013365        0.003193   \n",
       "163       0.034353      0.006147         0.013367        0.004074   \n",
       "162       0.036464      0.006371         0.010771        0.004917   \n",
       "161       0.033112      0.006843         0.010956        0.004023   \n",
       "234       0.036851      0.007659         0.011688        0.003899   \n",
       "\n",
       "    param_sgdclassifier__alpha param_sgdclassifier__class_weight  \\\n",
       "40                       0.001                          balanced   \n",
       "43                       0.001                          balanced   \n",
       "42                       0.001                          balanced   \n",
       "41                       0.001                          balanced   \n",
       "76                        0.01                          balanced   \n",
       "..                         ...                               ...   \n",
       "228                        0.8                              None   \n",
       "163                        0.2                              None   \n",
       "162                        0.2                              None   \n",
       "161                        0.2                              None   \n",
       "234                        0.8                              None   \n",
       "\n",
       "    param_sgdclassifier__loss param_sgdclassifier__max_iter  \\\n",
       "40                      hinge                            50   \n",
       "43                      hinge                          1000   \n",
       "42                      hinge                           500   \n",
       "41                      hinge                           100   \n",
       "76                      hinge                            50   \n",
       "..                        ...                           ...   \n",
       "228                  log_loss                            50   \n",
       "163                     hinge                          1000   \n",
       "162                     hinge                           500   \n",
       "161                     hinge                           100   \n",
       "234                     hinge                           500   \n",
       "\n",
       "                                                params  \\\n",
       "40   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "43   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "42   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "41   {'sgdclassifier__alpha': 0.001, 'sgdclassifier...   \n",
       "76   {'sgdclassifier__alpha': 0.01, 'sgdclassifier_...   \n",
       "..                                                 ...   \n",
       "228  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "163  {'sgdclassifier__alpha': 0.2, 'sgdclassifier__...   \n",
       "162  {'sgdclassifier__alpha': 0.2, 'sgdclassifier__...   \n",
       "161  {'sgdclassifier__alpha': 0.2, 'sgdclassifier__...   \n",
       "234  {'sgdclassifier__alpha': 0.8, 'sgdclassifier__...   \n",
       "\n",
       "     weighted_mean_test_score  mean_test_score  std_test_score  \\\n",
       "40                   0.342562         0.184508        0.229919   \n",
       "43                   0.342562         0.184508        0.229919   \n",
       "42                   0.342562         0.184508        0.229919   \n",
       "41                   0.342562         0.184508        0.229919   \n",
       "76                   0.323738         0.169558        0.235409   \n",
       "..                        ...              ...             ...   \n",
       "228                  0.000000         0.000000        0.000000   \n",
       "163                  0.000000         0.000000        0.000000   \n",
       "162                  0.000000         0.000000        0.000000   \n",
       "161                  0.000000         0.000000        0.000000   \n",
       "234                  0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  weighted_mean_train_score  mean_train_score  \\\n",
       "40                 1                   0.553700          0.533341   \n",
       "43                 2                   0.553700          0.533341   \n",
       "42                 3                   0.553700          0.533341   \n",
       "41                 4                   0.553700          0.533341   \n",
       "76                 5                   0.550728          0.528610   \n",
       "..               ...                        ...               ...   \n",
       "228              248                   0.000000          0.000000   \n",
       "163              249                   0.000000          0.000000   \n",
       "162              250                   0.000000          0.000000   \n",
       "161              251                   0.000000          0.000000   \n",
       "234              252                   0.000000          0.000000   \n",
       "\n",
       "     std_train_score  \n",
       "40          0.136147  \n",
       "43          0.136147  \n",
       "42          0.136147  \n",
       "41          0.136147  \n",
       "76          0.149525  \n",
       "..               ...  \n",
       "228         0.000000  \n",
       "163         0.000000  \n",
       "162         0.000000  \n",
       "161         0.000000  \n",
       "234         0.000000  \n",
       "\n",
       "[252 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd_class = SGDClassifier(random_state=seed)\n",
    "sgd_class_pipeline = make_pipeline(preprocessing, sgd_class)\n",
    "\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.8],\n",
    "    'sgdclassifier__max_iter': [50, 100, 500, 1000],\n",
    "    'sgdclassifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'sgdclassifier__class_weight': ['balanced', None, {0:1, 1:2}]\n",
    "}\n",
    "\n",
    "sgd_class_gs = optimize_params(sgd_class_pipeline, X_train, y_train, folds, scoring='f1', **param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.342562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.161107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbol de decision</td>\n",
       "      <td>0.136212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresion logistica</td>\n",
       "      <td>0.042577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.019250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Mejor puntuacion\n",
       "5                  SGD          0.342562\n",
       "1           KNeighbors          0.161107\n",
       "2    Arbol de decision          0.136212\n",
       "0  Regresion logistica          0.042577\n",
       "4              XGBoost          0.019250\n",
       "3        Random Forest          0.013986"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = {\n",
    "    'Regresion logistica': logistic_reg_gs,\n",
    "    'KNeighbors' : k_neighbors_class_gs,\n",
    "    'Arbol de decision': decision_tree_class_gs,\n",
    "    'Random Forest': random_forest_class_gs,\n",
    "    'XGBoost': xgb_class_gs,\n",
    "    'SGD': sgd_class_gs\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Modelo': models_dict.keys(),\n",
    "    'Mejor puntuacion': [gs.best_score_ for gs in models_dict.values()]\n",
    "})\n",
    "df_results = df_results.sort_values(by='Mejor puntuacion', ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model_4\\\\to_cr_gu\\\\model_mediaalta_alta.joblib']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[df_results.loc[df_results.index[0], 'Modelo']].best_estimator_\n",
    "model_path = os.path.join('models', 'experiment_4', 'TO_CR_GU', 'model_mediaalta_alta.joblib')\n",
    "dump(best_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas predicci√≥n del test\n",
      "F1:        0.5800521333516258\n",
      "Recall:    0.7983383685800605\n",
      "Precision: 0.4555052790346908\n",
      "Accuracy:  0.7689288140711105\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('models', 'experiment_4', 'TO_CR_GU', 'model_mediaalta_alta.joblib')\n",
    "model = load(model_path)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\"\"M√©tricas predicci√≥n del test\n",
    "F1:        {f1_score(y_test, pred)}\n",
    "Recall:    {recall_score(y_test, pred)}\n",
    "Precision: {precision_score(y_test, pred)}\n",
    "Accuracy:  {accuracy_score(y_test, pred)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicci√≥n final sobre los incendios de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join('models', 'experiment_4', 'TO_CR_GU')\n",
    "final_model = {\n",
    "    'baja_alta': load(os.path.join(folder_path, 'model_baja_alta.joblib')),\n",
    "    'baja_mediabaja': load(os.path.join(folder_path, 'model_baja_mediabaja.joblib')),\n",
    "    'mediaalta_alta': load(os.path.join(folder_path, 'model_mediaalta_alta.joblib')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fire_name in test_fire_names:\n",
    "    df_fire = df_test[df_test['incendio'] == fire_name].reset_index(drop=True)\n",
    "\n",
    "    X_fire = df_fire[variables]\n",
    "    y_fire = df_fire[target_discrete]\n",
    "    coords_fire = df_fire[coords_columns]\n",
    "\n",
    "    pred = final_model['baja_alta'].predict(X_fire)\n",
    "    predictions_baja_alta = pred\n",
    "    pred_fire = np.zeros_like(predictions_baja_alta)\n",
    "\n",
    "    if np.count_nonzero(predictions_baja_alta == 0) > 0:\n",
    "        indexes_pred_baja = X_fire.index[predictions_baja_alta == 0]\n",
    "        pred = final_model['baja_mediabaja'].predict(X_fire.loc[predictions_baja_alta == 0])\n",
    "\n",
    "\n",
    "        predictions_baja_media = pred\n",
    "        predictions_baja_media = np.where(predictions_baja_media == 0, 0, 1)\n",
    "        pred_fire[indexes_pred_baja] = predictions_baja_media\n",
    "\n",
    "    if np.count_nonzero(predictions_baja_alta == 1) > 0:\n",
    "        indexes_pred_alta = X_fire.index[predictions_baja_alta == 1]\n",
    "        pred = final_model['mediaalta_alta'].predict(X_fire.loc[predictions_baja_alta == 1])\n",
    "\n",
    "        predictions_alta_muyalta = pred\n",
    "        predictions_alta_muyalta = np.where(predictions_alta_muyalta == 0, 2, 3)\n",
    "        pred_fire[indexes_pred_alta] = predictions_alta_muyalta\n",
    "\n",
    "    matrix_fire = sm.get_severity_matrix(y_fire, coords_fire)\n",
    "    matrix_pred = sm.get_severity_matrix(pred_fire, coords_fire)\n",
    "    sm.show_original_prediction_evaluation_severity_matrices(matrix_fire, matrix_pred, fig_title=fire_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuevoEntorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
